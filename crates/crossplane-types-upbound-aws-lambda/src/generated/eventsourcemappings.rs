// WARNING: generated by kopium - manual changes will be overwritten
// kopium version: 0.21.2

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use schemars::JsonSchema;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::HashMap;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// EventSourceMappingSpec defines the desired state of EventSourceMapping
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, JsonSchema)]
#[kube(group = "lambda.aws.upbound.io", version = "v1beta2", kind = "EventSourceMapping", plural = "eventsourcemappings")]
#[kube(status = "EventSourceMappingStatus")]
pub struct EventSourceMappingSpec {
    /// DeletionPolicy specifies what will happen to the underlying external
    /// when this managed resource is deleted - either "Delete" or "Orphan" the
    /// external resource.
    /// This field is planned to be deprecated in favor of the ManagementPolicies
    /// field in a future release. Currently, both could be set independently and
    /// non-default values would be honored if the feature flag is enabled.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionPolicy")]
    pub deletion_policy: Option<EventSourceMappingDeletionPolicy>,
    #[serde(rename = "forProvider")]
    pub for_provider: EventSourceMappingForProvider,
    /// THIS IS A BETA FIELD. It will be honored
    /// unless the Management Policies feature flag is disabled.
    /// InitProvider holds the same fields as ForProvider, with the exception
    /// of Identifier and other resource reference fields. The fields that are
    /// in InitProvider are merged into ForProvider when the resource is created.
    /// The same fields are also added to the terraform ignore_changes hook, to
    /// avoid updating them after creation. This is useful for fields that are
    /// required on creation, but we do not desire to update them after creation,
    /// for example because of an external controller is managing them, like an
    /// autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initProvider")]
    pub init_provider: Option<EventSourceMappingInitProvider>,
    /// THIS IS A BETA FIELD. It is on by default but can be opted out
    /// through a Crossplane feature flag.
    /// ManagementPolicies specify the array of actions Crossplane is allowed to
    /// take on the managed and external resources.
    /// This field is planned to replace the DeletionPolicy field in a future
    /// release. Currently, both could be set independently and non-default
    /// values would be honored if the feature flag is enabled. If both are
    /// custom, the DeletionPolicy field will be ignored.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    /// and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managementPolicies")]
    pub management_policies: Option<Vec<String>>,
    /// ProviderConfigReference specifies how the provider that will be used to
    /// create, observe, update, and delete this managed resource should be
    /// configured.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providerConfigRef")]
    pub provider_config_ref: Option<EventSourceMappingProviderConfigRef>,
    /// PublishConnectionDetailsTo specifies the connection secret config which
    /// contains a name, metadata and a reference to secret store config to
    /// which any connection details for this managed resource should be written.
    /// Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "publishConnectionDetailsTo")]
    pub publish_connection_details_to: Option<EventSourceMappingPublishConnectionDetailsTo>,
    /// WriteConnectionSecretToReference specifies the namespace and name of a
    /// Secret to which any connection details for this managed resource should
    /// be written. Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    /// This field is planned to be replaced in a future release in favor of
    /// PublishConnectionDetailsTo. Currently, both could be set independently
    /// and connection details would be published to both without affecting
    /// each other.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeConnectionSecretToRef")]
    pub write_connection_secret_to_ref: Option<EventSourceMappingWriteConnectionSecretToRef>,
}

/// EventSourceMappingSpec defines the desired state of EventSourceMapping
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingDeletionPolicy {
    Orphan,
    Delete,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProvider {
    /// Additional configuration block for Amazon Managed Kafka sources. Incompatible with "self_managed_event_source" and "self_managed_kafka_event_source_config". Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "amazonManagedKafkaEventSourceConfig")]
    pub amazon_managed_kafka_event_source_config: Option<EventSourceMappingForProviderAmazonManagedKafkaEventSourceConfig>,
    /// The largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to 100 for DynamoDB, Kinesis, MQ and MSK, 10 for SQS.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "batchSize")]
    pub batch_size: Option<f64>,
    /// If the function returns an error, split the batch in two and retry. Only available for stream sources (DynamoDB and Kinesis). Defaults to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bisectBatchOnFunctionError")]
    pub bisect_batch_on_function_error: Option<bool>,
    /// An Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationConfig")]
    pub destination_config: Option<EventSourceMappingForProviderDestinationConfig>,
    /// Configuration settings for a DocumentDB event source. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "documentDbEventSourceConfig")]
    pub document_db_event_source_config: Option<EventSourceMappingForProviderDocumentDbEventSourceConfig>,
    /// Determines if the mapping will be enabled on creation. Defaults to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// The event source ARN - this is required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream.  It is incompatible with a Self Managed Kafka source.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "eventSourceArn")]
    pub event_source_arn: Option<String>,
    /// The criteria to use for event filtering Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "filterCriteria")]
    pub filter_criteria: Option<EventSourceMappingForProviderFilterCriteria>,
    /// The name or the ARN of the Lambda function that will be subscribing to events.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionName")]
    pub function_name: Option<String>,
    /// Reference to a Function in lambda to populate functionName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionNameRef")]
    pub function_name_ref: Option<EventSourceMappingForProviderFunctionNameRef>,
    /// Selector for a Function in lambda to populate functionName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionNameSelector")]
    pub function_name_selector: Option<EventSourceMappingForProviderFunctionNameSelector>,
    /// A list of current response type enums applied to the event source mapping for AWS Lambda checkpointing. Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: ReportBatchItemFailures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionResponseTypes")]
    pub function_response_types: Option<Vec<String>>,
    /// The ARN of the Key Management Service (KMS) customer managed key that Lambda uses to encrypt your function's filter criteria.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArn")]
    pub kms_key_arn: Option<String>,
    /// Reference to a Key in kms to populate kmsKeyArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArnRef")]
    pub kms_key_arn_ref: Option<EventSourceMappingForProviderKmsKeyArnRef>,
    /// Selector for a Key in kms to populate kmsKeyArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArnSelector")]
    pub kms_key_arn_selector: Option<EventSourceMappingForProviderKmsKeyArnSelector>,
    /// The maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer (or accumulate in the case of an SQS queue event source) until either maximum_batching_window_in_seconds expires or batch_size has been met. For streaming event sources, defaults to as soon as records are available in the stream. If the batch it reads from the stream/queue only has one record in it, Lambda only sends one record to the function. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBatchingWindowInSeconds")]
    pub maximum_batching_window_in_seconds: Option<f64>,
    /// The maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRecordAgeInSeconds")]
    pub maximum_record_age_in_seconds: Option<f64>,
    /// The maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRetryAttempts")]
    pub maximum_retry_attempts: Option<f64>,
    /// CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metricsConfig")]
    pub metrics_config: Option<EventSourceMappingForProviderMetricsConfig>,
    /// The number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parallelizationFactor")]
    pub parallelization_factor: Option<f64>,
    /// Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "provisionedPollerConfig")]
    pub provisioned_poller_config: Option<EventSourceMappingForProviderProvisionedPollerConfig>,
    /// The name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub queues: Option<Vec<String>>,
    /// Region is the region you'd like your resource to be created in.
    pub region: String,
    /// Scaling configuration of the event source. Only available for SQS queues. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scalingConfig")]
    pub scaling_config: Option<EventSourceMappingForProviderScalingConfig>,
    /// For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include source_access_configuration. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfManagedEventSource")]
    pub self_managed_event_source: Option<EventSourceMappingForProviderSelfManagedEventSource>,
    /// Additional configuration block for Self Managed Kafka sources. Incompatible with "event_source_arn" and "amazon_managed_kafka_event_source_config". Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfManagedKafkaEventSourceConfig")]
    pub self_managed_kafka_event_source_config: Option<EventSourceMappingForProviderSelfManagedKafkaEventSourceConfig>,
    /// :  For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include self_managed_event_source. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceAccessConfiguration")]
    pub source_access_configuration: Option<Vec<EventSourceMappingForProviderSourceAccessConfiguration>>,
    /// The position in the stream where AWS Lambda should start reading. Must be one of AT_TIMESTAMP (Kinesis only), LATEST or TRIM_HORIZON if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the AWS DynamoDB Streams API Reference and AWS Kinesis API Reference.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startingPosition")]
    pub starting_position: Option<String>,
    /// A timestamp in RFC3339 format of the data record which to start reading when using starting_position set to AT_TIMESTAMP. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startingPositionTimestamp")]
    pub starting_position_timestamp: Option<String>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tags: Option<HashMap<String, String>>,
    /// The name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub topics: Option<Vec<String>>,
    /// The duration in seconds of a processing window for AWS Lambda streaming analytics. The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tumblingWindowInSeconds")]
    pub tumbling_window_in_seconds: Option<f64>,
}

/// Additional configuration block for Amazon Managed Kafka sources. Incompatible with "self_managed_event_source" and "self_managed_kafka_event_source_config". Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderAmazonManagedKafkaEventSourceConfig {
    /// A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See AmazonManagedKafkaEventSourceConfig Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerGroupId")]
    pub consumer_group_id: Option<String>,
}

/// An Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderDestinationConfig {
    /// The destination configuration for failed invocations. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onFailure")]
    pub on_failure: Option<EventSourceMappingForProviderDestinationConfigOnFailure>,
}

/// The destination configuration for failed invocations. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderDestinationConfigOnFailure {
    /// The Amazon Resource Name (ARN) of the destination resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationArn")]
    pub destination_arn: Option<String>,
}

/// Configuration settings for a DocumentDB event source. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderDocumentDbEventSourceConfig {
    /// The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionName")]
    pub collection_name: Option<String>,
    /// The name of the database to consume within the DocumentDB cluster.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "databaseName")]
    pub database_name: Option<String>,
    /// Determines what DocumentDB sends to your event stream during document update operations. If set to UpdateLookup, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes. Valid values: UpdateLookup, Default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fullDocument")]
    pub full_document: Option<String>,
}

/// The criteria to use for event filtering Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderFilterCriteria {
    /// A set of up to 5 filter. If an event satisfies at least one, Lambda sends the event to the function or adds it to the next batch. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub filter: Option<Vec<EventSourceMappingForProviderFilterCriteriaFilter>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderFilterCriteriaFilter {
    /// A filter pattern up to 4096 characters. See Filter Rule Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pattern: Option<String>,
}

/// Reference to a Function in lambda to populate functionName.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderFunctionNameRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingForProviderFunctionNameRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderFunctionNameRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingForProviderFunctionNameRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingForProviderFunctionNameRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderFunctionNameRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderFunctionNameRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Function in lambda to populate functionName.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderFunctionNameSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingForProviderFunctionNameSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderFunctionNameSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingForProviderFunctionNameSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingForProviderFunctionNameSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderFunctionNameSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderFunctionNameSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderKmsKeyArnRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingForProviderKmsKeyArnRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderKmsKeyArnRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingForProviderKmsKeyArnRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingForProviderKmsKeyArnRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderKmsKeyArnRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderKmsKeyArnRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderKmsKeyArnSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingForProviderKmsKeyArnSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderKmsKeyArnSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingForProviderKmsKeyArnSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingForProviderKmsKeyArnSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderKmsKeyArnSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingForProviderKmsKeyArnSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderMetricsConfig {
    /// A list containing the metrics to be produced by the event source mapping. Valid values: EventCount.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<String>>,
}

/// Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderProvisionedPollerConfig {
    /// The maximum number of event pollers this event source can scale up to. The range is between 1 and 2000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumPollers")]
    pub maximum_pollers: Option<f64>,
    /// The minimum number of event pollers this event source can scale down to. The range is between 1 and 200.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minimumPollers")]
    pub minimum_pollers: Option<f64>,
}

/// Scaling configuration of the event source. Only available for SQS queues. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderScalingConfig {
    /// Limits the number of concurrent instances that the Amazon SQS event source can invoke. Must be greater than or equal to 2. See Configuring maximum concurrency for Amazon SQS event sources. You need to raise a Service Quota Ticket to increase the concurrency beyond 1000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumConcurrency")]
    pub maximum_concurrency: Option<f64>,
}

/// For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include source_access_configuration. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderSelfManagedEventSource {
    /// A map of endpoints for the self managed source.  For Kafka self-managed sources, the key should be KAFKA_BOOTSTRAP_SERVERS and the value should be a string with a comma separated list of broker endpoints.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub endpoints: Option<HashMap<String, String>>,
}

/// Additional configuration block for Self Managed Kafka sources. Incompatible with "event_source_arn" and "amazon_managed_kafka_event_source_config". Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderSelfManagedKafkaEventSourceConfig {
    /// A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See SelfManagedKafkaEventSourceConfig Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerGroupId")]
    pub consumer_group_id: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingForProviderSourceAccessConfiguration {
    /// The type of authentication protocol, VPC components, or virtual host for your event source. For valid values, refer to the AWS documentation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
    /// The URI for this configuration.  For type VPC_SUBNET the value should be subnet:subnet_id where subnet_id is the value you would find in an aws_subnet resource's id attribute.  For type VPC_SECURITY_GROUP the value should be security_group:security_group_id where security_group_id is the value you would find in an aws_security_group resource's id attribute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub uri: Option<String>,
}

/// THIS IS A BETA FIELD. It will be honored
/// unless the Management Policies feature flag is disabled.
/// InitProvider holds the same fields as ForProvider, with the exception
/// of Identifier and other resource reference fields. The fields that are
/// in InitProvider are merged into ForProvider when the resource is created.
/// The same fields are also added to the terraform ignore_changes hook, to
/// avoid updating them after creation. This is useful for fields that are
/// required on creation, but we do not desire to update them after creation,
/// for example because of an external controller is managing them, like an
/// autoscaler.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProvider {
    /// Additional configuration block for Amazon Managed Kafka sources. Incompatible with "self_managed_event_source" and "self_managed_kafka_event_source_config". Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "amazonManagedKafkaEventSourceConfig")]
    pub amazon_managed_kafka_event_source_config: Option<EventSourceMappingInitProviderAmazonManagedKafkaEventSourceConfig>,
    /// The largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to 100 for DynamoDB, Kinesis, MQ and MSK, 10 for SQS.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "batchSize")]
    pub batch_size: Option<f64>,
    /// If the function returns an error, split the batch in two and retry. Only available for stream sources (DynamoDB and Kinesis). Defaults to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bisectBatchOnFunctionError")]
    pub bisect_batch_on_function_error: Option<bool>,
    /// An Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationConfig")]
    pub destination_config: Option<EventSourceMappingInitProviderDestinationConfig>,
    /// Configuration settings for a DocumentDB event source. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "documentDbEventSourceConfig")]
    pub document_db_event_source_config: Option<EventSourceMappingInitProviderDocumentDbEventSourceConfig>,
    /// Determines if the mapping will be enabled on creation. Defaults to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// The event source ARN - this is required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream.  It is incompatible with a Self Managed Kafka source.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "eventSourceArn")]
    pub event_source_arn: Option<String>,
    /// The criteria to use for event filtering Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "filterCriteria")]
    pub filter_criteria: Option<EventSourceMappingInitProviderFilterCriteria>,
    /// The name or the ARN of the Lambda function that will be subscribing to events.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionName")]
    pub function_name: Option<String>,
    /// Reference to a Function in lambda to populate functionName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionNameRef")]
    pub function_name_ref: Option<EventSourceMappingInitProviderFunctionNameRef>,
    /// Selector for a Function in lambda to populate functionName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionNameSelector")]
    pub function_name_selector: Option<EventSourceMappingInitProviderFunctionNameSelector>,
    /// A list of current response type enums applied to the event source mapping for AWS Lambda checkpointing. Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: ReportBatchItemFailures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionResponseTypes")]
    pub function_response_types: Option<Vec<String>>,
    /// The ARN of the Key Management Service (KMS) customer managed key that Lambda uses to encrypt your function's filter criteria.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArn")]
    pub kms_key_arn: Option<String>,
    /// Reference to a Key in kms to populate kmsKeyArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArnRef")]
    pub kms_key_arn_ref: Option<EventSourceMappingInitProviderKmsKeyArnRef>,
    /// Selector for a Key in kms to populate kmsKeyArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArnSelector")]
    pub kms_key_arn_selector: Option<EventSourceMappingInitProviderKmsKeyArnSelector>,
    /// The maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer (or accumulate in the case of an SQS queue event source) until either maximum_batching_window_in_seconds expires or batch_size has been met. For streaming event sources, defaults to as soon as records are available in the stream. If the batch it reads from the stream/queue only has one record in it, Lambda only sends one record to the function. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBatchingWindowInSeconds")]
    pub maximum_batching_window_in_seconds: Option<f64>,
    /// The maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRecordAgeInSeconds")]
    pub maximum_record_age_in_seconds: Option<f64>,
    /// The maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRetryAttempts")]
    pub maximum_retry_attempts: Option<f64>,
    /// CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metricsConfig")]
    pub metrics_config: Option<EventSourceMappingInitProviderMetricsConfig>,
    /// The number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parallelizationFactor")]
    pub parallelization_factor: Option<f64>,
    /// Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "provisionedPollerConfig")]
    pub provisioned_poller_config: Option<EventSourceMappingInitProviderProvisionedPollerConfig>,
    /// The name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub queues: Option<Vec<String>>,
    /// Scaling configuration of the event source. Only available for SQS queues. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scalingConfig")]
    pub scaling_config: Option<EventSourceMappingInitProviderScalingConfig>,
    /// For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include source_access_configuration. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfManagedEventSource")]
    pub self_managed_event_source: Option<EventSourceMappingInitProviderSelfManagedEventSource>,
    /// Additional configuration block for Self Managed Kafka sources. Incompatible with "event_source_arn" and "amazon_managed_kafka_event_source_config". Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfManagedKafkaEventSourceConfig")]
    pub self_managed_kafka_event_source_config: Option<EventSourceMappingInitProviderSelfManagedKafkaEventSourceConfig>,
    /// :  For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include self_managed_event_source. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceAccessConfiguration")]
    pub source_access_configuration: Option<Vec<EventSourceMappingInitProviderSourceAccessConfiguration>>,
    /// The position in the stream where AWS Lambda should start reading. Must be one of AT_TIMESTAMP (Kinesis only), LATEST or TRIM_HORIZON if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the AWS DynamoDB Streams API Reference and AWS Kinesis API Reference.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startingPosition")]
    pub starting_position: Option<String>,
    /// A timestamp in RFC3339 format of the data record which to start reading when using starting_position set to AT_TIMESTAMP. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startingPositionTimestamp")]
    pub starting_position_timestamp: Option<String>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tags: Option<HashMap<String, String>>,
    /// The name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub topics: Option<Vec<String>>,
    /// The duration in seconds of a processing window for AWS Lambda streaming analytics. The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tumblingWindowInSeconds")]
    pub tumbling_window_in_seconds: Option<f64>,
}

/// Additional configuration block for Amazon Managed Kafka sources. Incompatible with "self_managed_event_source" and "self_managed_kafka_event_source_config". Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderAmazonManagedKafkaEventSourceConfig {
    /// A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See AmazonManagedKafkaEventSourceConfig Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerGroupId")]
    pub consumer_group_id: Option<String>,
}

/// An Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderDestinationConfig {
    /// The destination configuration for failed invocations. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onFailure")]
    pub on_failure: Option<EventSourceMappingInitProviderDestinationConfigOnFailure>,
}

/// The destination configuration for failed invocations. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderDestinationConfigOnFailure {
    /// The Amazon Resource Name (ARN) of the destination resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationArn")]
    pub destination_arn: Option<String>,
}

/// Configuration settings for a DocumentDB event source. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderDocumentDbEventSourceConfig {
    /// The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionName")]
    pub collection_name: Option<String>,
    /// The name of the database to consume within the DocumentDB cluster.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "databaseName")]
    pub database_name: Option<String>,
    /// Determines what DocumentDB sends to your event stream during document update operations. If set to UpdateLookup, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes. Valid values: UpdateLookup, Default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fullDocument")]
    pub full_document: Option<String>,
}

/// The criteria to use for event filtering Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderFilterCriteria {
    /// A set of up to 5 filter. If an event satisfies at least one, Lambda sends the event to the function or adds it to the next batch. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub filter: Option<Vec<EventSourceMappingInitProviderFilterCriteriaFilter>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderFilterCriteriaFilter {
    /// A filter pattern up to 4096 characters. See Filter Rule Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pattern: Option<String>,
}

/// Reference to a Function in lambda to populate functionName.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderFunctionNameRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingInitProviderFunctionNameRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderFunctionNameRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingInitProviderFunctionNameRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingInitProviderFunctionNameRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderFunctionNameRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderFunctionNameRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Function in lambda to populate functionName.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderFunctionNameSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingInitProviderFunctionNameSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderFunctionNameSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingInitProviderFunctionNameSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingInitProviderFunctionNameSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderFunctionNameSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderFunctionNameSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderKmsKeyArnRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingInitProviderKmsKeyArnRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderKmsKeyArnRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingInitProviderKmsKeyArnRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingInitProviderKmsKeyArnRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderKmsKeyArnRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderKmsKeyArnRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderKmsKeyArnSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingInitProviderKmsKeyArnSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderKmsKeyArnSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingInitProviderKmsKeyArnSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingInitProviderKmsKeyArnSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderKmsKeyArnSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingInitProviderKmsKeyArnSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderMetricsConfig {
    /// A list containing the metrics to be produced by the event source mapping. Valid values: EventCount.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<String>>,
}

/// Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderProvisionedPollerConfig {
    /// The maximum number of event pollers this event source can scale up to. The range is between 1 and 2000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumPollers")]
    pub maximum_pollers: Option<f64>,
    /// The minimum number of event pollers this event source can scale down to. The range is between 1 and 200.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minimumPollers")]
    pub minimum_pollers: Option<f64>,
}

/// Scaling configuration of the event source. Only available for SQS queues. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderScalingConfig {
    /// Limits the number of concurrent instances that the Amazon SQS event source can invoke. Must be greater than or equal to 2. See Configuring maximum concurrency for Amazon SQS event sources. You need to raise a Service Quota Ticket to increase the concurrency beyond 1000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumConcurrency")]
    pub maximum_concurrency: Option<f64>,
}

/// For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include source_access_configuration. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderSelfManagedEventSource {
    /// A map of endpoints for the self managed source.  For Kafka self-managed sources, the key should be KAFKA_BOOTSTRAP_SERVERS and the value should be a string with a comma separated list of broker endpoints.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub endpoints: Option<HashMap<String, String>>,
}

/// Additional configuration block for Self Managed Kafka sources. Incompatible with "event_source_arn" and "amazon_managed_kafka_event_source_config". Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderSelfManagedKafkaEventSourceConfig {
    /// A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See SelfManagedKafkaEventSourceConfig Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerGroupId")]
    pub consumer_group_id: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingInitProviderSourceAccessConfiguration {
    /// The type of authentication protocol, VPC components, or virtual host for your event source. For valid values, refer to the AWS documentation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
    /// The URI for this configuration.  For type VPC_SUBNET the value should be subnet:subnet_id where subnet_id is the value you would find in an aws_subnet resource's id attribute.  For type VPC_SECURITY_GROUP the value should be security_group:security_group_id where security_group_id is the value you would find in an aws_security_group resource's id attribute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub uri: Option<String>,
}

/// ProviderConfigReference specifies how the provider that will be used to
/// create, observe, update, and delete this managed resource should be
/// configured.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingProviderConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingProviderConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingProviderConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingProviderConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingProviderConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingProviderConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingProviderConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// PublishConnectionDetailsTo specifies the connection secret config which
/// contains a name, metadata and a reference to secret store config to
/// which any connection details for this managed resource should be written.
/// Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingPublishConnectionDetailsTo {
    /// SecretStoreConfigRef specifies which secret store config should be used
    /// for this ConnectionSecret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configRef")]
    pub config_ref: Option<EventSourceMappingPublishConnectionDetailsToConfigRef>,
    /// Metadata is the metadata for connection secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metadata: Option<EventSourceMappingPublishConnectionDetailsToMetadata>,
    /// Name is the name of the connection secret.
    pub name: String,
}

/// SecretStoreConfigRef specifies which secret store config should be used
/// for this ConnectionSecret.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingPublishConnectionDetailsToConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<EventSourceMappingPublishConnectionDetailsToConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingPublishConnectionDetailsToConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<EventSourceMappingPublishConnectionDetailsToConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<EventSourceMappingPublishConnectionDetailsToConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingPublishConnectionDetailsToConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EventSourceMappingPublishConnectionDetailsToConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Metadata is the metadata for connection secret.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingPublishConnectionDetailsToMetadata {
    /// Annotations are the annotations to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.annotations".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<HashMap<String, String>>,
    /// Labels are the labels/tags to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.labels".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<HashMap<String, String>>,
    /// Type is the SecretType for the connection secret.
    /// - Only valid for Kubernetes Secret Stores.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// WriteConnectionSecretToReference specifies the namespace and name of a
/// Secret to which any connection details for this managed resource should
/// be written. Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
/// This field is planned to be replaced in a future release in favor of
/// PublishConnectionDetailsTo. Currently, both could be set independently
/// and connection details would be published to both without affecting
/// each other.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingWriteConnectionSecretToRef {
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// EventSourceMappingStatus defines the observed state of EventSourceMapping.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatus {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "atProvider")]
    pub at_provider: Option<EventSourceMappingStatusAtProvider>,
    /// Conditions of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<Condition>>,
    /// ObservedGeneration is the latest metadata.generation
    /// which resulted in either a ready state, or stalled due to error
    /// it can not recover from without human intervention.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    pub observed_generation: Option<i64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProvider {
    /// Additional configuration block for Amazon Managed Kafka sources. Incompatible with "self_managed_event_source" and "self_managed_kafka_event_source_config". Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "amazonManagedKafkaEventSourceConfig")]
    pub amazon_managed_kafka_event_source_config: Option<EventSourceMappingStatusAtProviderAmazonManagedKafkaEventSourceConfig>,
    /// The event source mapping ARN.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub arn: Option<String>,
    /// The largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to 100 for DynamoDB, Kinesis, MQ and MSK, 10 for SQS.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "batchSize")]
    pub batch_size: Option<f64>,
    /// If the function returns an error, split the batch in two and retry. Only available for stream sources (DynamoDB and Kinesis). Defaults to false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bisectBatchOnFunctionError")]
    pub bisect_batch_on_function_error: Option<bool>,
    /// An Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationConfig")]
    pub destination_config: Option<EventSourceMappingStatusAtProviderDestinationConfig>,
    /// Configuration settings for a DocumentDB event source. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "documentDbEventSourceConfig")]
    pub document_db_event_source_config: Option<EventSourceMappingStatusAtProviderDocumentDbEventSourceConfig>,
    /// Determines if the mapping will be enabled on creation. Defaults to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub enabled: Option<bool>,
    /// The event source ARN - this is required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream.  It is incompatible with a Self Managed Kafka source.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "eventSourceArn")]
    pub event_source_arn: Option<String>,
    /// The criteria to use for event filtering Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "filterCriteria")]
    pub filter_criteria: Option<EventSourceMappingStatusAtProviderFilterCriteria>,
    /// The ARN of the Lambda function the event source mapping is sending events to. (Note: this is a computed value that differs from function_name above.)
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionArn")]
    pub function_arn: Option<String>,
    /// The name or the ARN of the Lambda function that will be subscribing to events.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionName")]
    pub function_name: Option<String>,
    /// A list of current response type enums applied to the event source mapping for AWS Lambda checkpointing. Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: ReportBatchItemFailures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "functionResponseTypes")]
    pub function_response_types: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub id: Option<String>,
    /// The ARN of the Key Management Service (KMS) customer managed key that Lambda uses to encrypt your function's filter criteria.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArn")]
    pub kms_key_arn: Option<String>,
    /// The date this resource was last modified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastModified")]
    pub last_modified: Option<String>,
    /// The result of the last AWS Lambda invocation of your Lambda function.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastProcessingResult")]
    pub last_processing_result: Option<String>,
    /// The maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer (or accumulate in the case of an SQS queue event source) until either maximum_batching_window_in_seconds expires or batch_size has been met. For streaming event sources, defaults to as soon as records are available in the stream. If the batch it reads from the stream/queue only has one record in it, Lambda only sends one record to the function. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBatchingWindowInSeconds")]
    pub maximum_batching_window_in_seconds: Option<f64>,
    /// The maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRecordAgeInSeconds")]
    pub maximum_record_age_in_seconds: Option<f64>,
    /// The maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumRetryAttempts")]
    pub maximum_retry_attempts: Option<f64>,
    /// CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metricsConfig")]
    pub metrics_config: Option<EventSourceMappingStatusAtProviderMetricsConfig>,
    /// The number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parallelizationFactor")]
    pub parallelization_factor: Option<f64>,
    /// Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "provisionedPollerConfig")]
    pub provisioned_poller_config: Option<EventSourceMappingStatusAtProviderProvisionedPollerConfig>,
    /// The name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub queues: Option<Vec<String>>,
    /// Scaling configuration of the event source. Only available for SQS queues. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scalingConfig")]
    pub scaling_config: Option<EventSourceMappingStatusAtProviderScalingConfig>,
    /// For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include source_access_configuration. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfManagedEventSource")]
    pub self_managed_event_source: Option<EventSourceMappingStatusAtProviderSelfManagedEventSource>,
    /// Additional configuration block for Self Managed Kafka sources. Incompatible with "event_source_arn" and "amazon_managed_kafka_event_source_config". Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfManagedKafkaEventSourceConfig")]
    pub self_managed_kafka_event_source_config: Option<EventSourceMappingStatusAtProviderSelfManagedKafkaEventSourceConfig>,
    /// :  For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include self_managed_event_source. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceAccessConfiguration")]
    pub source_access_configuration: Option<Vec<EventSourceMappingStatusAtProviderSourceAccessConfiguration>>,
    /// The position in the stream where AWS Lambda should start reading. Must be one of AT_TIMESTAMP (Kinesis only), LATEST or TRIM_HORIZON if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the AWS DynamoDB Streams API Reference and AWS Kinesis API Reference.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startingPosition")]
    pub starting_position: Option<String>,
    /// A timestamp in RFC3339 format of the data record which to start reading when using starting_position set to AT_TIMESTAMP. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startingPositionTimestamp")]
    pub starting_position_timestamp: Option<String>,
    /// The state of the event source mapping.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub state: Option<String>,
    /// The reason the event source mapping is in its current state.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "stateTransitionReason")]
    pub state_transition_reason: Option<String>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub tags: Option<HashMap<String, String>>,
    /// A map of tags assigned to the resource, including those inherited from the provider default_tags configuration block.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tagsAll")]
    pub tags_all: Option<HashMap<String, String>>,
    /// The name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub topics: Option<Vec<String>>,
    /// The duration in seconds of a processing window for AWS Lambda streaming analytics. The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tumblingWindowInSeconds")]
    pub tumbling_window_in_seconds: Option<f64>,
    /// The UUID of the created event source mapping.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub uuid: Option<String>,
}

/// Additional configuration block for Amazon Managed Kafka sources. Incompatible with "self_managed_event_source" and "self_managed_kafka_event_source_config". Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderAmazonManagedKafkaEventSourceConfig {
    /// A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See AmazonManagedKafkaEventSourceConfig Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerGroupId")]
    pub consumer_group_id: Option<String>,
}

/// An Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderDestinationConfig {
    /// The destination configuration for failed invocations. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onFailure")]
    pub on_failure: Option<EventSourceMappingStatusAtProviderDestinationConfigOnFailure>,
}

/// The destination configuration for failed invocations. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderDestinationConfigOnFailure {
    /// The Amazon Resource Name (ARN) of the destination resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationArn")]
    pub destination_arn: Option<String>,
}

/// Configuration settings for a DocumentDB event source. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderDocumentDbEventSourceConfig {
    /// The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "collectionName")]
    pub collection_name: Option<String>,
    /// The name of the database to consume within the DocumentDB cluster.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "databaseName")]
    pub database_name: Option<String>,
    /// Determines what DocumentDB sends to your event stream during document update operations. If set to UpdateLookup, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes. Valid values: UpdateLookup, Default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fullDocument")]
    pub full_document: Option<String>,
}

/// The criteria to use for event filtering Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderFilterCriteria {
    /// A set of up to 5 filter. If an event satisfies at least one, Lambda sends the event to the function or adds it to the next batch. Detailed below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub filter: Option<Vec<EventSourceMappingStatusAtProviderFilterCriteriaFilter>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderFilterCriteriaFilter {
    /// A filter pattern up to 4096 characters. See Filter Rule Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pattern: Option<String>,
}

/// CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderMetricsConfig {
    /// A list containing the metrics to be produced by the event source mapping. Valid values: EventCount.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metrics: Option<Vec<String>>,
}

/// Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderProvisionedPollerConfig {
    /// The maximum number of event pollers this event source can scale up to. The range is between 1 and 2000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumPollers")]
    pub maximum_pollers: Option<f64>,
    /// The minimum number of event pollers this event source can scale down to. The range is between 1 and 200.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "minimumPollers")]
    pub minimum_pollers: Option<f64>,
}

/// Scaling configuration of the event source. Only available for SQS queues. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderScalingConfig {
    /// Limits the number of concurrent instances that the Amazon SQS event source can invoke. Must be greater than or equal to 2. See Configuring maximum concurrency for Amazon SQS event sources. You need to raise a Service Quota Ticket to increase the concurrency beyond 1000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumConcurrency")]
    pub maximum_concurrency: Option<f64>,
}

/// For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include source_access_configuration. Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderSelfManagedEventSource {
    /// A map of endpoints for the self managed source.  For Kafka self-managed sources, the key should be KAFKA_BOOTSTRAP_SERVERS and the value should be a string with a comma separated list of broker endpoints.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub endpoints: Option<HashMap<String, String>>,
}

/// Additional configuration block for Self Managed Kafka sources. Incompatible with "event_source_arn" and "amazon_managed_kafka_event_source_config". Detailed below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderSelfManagedKafkaEventSourceConfig {
    /// A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See SelfManagedKafkaEventSourceConfig Syntax.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "consumerGroupId")]
    pub consumer_group_id: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct EventSourceMappingStatusAtProviderSourceAccessConfiguration {
    /// The type of authentication protocol, VPC components, or virtual host for your event source. For valid values, refer to the AWS documentation.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
    /// The URI for this configuration.  For type VPC_SUBNET the value should be subnet:subnet_id where subnet_id is the value you would find in an aws_subnet resource's id attribute.  For type VPC_SECURITY_GROUP the value should be security_group:security_group_id where security_group_id is the value you would find in an aws_security_group resource's id attribute.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub uri: Option<String>,
}

