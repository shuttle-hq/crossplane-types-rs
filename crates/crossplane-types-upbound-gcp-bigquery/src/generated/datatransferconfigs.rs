// WARNING: generated by kopium - manual changes will be overwritten
// kopium version: 0.21.2

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use schemars::JsonSchema;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::HashMap;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// DataTransferConfigSpec defines the desired state of DataTransferConfig
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, JsonSchema)]
#[kube(group = "bigquery.gcp.upbound.io", version = "v1beta2", kind = "DataTransferConfig", plural = "datatransferconfigs")]
#[kube(status = "DataTransferConfigStatus")]
pub struct DataTransferConfigSpec {
    /// DeletionPolicy specifies what will happen to the underlying external
    /// when this managed resource is deleted - either "Delete" or "Orphan" the
    /// external resource.
    /// This field is planned to be deprecated in favor of the ManagementPolicies
    /// field in a future release. Currently, both could be set independently and
    /// non-default values would be honored if the feature flag is enabled.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionPolicy")]
    pub deletion_policy: Option<DataTransferConfigDeletionPolicy>,
    #[serde(rename = "forProvider")]
    pub for_provider: DataTransferConfigForProvider,
    /// THIS IS A BETA FIELD. It will be honored
    /// unless the Management Policies feature flag is disabled.
    /// InitProvider holds the same fields as ForProvider, with the exception
    /// of Identifier and other resource reference fields. The fields that are
    /// in InitProvider are merged into ForProvider when the resource is created.
    /// The same fields are also added to the terraform ignore_changes hook, to
    /// avoid updating them after creation. This is useful for fields that are
    /// required on creation, but we do not desire to update them after creation,
    /// for example because of an external controller is managing them, like an
    /// autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initProvider")]
    pub init_provider: Option<DataTransferConfigInitProvider>,
    /// THIS IS A BETA FIELD. It is on by default but can be opted out
    /// through a Crossplane feature flag.
    /// ManagementPolicies specify the array of actions Crossplane is allowed to
    /// take on the managed and external resources.
    /// This field is planned to replace the DeletionPolicy field in a future
    /// release. Currently, both could be set independently and non-default
    /// values would be honored if the feature flag is enabled. If both are
    /// custom, the DeletionPolicy field will be ignored.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    /// and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managementPolicies")]
    pub management_policies: Option<Vec<String>>,
    /// ProviderConfigReference specifies how the provider that will be used to
    /// create, observe, update, and delete this managed resource should be
    /// configured.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providerConfigRef")]
    pub provider_config_ref: Option<DataTransferConfigProviderConfigRef>,
    /// PublishConnectionDetailsTo specifies the connection secret config which
    /// contains a name, metadata and a reference to secret store config to
    /// which any connection details for this managed resource should be written.
    /// Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "publishConnectionDetailsTo")]
    pub publish_connection_details_to: Option<DataTransferConfigPublishConnectionDetailsTo>,
    /// WriteConnectionSecretToReference specifies the namespace and name of a
    /// Secret to which any connection details for this managed resource should
    /// be written. Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    /// This field is planned to be replaced in a future release in favor of
    /// PublishConnectionDetailsTo. Currently, both could be set independently
    /// and connection details would be published to both without affecting
    /// each other.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeConnectionSecretToRef")]
    pub write_connection_secret_to_ref: Option<DataTransferConfigWriteConnectionSecretToRef>,
}

/// DataTransferConfigSpec defines the desired state of DataTransferConfig
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigDeletionPolicy {
    Orphan,
    Delete,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProvider {
    /// The number of days to look back to automatically refresh the data.
    /// For example, if dataRefreshWindowDays = 10, then every day BigQuery
    /// reingests data for [today-10, today-1], rather than ingesting data for
    /// just [today-1]. Only valid if the data source supports the feature.
    /// Set the value to 0 to use the default value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataRefreshWindowDays")]
    pub data_refresh_window_days: Option<f64>,
    /// The data source id. Cannot be changed once the transfer config is created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceId")]
    pub data_source_id: Option<String>,
    /// The BigQuery target dataset id.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetId")]
    pub destination_dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate destinationDatasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetIdRef")]
    pub destination_dataset_id_ref: Option<DataTransferConfigForProviderDestinationDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate destinationDatasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetIdSelector")]
    pub destination_dataset_id_selector: Option<DataTransferConfigForProviderDestinationDatasetIdSelector>,
    /// When set to true, no runs are scheduled for a given transfer.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub disabled: Option<bool>,
    /// The user specified display name for the transfer config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "displayName")]
    pub display_name: Option<String>,
    /// Email notifications will be sent according to these preferences to the
    /// email address of the user who owns this transfer config.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "emailPreferences")]
    pub email_preferences: Option<DataTransferConfigForProviderEmailPreferences>,
    /// The geographic location where the transfer config should reside.
    /// Examples: US, EU, asia-northeast1. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub location: Option<String>,
    /// Pub/Sub topic where notifications will be sent after transfer runs
    /// associated with this transfer config finish.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "notificationPubsubTopic")]
    pub notification_pubsub_topic: Option<String>,
    /// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer'
    /// section for each data source. For example the parameters for Cloud Storage transfers are listed here:
    /// https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    /// NOTE : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub params: Option<HashMap<String, String>>,
    /// The ID of the project in which the resource belongs.
    /// If it is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub project: Option<String>,
    /// Data transfer schedule. If the data source does not support a custom
    /// schedule, this should be empty. If it is empty, the default value for
    /// the data source will be used. The specified times are in UTC. Examples
    /// of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
    /// jun 13:15, and first sunday of quarter 00:00. See more explanation
    /// about the format here:
    /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
    /// NOTE: The minimum interval time between recurring transfers depends
    /// on the data source; refer to the documentation for your data source.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schedule: Option<String>,
    /// Options customizing the data transfer schedule.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scheduleOptions")]
    pub schedule_options: Option<DataTransferConfigForProviderScheduleOptions>,
    /// Different parameters are configured primarily using the the params field on this
    /// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
    /// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
    /// in the params map in the api request.
    /// Credentials may not be specified in both locations and will cause an error. Changing from one location
    /// to a different credential configuration in the config will require an apply to update state.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sensitiveParams")]
    pub sensitive_params: Option<DataTransferConfigForProviderSensitiveParams>,
    /// Service account email. If this field is set, transfer config will
    /// be created with this service account credentials. It requires that
    /// requesting user calling this API has permissions to act as this service account.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceAccountName")]
    pub service_account_name: Option<String>,
}

/// Reference to a Dataset in bigquery to populate destinationDatasetId.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderDestinationDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<DataTransferConfigForProviderDestinationDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderDestinationDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<DataTransferConfigForProviderDestinationDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<DataTransferConfigForProviderDestinationDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigForProviderDestinationDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigForProviderDestinationDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate destinationDatasetId.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderDestinationDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<DataTransferConfigForProviderDestinationDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderDestinationDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<DataTransferConfigForProviderDestinationDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<DataTransferConfigForProviderDestinationDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigForProviderDestinationDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigForProviderDestinationDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Email notifications will be sent according to these preferences to the
/// email address of the user who owns this transfer config.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderEmailPreferences {
    /// If true, email notifications will be sent on transfer run failures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableFailureEmail")]
    pub enable_failure_email: Option<bool>,
}

/// Options customizing the data transfer schedule.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderScheduleOptions {
    /// If true, automatic scheduling of data transfer runs for this
    /// configuration will be disabled. The runs can be started on ad-hoc
    /// basis using transferConfigs.startManualRuns API. When automatic
    /// scheduling is disabled, the TransferConfig.schedule field will
    /// be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableAutoScheduling")]
    pub disable_auto_scheduling: Option<bool>,
    /// Defines time to stop scheduling transfer runs. A transfer run cannot be
    /// scheduled at or after the end time. The end time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endTime")]
    pub end_time: Option<String>,
    /// Specifies time to start scheduling transfer runs. The first run will be
    /// scheduled at or after the start time according to a recurrence pattern
    /// defined in the schedule string. The start time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startTime")]
    pub start_time: Option<String>,
}

/// Different parameters are configured primarily using the the params field on this
/// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
/// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
/// in the params map in the api request.
/// Credentials may not be specified in both locations and will cause an error. Changing from one location
/// to a different credential configuration in the config will require an apply to update state.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderSensitiveParams {
    /// The Secret Access Key of the AWS account transferring data from.
    /// Note: This property is sensitive and will not be displayed in the plan.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretAccessKeySecretRef")]
    pub secret_access_key_secret_ref: Option<DataTransferConfigForProviderSensitiveParamsSecretAccessKeySecretRef>,
}

/// The Secret Access Key of the AWS account transferring data from.
/// Note: This property is sensitive and will not be displayed in the plan.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigForProviderSensitiveParamsSecretAccessKeySecretRef {
    /// The key to select.
    pub key: String,
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// THIS IS A BETA FIELD. It will be honored
/// unless the Management Policies feature flag is disabled.
/// InitProvider holds the same fields as ForProvider, with the exception
/// of Identifier and other resource reference fields. The fields that are
/// in InitProvider are merged into ForProvider when the resource is created.
/// The same fields are also added to the terraform ignore_changes hook, to
/// avoid updating them after creation. This is useful for fields that are
/// required on creation, but we do not desire to update them after creation,
/// for example because of an external controller is managing them, like an
/// autoscaler.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProvider {
    /// The number of days to look back to automatically refresh the data.
    /// For example, if dataRefreshWindowDays = 10, then every day BigQuery
    /// reingests data for [today-10, today-1], rather than ingesting data for
    /// just [today-1]. Only valid if the data source supports the feature.
    /// Set the value to 0 to use the default value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataRefreshWindowDays")]
    pub data_refresh_window_days: Option<f64>,
    /// The data source id. Cannot be changed once the transfer config is created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceId")]
    pub data_source_id: Option<String>,
    /// The BigQuery target dataset id.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetId")]
    pub destination_dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate destinationDatasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetIdRef")]
    pub destination_dataset_id_ref: Option<DataTransferConfigInitProviderDestinationDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate destinationDatasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetIdSelector")]
    pub destination_dataset_id_selector: Option<DataTransferConfigInitProviderDestinationDatasetIdSelector>,
    /// When set to true, no runs are scheduled for a given transfer.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub disabled: Option<bool>,
    /// The user specified display name for the transfer config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "displayName")]
    pub display_name: Option<String>,
    /// Email notifications will be sent according to these preferences to the
    /// email address of the user who owns this transfer config.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "emailPreferences")]
    pub email_preferences: Option<DataTransferConfigInitProviderEmailPreferences>,
    /// The geographic location where the transfer config should reside.
    /// Examples: US, EU, asia-northeast1. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub location: Option<String>,
    /// Pub/Sub topic where notifications will be sent after transfer runs
    /// associated with this transfer config finish.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "notificationPubsubTopic")]
    pub notification_pubsub_topic: Option<String>,
    /// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer'
    /// section for each data source. For example the parameters for Cloud Storage transfers are listed here:
    /// https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    /// NOTE : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub params: Option<HashMap<String, String>>,
    /// The ID of the project in which the resource belongs.
    /// If it is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub project: Option<String>,
    /// Data transfer schedule. If the data source does not support a custom
    /// schedule, this should be empty. If it is empty, the default value for
    /// the data source will be used. The specified times are in UTC. Examples
    /// of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
    /// jun 13:15, and first sunday of quarter 00:00. See more explanation
    /// about the format here:
    /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
    /// NOTE: The minimum interval time between recurring transfers depends
    /// on the data source; refer to the documentation for your data source.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schedule: Option<String>,
    /// Options customizing the data transfer schedule.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scheduleOptions")]
    pub schedule_options: Option<DataTransferConfigInitProviderScheduleOptions>,
    /// Different parameters are configured primarily using the the params field on this
    /// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
    /// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
    /// in the params map in the api request.
    /// Credentials may not be specified in both locations and will cause an error. Changing from one location
    /// to a different credential configuration in the config will require an apply to update state.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sensitiveParams")]
    pub sensitive_params: Option<DataTransferConfigInitProviderSensitiveParams>,
    /// Service account email. If this field is set, transfer config will
    /// be created with this service account credentials. It requires that
    /// requesting user calling this API has permissions to act as this service account.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceAccountName")]
    pub service_account_name: Option<String>,
}

/// Reference to a Dataset in bigquery to populate destinationDatasetId.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderDestinationDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<DataTransferConfigInitProviderDestinationDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderDestinationDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<DataTransferConfigInitProviderDestinationDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<DataTransferConfigInitProviderDestinationDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigInitProviderDestinationDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigInitProviderDestinationDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate destinationDatasetId.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderDestinationDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<DataTransferConfigInitProviderDestinationDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderDestinationDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<DataTransferConfigInitProviderDestinationDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<DataTransferConfigInitProviderDestinationDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigInitProviderDestinationDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigInitProviderDestinationDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Email notifications will be sent according to these preferences to the
/// email address of the user who owns this transfer config.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderEmailPreferences {
    /// If true, email notifications will be sent on transfer run failures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableFailureEmail")]
    pub enable_failure_email: Option<bool>,
}

/// Options customizing the data transfer schedule.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderScheduleOptions {
    /// If true, automatic scheduling of data transfer runs for this
    /// configuration will be disabled. The runs can be started on ad-hoc
    /// basis using transferConfigs.startManualRuns API. When automatic
    /// scheduling is disabled, the TransferConfig.schedule field will
    /// be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableAutoScheduling")]
    pub disable_auto_scheduling: Option<bool>,
    /// Defines time to stop scheduling transfer runs. A transfer run cannot be
    /// scheduled at or after the end time. The end time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endTime")]
    pub end_time: Option<String>,
    /// Specifies time to start scheduling transfer runs. The first run will be
    /// scheduled at or after the start time according to a recurrence pattern
    /// defined in the schedule string. The start time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startTime")]
    pub start_time: Option<String>,
}

/// Different parameters are configured primarily using the the params field on this
/// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
/// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
/// in the params map in the api request.
/// Credentials may not be specified in both locations and will cause an error. Changing from one location
/// to a different credential configuration in the config will require an apply to update state.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderSensitiveParams {
    /// The Secret Access Key of the AWS account transferring data from.
    /// Note: This property is sensitive and will not be displayed in the plan.
    #[serde(rename = "secretAccessKeySecretRef")]
    pub secret_access_key_secret_ref: DataTransferConfigInitProviderSensitiveParamsSecretAccessKeySecretRef,
}

/// The Secret Access Key of the AWS account transferring data from.
/// Note: This property is sensitive and will not be displayed in the plan.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigInitProviderSensitiveParamsSecretAccessKeySecretRef {
    /// The key to select.
    pub key: String,
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// ProviderConfigReference specifies how the provider that will be used to
/// create, observe, update, and delete this managed resource should be
/// configured.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigProviderConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<DataTransferConfigProviderConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigProviderConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<DataTransferConfigProviderConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<DataTransferConfigProviderConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigProviderConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigProviderConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// PublishConnectionDetailsTo specifies the connection secret config which
/// contains a name, metadata and a reference to secret store config to
/// which any connection details for this managed resource should be written.
/// Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigPublishConnectionDetailsTo {
    /// SecretStoreConfigRef specifies which secret store config should be used
    /// for this ConnectionSecret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configRef")]
    pub config_ref: Option<DataTransferConfigPublishConnectionDetailsToConfigRef>,
    /// Metadata is the metadata for connection secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metadata: Option<DataTransferConfigPublishConnectionDetailsToMetadata>,
    /// Name is the name of the connection secret.
    pub name: String,
}

/// SecretStoreConfigRef specifies which secret store config should be used
/// for this ConnectionSecret.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigPublishConnectionDetailsToConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<DataTransferConfigPublishConnectionDetailsToConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigPublishConnectionDetailsToConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<DataTransferConfigPublishConnectionDetailsToConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<DataTransferConfigPublishConnectionDetailsToConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigPublishConnectionDetailsToConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum DataTransferConfigPublishConnectionDetailsToConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Metadata is the metadata for connection secret.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigPublishConnectionDetailsToMetadata {
    /// Annotations are the annotations to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.annotations".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<HashMap<String, String>>,
    /// Labels are the labels/tags to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.labels".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<HashMap<String, String>>,
    /// Type is the SecretType for the connection secret.
    /// - Only valid for Kubernetes Secret Stores.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// WriteConnectionSecretToReference specifies the namespace and name of a
/// Secret to which any connection details for this managed resource should
/// be written. Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
/// This field is planned to be replaced in a future release in favor of
/// PublishConnectionDetailsTo. Currently, both could be set independently
/// and connection details would be published to both without affecting
/// each other.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigWriteConnectionSecretToRef {
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// DataTransferConfigStatus defines the observed state of DataTransferConfig.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigStatus {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "atProvider")]
    pub at_provider: Option<DataTransferConfigStatusAtProvider>,
    /// Conditions of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<Condition>>,
    /// ObservedGeneration is the latest metadata.generation
    /// which resulted in either a ready state, or stalled due to error
    /// it can not recover from without human intervention.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    pub observed_generation: Option<i64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigStatusAtProvider {
    /// The number of days to look back to automatically refresh the data.
    /// For example, if dataRefreshWindowDays = 10, then every day BigQuery
    /// reingests data for [today-10, today-1], rather than ingesting data for
    /// just [today-1]. Only valid if the data source supports the feature.
    /// Set the value to 0 to use the default value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataRefreshWindowDays")]
    pub data_refresh_window_days: Option<f64>,
    /// The data source id. Cannot be changed once the transfer config is created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "dataSourceId")]
    pub data_source_id: Option<String>,
    /// The BigQuery target dataset id.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationDatasetId")]
    pub destination_dataset_id: Option<String>,
    /// When set to true, no runs are scheduled for a given transfer.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub disabled: Option<bool>,
    /// The user specified display name for the transfer config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "displayName")]
    pub display_name: Option<String>,
    /// Email notifications will be sent according to these preferences to the
    /// email address of the user who owns this transfer config.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "emailPreferences")]
    pub email_preferences: Option<DataTransferConfigStatusAtProviderEmailPreferences>,
    /// an identifier for the resource with format {{name}}
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub id: Option<String>,
    /// The geographic location where the transfer config should reside.
    /// Examples: US, EU, asia-northeast1. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub location: Option<String>,
    /// The resource name of the transfer config. Transfer config names have the
    /// form projects/{projectId}/locations/{location}/transferConfigs/{configId}
    /// or projects/{projectId}/transferConfigs/{configId},
    /// where configId is usually a uuid, but this is not required.
    /// The name is ignored when creating a transfer config.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Pub/Sub topic where notifications will be sent after transfer runs
    /// associated with this transfer config finish.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "notificationPubsubTopic")]
    pub notification_pubsub_topic: Option<String>,
    /// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer'
    /// section for each data source. For example the parameters for Cloud Storage transfers are listed here:
    /// https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
    /// NOTE : If you are attempting to update a parameter that cannot be updated (due to api limitations) please force recreation of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub params: Option<HashMap<String, String>>,
    /// The ID of the project in which the resource belongs.
    /// If it is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub project: Option<String>,
    /// Data transfer schedule. If the data source does not support a custom
    /// schedule, this should be empty. If it is empty, the default value for
    /// the data source will be used. The specified times are in UTC. Examples
    /// of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
    /// jun 13:15, and first sunday of quarter 00:00. See more explanation
    /// about the format here:
    /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
    /// NOTE: The minimum interval time between recurring transfers depends
    /// on the data source; refer to the documentation for your data source.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schedule: Option<String>,
    /// Options customizing the data transfer schedule.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scheduleOptions")]
    pub schedule_options: Option<DataTransferConfigStatusAtProviderScheduleOptions>,
    /// Different parameters are configured primarily using the the params field on this
    /// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
    /// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
    /// in the params map in the api request.
    /// Credentials may not be specified in both locations and will cause an error. Changing from one location
    /// to a different credential configuration in the config will require an apply to update state.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sensitiveParams")]
    pub sensitive_params: Option<DataTransferConfigStatusAtProviderSensitiveParams>,
    /// Service account email. If this field is set, transfer config will
    /// be created with this service account credentials. It requires that
    /// requesting user calling this API has permissions to act as this service account.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "serviceAccountName")]
    pub service_account_name: Option<String>,
}

/// Email notifications will be sent according to these preferences to the
/// email address of the user who owns this transfer config.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigStatusAtProviderEmailPreferences {
    /// If true, email notifications will be sent on transfer run failures.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableFailureEmail")]
    pub enable_failure_email: Option<bool>,
}

/// Options customizing the data transfer schedule.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigStatusAtProviderScheduleOptions {
    /// If true, automatic scheduling of data transfer runs for this
    /// configuration will be disabled. The runs can be started on ad-hoc
    /// basis using transferConfigs.startManualRuns API. When automatic
    /// scheduling is disabled, the TransferConfig.schedule field will
    /// be ignored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "disableAutoScheduling")]
    pub disable_auto_scheduling: Option<bool>,
    /// Defines time to stop scheduling transfer runs. A transfer run cannot be
    /// scheduled at or after the end time. The end time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "endTime")]
    pub end_time: Option<String>,
    /// Specifies time to start scheduling transfer runs. The first run will be
    /// scheduled at or after the start time according to a recurrence pattern
    /// defined in the schedule string. The start time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "startTime")]
    pub start_time: Option<String>,
}

/// Different parameters are configured primarily using the the params field on this
/// resource. This block contains the parameters which contain secrets or passwords so that they can be marked
/// sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
/// in the params map in the api request.
/// Credentials may not be specified in both locations and will cause an error. Changing from one location
/// to a different credential configuration in the config will require an apply to update state.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigStatusAtProviderSensitiveParams {
    /// The Secret Access Key of the AWS account transferring data from.
    /// Note: This property is sensitive and will not be displayed in the plan.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "secretAccessKeySecretRef")]
    pub secret_access_key_secret_ref: Option<DataTransferConfigStatusAtProviderSensitiveParamsSecretAccessKeySecretRef>,
}

/// The Secret Access Key of the AWS account transferring data from.
/// Note: This property is sensitive and will not be displayed in the plan.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct DataTransferConfigStatusAtProviderSensitiveParamsSecretAccessKeySecretRef {
    /// The key to select.
    pub key: String,
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

