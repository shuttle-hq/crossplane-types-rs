// WARNING: generated by kopium - manual changes will be overwritten
// kopium version: 0.21.2

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use schemars::JsonSchema;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::HashMap;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// TableSpec defines the desired state of Table
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, JsonSchema)]
#[kube(group = "bigquery.gcp.upbound.io", version = "v1beta2", kind = "Table", plural = "tables")]
#[kube(status = "TableStatus")]
pub struct TableSpec {
    /// DeletionPolicy specifies what will happen to the underlying external
    /// when this managed resource is deleted - either "Delete" or "Orphan" the
    /// external resource.
    /// This field is planned to be deprecated in favor of the ManagementPolicies
    /// field in a future release. Currently, both could be set independently and
    /// non-default values would be honored if the feature flag is enabled.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionPolicy")]
    pub deletion_policy: Option<TableDeletionPolicy>,
    #[serde(rename = "forProvider")]
    pub for_provider: TableForProvider,
    /// THIS IS A BETA FIELD. It will be honored
    /// unless the Management Policies feature flag is disabled.
    /// InitProvider holds the same fields as ForProvider, with the exception
    /// of Identifier and other resource reference fields. The fields that are
    /// in InitProvider are merged into ForProvider when the resource is created.
    /// The same fields are also added to the terraform ignore_changes hook, to
    /// avoid updating them after creation. This is useful for fields that are
    /// required on creation, but we do not desire to update them after creation,
    /// for example because of an external controller is managing them, like an
    /// autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initProvider")]
    pub init_provider: Option<TableInitProvider>,
    /// THIS IS A BETA FIELD. It is on by default but can be opted out
    /// through a Crossplane feature flag.
    /// ManagementPolicies specify the array of actions Crossplane is allowed to
    /// take on the managed and external resources.
    /// This field is planned to replace the DeletionPolicy field in a future
    /// release. Currently, both could be set independently and non-default
    /// values would be honored if the feature flag is enabled. If both are
    /// custom, the DeletionPolicy field will be ignored.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    /// and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managementPolicies")]
    pub management_policies: Option<Vec<String>>,
    /// ProviderConfigReference specifies how the provider that will be used to
    /// create, observe, update, and delete this managed resource should be
    /// configured.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providerConfigRef")]
    pub provider_config_ref: Option<TableProviderConfigRef>,
    /// PublishConnectionDetailsTo specifies the connection secret config which
    /// contains a name, metadata and a reference to secret store config to
    /// which any connection details for this managed resource should be written.
    /// Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "publishConnectionDetailsTo")]
    pub publish_connection_details_to: Option<TablePublishConnectionDetailsTo>,
    /// WriteConnectionSecretToReference specifies the namespace and name of a
    /// Secret to which any connection details for this managed resource should
    /// be written. Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    /// This field is planned to be replaced in a future release in favor of
    /// PublishConnectionDetailsTo. Currently, both could be set independently
    /// and connection details would be published to both without affecting
    /// each other.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeConnectionSecretToRef")]
    pub write_connection_secret_to_ref: Option<TableWriteConnectionSecretToRef>,
}

/// TableSpec defines the desired state of Table
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableDeletionPolicy {
    Orphan,
    Delete,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProvider {
    /// If set to true, it allows table
    /// deletion when there are still resource tags attached. The default value is
    /// false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowResourceTagsOnDeletion")]
    pub allow_resource_tags_on_deletion: Option<bool>,
    /// Specifies column names to use for data clustering.
    /// Up to four top-level columns are allowed, and should be specified in
    /// descending priority order.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub clustering: Option<Vec<String>>,
    /// The dataset ID to create the table in.
    /// Changing this forces a new resource to be created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    pub dataset_id_ref: Option<TableForProviderDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    pub dataset_id_selector: Option<TableForProviderDatasetIdSelector>,
    /// When the field is set to false, deleting the table is allowed..
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionProtection")]
    pub deletion_protection: Option<bool>,
    /// The field description.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,
    /// Specifies how the table should be encrypted.
    /// If left blank, the table will be encrypted with a Google-managed key; that process
    /// is transparent to the user.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "encryptionConfiguration")]
    pub encryption_configuration: Option<TableForProviderEncryptionConfiguration>,
    /// The time when this table expires, in
    /// milliseconds since the epoch. If not present, the table will persist
    /// indefinitely. Expired tables will be deleted and their storage
    /// reclaimed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationTime")]
    pub expiration_time: Option<f64>,
    /// Describes the data format,
    /// location, and other properties of a table stored outside of BigQuery.
    /// By defining these properties, the data source can then be queried as
    /// if it were a standard BigQuery table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalDataConfiguration")]
    pub external_data_configuration: Option<TableForProviderExternalDataConfiguration>,
    /// A descriptive name for the table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "friendlyName")]
    pub friendly_name: Option<String>,
    /// A mapping of labels to assign to the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<HashMap<String, String>>,
    /// If specified, configures this table as a materialized view.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "materializedView")]
    pub materialized_view: Option<TableForProviderMaterializedView>,
    /// :  The maximum staleness of data that could be
    /// returned when the table (or stale MV) is queried. Staleness encoded as a
    /// string encoding of SQL IntervalValue
    /// type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxStaleness")]
    pub max_staleness: Option<String>,
    /// The ID of the project in which the resource belongs. If it
    /// is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub project: Option<String>,
    /// If specified, configures range-based
    /// partitioning for this table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "rangePartitioning")]
    pub range_partitioning: Option<TableForProviderRangePartitioning>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// The tags attached to this table. Tag keys are
    /// globally unique. Tag key is expected to be in the namespaced format, for
    /// example "123456789012/environment" where 123456789012 is the ID of the
    /// parent organization or project resource for this tag key. Tag value is
    /// expected to be the short name, for example "Production".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceTags")]
    pub resource_tags: Option<HashMap<String, String>>,
    /// A JSON schema for the table.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schema: Option<String>,
    /// Defines the primary key and foreign keys.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableConstraints")]
    pub table_constraints: Option<TableForProviderTableConstraints>,
    /// Replication info of a table created
    /// using "AS REPLICA" DDL like:
    /// CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableReplicationInfo")]
    pub table_replication_info: Option<TableForProviderTableReplicationInfo>,
    /// If specified, configures time-based
    /// partitioning for this table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timePartitioning")]
    pub time_partitioning: Option<TableForProviderTimePartitioning>,
    /// If specified, configures this table as a view.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub view: Option<TableForProviderView>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<TableForProviderDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<TableForProviderDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<TableForProviderDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableForProviderDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableForProviderDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<TableForProviderDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<TableForProviderDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<TableForProviderDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableForProviderDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableForProviderDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Specifies how the table should be encrypted.
/// If left blank, the table will be encrypted with a Google-managed key; that process
/// is transparent to the user.  Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderEncryptionConfiguration {
    /// The self link or full name of a key which should be used to
    /// encrypt this table.  Note that the default bigquery service account will need to have
    /// encrypt/decrypt permissions on this key - you may want to see the
    /// google_bigquery_default_service_account datasource and the
    /// google_kms_crypto_key_iam_binding resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    pub kms_key_name: Option<String>,
}

/// Describes the data format,
/// location, and other properties of a table stored outside of BigQuery.
/// By defining these properties, the data source can then be queried as
/// if it were a standard BigQuery table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfiguration {
    /// - Let BigQuery try to autodetect the schema
    /// and format of the table.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub autodetect: Option<bool>,
    /// Additional options if source_format is set to
    /// "AVRO".  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "avroOptions")]
    pub avro_options: Option<TableForProviderExternalDataConfigurationAvroOptions>,
    /// Additional properties to set if
    /// source_format is set to "BIGTABLE". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bigtableOptions")]
    pub bigtable_options: Option<TableForProviderExternalDataConfigurationBigtableOptions>,
    /// The compression type of the data source.
    /// Valid values are "NONE" or "GZIP".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<String>,
    /// The connection specifying the credentials to be used to read
    /// external storage, such as Azure Blob, Cloud Storage, or S3. The connection_id can have
    /// the form {{project}}.{{location}}.{{connection_id}}
    /// or projects/{{project}}/locations/{{location}}/connections/{{connection_id}}.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionId")]
    pub connection_id: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "CSV". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "csvOptions")]
    pub csv_options: Option<TableForProviderExternalDataConfigurationCsvOptions>,
    /// Specifies how source URIs are interpreted for constructing the file set to load.
    /// By default source URIs are expanded against the underlying storage.
    /// Other options include specifying manifest files. Only applicable to object storage systems. Docs
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSetSpecType")]
    pub file_set_spec_type: Option<String>,
    /// Additional options if
    /// source_format is set to "GOOGLE_SHEETS". Structure is
    /// documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "googleSheetsOptions")]
    pub google_sheets_options: Option<TableForProviderExternalDataConfigurationGoogleSheetsOptions>,
    /// When set, configures hive partitioning
    /// support. Not all storage formats support hive partitioning -- requesting hive
    /// partitioning on an unsupported format will lead to an error, as will providing
    /// an invalid specification. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "hivePartitioningOptions")]
    pub hive_partitioning_options: Option<TableForProviderExternalDataConfigurationHivePartitioningOptions>,
    /// Indicates if BigQuery should
    /// allow extra values that are not represented in the table schema.
    /// If true, the extra values are ignored. If false, records with
    /// extra columns are treated as bad records, and if there are too
    /// many bad records, an invalid error is returned in the job result.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnknownValues")]
    pub ignore_unknown_values: Option<bool>,
    /// Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the JSON source format. Valid values are: GEOJSON.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonExtension")]
    pub json_extension: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "JSON". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonOptions")]
    pub json_options: Option<TableForProviderExternalDataConfigurationJsonOptions>,
    /// The maximum number of bad records that
    /// BigQuery can ignore when reading data.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxBadRecords")]
    pub max_bad_records: Option<f64>,
    /// Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are AUTOMATIC and MANUAL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metadataCacheMode")]
    pub metadata_cache_mode: Option<String>,
    /// Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If object_metadata is set, source_format should be omitted.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "objectMetadata")]
    pub object_metadata: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "PARQUET". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parquetOptions")]
    pub parquet_options: Option<TableForProviderExternalDataConfigurationParquetOptions>,
    /// When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referenceFileSchemaUri")]
    pub reference_file_schema_uri: Option<String>,
    /// A JSON schema for the external table. Schema is required
    /// for CSV and JSON formats if autodetect is not on. Schema is disallowed
    /// for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
    /// ~>NOTE: Because this field expects a JSON string, any changes to the
    /// string will create a diff, even if the JSON itself hasn't changed.
    /// Furthermore drift for this field cannot not be detected because BigQuery
    /// only uses this schema to compute the effective schema for the table, therefore
    /// any changes on the configured value will force the table to be recreated.
    /// This schema is effectively only applied when creating a table from an external
    /// datasource, after creation the computed schema will be stored in
    /// google_bigquery_table.schema
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schema: Option<String>,
    /// The data format. Please see sourceFormat under
    /// ExternalDataConfiguration
    /// in Bigquery's public API documentation for supported formats. To use "GOOGLE_SHEETS"
    /// the scopes must include "https://www.googleapis.com/auth/drive.readonly".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceFormat")]
    pub source_format: Option<String>,
    /// A list of the fully-qualified URIs that point to
    /// your data in Google Cloud.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUris")]
    pub source_uris: Option<Vec<String>>,
}

/// Additional options if source_format is set to
/// "AVRO".  Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationAvroOptions {
    /// If is set to true, indicates whether
    /// to interpret logical types as the corresponding BigQuery data type
    /// (for example, TIMESTAMP), instead of using the raw type (for example, INTEGER).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useAvroLogicalTypes")]
    pub use_avro_logical_types: Option<bool>,
}

/// Additional properties to set if
/// source_format is set to "BIGTABLE". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationBigtableOptions {
    /// A list of column families to expose in the table schema along with their types. This list restricts the column families that can be referenced in queries and specifies their value types. You can use this list to do type conversions - see the 'type' field for more details. If you leave this list empty, all column families are present in the table schema and their values are read as BYTES. During a query only the column families referenced in that query are read from Bigtable.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "columnFamily")]
    pub column_family: Option<Vec<TableForProviderExternalDataConfigurationBigtableOptionsColumnFamily>>,
    /// If field is true, then the column families that are not specified in columnFamilies list are not exposed in the table schema. Otherwise, they are read with BYTES type values. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnspecifiedColumnFamilies")]
    pub ignore_unspecified_column_families: Option<bool>,
    /// If field is true, then each column family will be read as a single JSON column. Otherwise they are read as a repeated cell structure containing timestamp/value tuples. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "outputColumnFamiliesAsJson")]
    pub output_column_families_as_json: Option<bool>,
    /// If field is true, then the rowkey column families will be read and converted to string. Otherwise they are read with BYTES type values and users need to manually cast them with CAST if necessary. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readRowkeyAsString")]
    pub read_rowkey_as_string: Option<bool>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationBigtableOptionsColumnFamily {
    /// A List of columns that should be exposed as individual fields as opposed to a list of (column name, value) pairs. All columns whose qualifier matches a qualifier in this list can be accessed as Other columns can be accessed as a list through column field.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub column: Option<Vec<TableForProviderExternalDataConfigurationBigtableOptionsColumnFamilyColumn>>,
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// Identifier of the column family.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "familyId")]
    pub family_id: Option<String>,
    /// If this is set only the latest version of value are exposed for all columns in this column family. This can be overridden for a specific column by listing that column in 'columns' and specifying a different setting for that column.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlyReadLatest")]
    pub only_read_latest: Option<bool>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationBigtableOptionsColumnFamilyColumn {
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// If the qualifier is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as the column field name and is used as field name in queries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldName")]
    pub field_name: Option<String>,
    /// If this is set only the latest version of value are exposed for all columns in this column family. This can be overridden for a specific column by listing that column in 'columns' and specifying a different setting for that column.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlyReadLatest")]
    pub only_read_latest: Option<bool>,
    /// Qualifier of the column. Columns in the parent column family that has this exact qualifier are exposed as . field. If the qualifier is valid UTF-8 string, it can be specified in the qualifierString field. Otherwise, a base-64 encoded value must be set to qualifierEncoded. The column field name is the same as the column qualifier. However, if the qualifier is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as fieldName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "qualifierEncoded")]
    pub qualifier_encoded: Option<String>,
    /// Qualifier string.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "qualifierString")]
    pub qualifier_string: Option<String>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "CSV". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationCsvOptions {
    /// Indicates if BigQuery should accept rows
    /// that are missing trailing optional columns.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowJaggedRows")]
    pub allow_jagged_rows: Option<bool>,
    /// Indicates if BigQuery should allow
    /// quoted data sections that contain newline characters in a CSV file.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowQuotedNewlines")]
    pub allow_quoted_newlines: Option<bool>,
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// The separator for fields in a CSV file.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    pub field_delimiter: Option<String>,
    /// The value that is used to quote data sections in a
    /// CSV file. If your data does not contain quoted sections, set the
    /// property value to an empty string. If your data contains quoted newline
    /// characters, you must also set the allow_quoted_newlines property to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub quote: Option<String>,
    /// The number of rows at the top of the sheet
    /// that BigQuery will skip when reading the data. At least one of range or
    /// skip_leading_rows must be set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    pub skip_leading_rows: Option<f64>,
}

/// Additional options if
/// source_format is set to "GOOGLE_SHEETS". Structure is
/// documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationGoogleSheetsOptions {
    /// Information required to partition based on ranges.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub range: Option<String>,
    /// The number of rows at the top of the sheet
    /// that BigQuery will skip when reading the data. At least one of range or
    /// skip_leading_rows must be set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    pub skip_leading_rows: Option<f64>,
}

/// When set, configures hive partitioning
/// support. Not all storage formats support hive partitioning -- requesting hive
/// partitioning on an unsupported format will lead to an error, as will providing
/// an invalid specification. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationHivePartitioningOptions {
    /// When set, what mode of hive partitioning to use when
    /// reading data. The following modes are supported.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<String>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified. require_partition_filter is deprecated and will be removed in
    /// a future major release. Use the top level field with the same name instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// When hive partition detection is requested,
    /// a common for all source uris must be required. The prefix must end immediately
    /// before the partition key encoding begins. For example, consider files following
    /// this data layout. gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
    /// gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive
    /// partitioning is requested with either AUTO or STRINGS detection, the common prefix
    /// can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/.
    /// Note that when mode is set to CUSTOM, you must encode the partition key schema within the source_uri_prefix by setting source_uri_prefix to gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUriPrefix")]
    pub source_uri_prefix: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "JSON". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationJsonOptions {
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "PARQUET". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderExternalDataConfigurationParquetOptions {
    /// Indicates whether to use schema inference specifically for Parquet LIST logical type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableListInference")]
    pub enable_list_inference: Option<bool>,
    /// Indicates whether to infer Parquet ENUM logical type as STRING instead of BYTES by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enumAsString")]
    pub enum_as_string: Option<bool>,
}

/// If specified, configures this table as a materialized view.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderMaterializedView {
    /// Allow non incremental materialized view definition.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowNonIncrementalDefinition")]
    pub allow_non_incremental_definition: Option<bool>,
    /// Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
    /// The default value is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableRefresh")]
    pub enable_refresh: Option<bool>,
    /// A query whose result is persisted.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// The maximum frequency at which this materialized view will be refreshed.
    /// The default value is 1800000
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "refreshIntervalMs")]
    pub refresh_interval_ms: Option<f64>,
}

/// If specified, configures range-based
/// partitioning for this table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderRangePartitioning {
    /// The field used to determine how to create a range-based
    /// partition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub field: Option<String>,
    /// Information required to partition based on ranges.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub range: Option<TableForProviderRangePartitioningRange>,
}

/// Information required to partition based on ranges.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderRangePartitioningRange {
    /// End of the range partitioning, exclusive.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub end: Option<f64>,
    /// The width of each range within the partition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub interval: Option<f64>,
    /// Start of the range partitioning, inclusive.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub start: Option<f64>,
}

/// Defines the primary key and foreign keys.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTableConstraints {
    /// Present only if the table has a foreign key.
    /// The foreign key is not enforced.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "foreignKeys")]
    pub foreign_keys: Option<Vec<TableForProviderTableConstraintsForeignKeys>>,
    /// Represents the primary key constraint
    /// on a table's columns. Present only if the table has a primary key.
    /// The primary key is not enforced.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryKey")]
    pub primary_key: Option<TableForProviderTableConstraintsPrimaryKey>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTableConstraintsForeignKeys {
    /// :  The pair of the foreign key column and primary key column.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "columnReferences")]
    pub column_references: Option<TableForProviderTableConstraintsForeignKeysColumnReferences>,
    /// :  Set only if the foreign key constraint is named.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// :  The table that holds the primary key
    /// and is referenced by this foreign key.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencedTable")]
    pub referenced_table: Option<TableForProviderTableConstraintsForeignKeysReferencedTable>,
}

/// :  The pair of the foreign key column and primary key column.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTableConstraintsForeignKeysColumnReferences {
    /// :  The column in the primary key that are
    /// referenced by the referencingColumn
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencedColumn")]
    pub referenced_column: Option<String>,
    /// :  The column that composes the foreign key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencingColumn")]
    pub referencing_column: Option<String>,
}

/// :  The table that holds the primary key
/// and is referenced by this foreign key.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTableConstraintsForeignKeysReferencedTable {
    /// :  The ID of the dataset containing this table.
    #[serde(rename = "datasetId")]
    pub dataset_id: String,
    /// :  The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    pub project_id: Option<String>,
    /// A unique ID for the resource.
    /// Changing this forces a new resource to be created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    pub table_id: Option<String>,
}

/// Represents the primary key constraint
/// on a table's columns. Present only if the table has a primary key.
/// The primary key is not enforced.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTableConstraintsPrimaryKey {
    /// :  The columns that are composed of the primary key constraint.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub columns: Option<Vec<String>>,
}

/// Replication info of a table created
/// using "AS REPLICA" DDL like:
/// CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTableReplicationInfo {
    /// The interval at which the source
    /// materialized view is polled for updates. The default is 300000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationIntervalMs")]
    pub replication_interval_ms: Option<f64>,
    /// The ID of the source dataset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceDatasetId")]
    pub source_dataset_id: Option<String>,
    /// The ID of the source project.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceProjectId")]
    pub source_project_id: Option<String>,
    /// The ID of the source materialized view.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTableId")]
    pub source_table_id: Option<String>,
}

/// If specified, configures time-based
/// partitioning for this table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderTimePartitioning {
    /// Number of milliseconds for which to keep the
    /// storage for a partition.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationMs")]
    pub expiration_ms: Option<f64>,
    /// The field used to determine how to create a time-based
    /// partition. If time-based partitioning is enabled without this value, the
    /// table is partitioned based on the load time.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub field: Option<String>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified. require_partition_filter is deprecated and will be removed in
    /// a future major release. Use the top level field with the same name instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// The supported types are DAY, HOUR, MONTH, and YEAR,
    /// which will generate one partition per day, hour, month, and year, respectively.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// If specified, configures this table as a view.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableForProviderView {
    /// A query that BigQuery executes when the view is referenced.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// Specifies whether to use BigQuery's legacy SQL for this view.
    /// The default value is true. If set to false, the view will use BigQuery's standard SQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useLegacySql")]
    pub use_legacy_sql: Option<bool>,
}

/// THIS IS A BETA FIELD. It will be honored
/// unless the Management Policies feature flag is disabled.
/// InitProvider holds the same fields as ForProvider, with the exception
/// of Identifier and other resource reference fields. The fields that are
/// in InitProvider are merged into ForProvider when the resource is created.
/// The same fields are also added to the terraform ignore_changes hook, to
/// avoid updating them after creation. This is useful for fields that are
/// required on creation, but we do not desire to update them after creation,
/// for example because of an external controller is managing them, like an
/// autoscaler.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProvider {
    /// If set to true, it allows table
    /// deletion when there are still resource tags attached. The default value is
    /// false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowResourceTagsOnDeletion")]
    pub allow_resource_tags_on_deletion: Option<bool>,
    /// Specifies column names to use for data clustering.
    /// Up to four top-level columns are allowed, and should be specified in
    /// descending priority order.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub clustering: Option<Vec<String>>,
    /// When the field is set to false, deleting the table is allowed..
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionProtection")]
    pub deletion_protection: Option<bool>,
    /// The field description.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,
    /// Specifies how the table should be encrypted.
    /// If left blank, the table will be encrypted with a Google-managed key; that process
    /// is transparent to the user.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "encryptionConfiguration")]
    pub encryption_configuration: Option<TableInitProviderEncryptionConfiguration>,
    /// The time when this table expires, in
    /// milliseconds since the epoch. If not present, the table will persist
    /// indefinitely. Expired tables will be deleted and their storage
    /// reclaimed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationTime")]
    pub expiration_time: Option<f64>,
    /// Describes the data format,
    /// location, and other properties of a table stored outside of BigQuery.
    /// By defining these properties, the data source can then be queried as
    /// if it were a standard BigQuery table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalDataConfiguration")]
    pub external_data_configuration: Option<TableInitProviderExternalDataConfiguration>,
    /// A descriptive name for the table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "friendlyName")]
    pub friendly_name: Option<String>,
    /// A mapping of labels to assign to the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<HashMap<String, String>>,
    /// If specified, configures this table as a materialized view.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "materializedView")]
    pub materialized_view: Option<TableInitProviderMaterializedView>,
    /// :  The maximum staleness of data that could be
    /// returned when the table (or stale MV) is queried. Staleness encoded as a
    /// string encoding of SQL IntervalValue
    /// type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxStaleness")]
    pub max_staleness: Option<String>,
    /// If specified, configures range-based
    /// partitioning for this table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "rangePartitioning")]
    pub range_partitioning: Option<TableInitProviderRangePartitioning>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// The tags attached to this table. Tag keys are
    /// globally unique. Tag key is expected to be in the namespaced format, for
    /// example "123456789012/environment" where 123456789012 is the ID of the
    /// parent organization or project resource for this tag key. Tag value is
    /// expected to be the short name, for example "Production".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceTags")]
    pub resource_tags: Option<HashMap<String, String>>,
    /// A JSON schema for the table.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schema: Option<String>,
    /// Defines the primary key and foreign keys.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableConstraints")]
    pub table_constraints: Option<TableInitProviderTableConstraints>,
    /// Replication info of a table created
    /// using "AS REPLICA" DDL like:
    /// CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableReplicationInfo")]
    pub table_replication_info: Option<TableInitProviderTableReplicationInfo>,
    /// If specified, configures time-based
    /// partitioning for this table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timePartitioning")]
    pub time_partitioning: Option<TableInitProviderTimePartitioning>,
    /// If specified, configures this table as a view.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub view: Option<TableInitProviderView>,
}

/// Specifies how the table should be encrypted.
/// If left blank, the table will be encrypted with a Google-managed key; that process
/// is transparent to the user.  Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderEncryptionConfiguration {
    /// The self link or full name of a key which should be used to
    /// encrypt this table.  Note that the default bigquery service account will need to have
    /// encrypt/decrypt permissions on this key - you may want to see the
    /// google_bigquery_default_service_account datasource and the
    /// google_kms_crypto_key_iam_binding resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    pub kms_key_name: Option<String>,
}

/// Describes the data format,
/// location, and other properties of a table stored outside of BigQuery.
/// By defining these properties, the data source can then be queried as
/// if it were a standard BigQuery table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfiguration {
    /// - Let BigQuery try to autodetect the schema
    /// and format of the table.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub autodetect: Option<bool>,
    /// Additional options if source_format is set to
    /// "AVRO".  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "avroOptions")]
    pub avro_options: Option<TableInitProviderExternalDataConfigurationAvroOptions>,
    /// Additional properties to set if
    /// source_format is set to "BIGTABLE". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bigtableOptions")]
    pub bigtable_options: Option<TableInitProviderExternalDataConfigurationBigtableOptions>,
    /// The compression type of the data source.
    /// Valid values are "NONE" or "GZIP".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<String>,
    /// The connection specifying the credentials to be used to read
    /// external storage, such as Azure Blob, Cloud Storage, or S3. The connection_id can have
    /// the form {{project}}.{{location}}.{{connection_id}}
    /// or projects/{{project}}/locations/{{location}}/connections/{{connection_id}}.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionId")]
    pub connection_id: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "CSV". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "csvOptions")]
    pub csv_options: Option<TableInitProviderExternalDataConfigurationCsvOptions>,
    /// Specifies how source URIs are interpreted for constructing the file set to load.
    /// By default source URIs are expanded against the underlying storage.
    /// Other options include specifying manifest files. Only applicable to object storage systems. Docs
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSetSpecType")]
    pub file_set_spec_type: Option<String>,
    /// Additional options if
    /// source_format is set to "GOOGLE_SHEETS". Structure is
    /// documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "googleSheetsOptions")]
    pub google_sheets_options: Option<TableInitProviderExternalDataConfigurationGoogleSheetsOptions>,
    /// When set, configures hive partitioning
    /// support. Not all storage formats support hive partitioning -- requesting hive
    /// partitioning on an unsupported format will lead to an error, as will providing
    /// an invalid specification. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "hivePartitioningOptions")]
    pub hive_partitioning_options: Option<TableInitProviderExternalDataConfigurationHivePartitioningOptions>,
    /// Indicates if BigQuery should
    /// allow extra values that are not represented in the table schema.
    /// If true, the extra values are ignored. If false, records with
    /// extra columns are treated as bad records, and if there are too
    /// many bad records, an invalid error is returned in the job result.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnknownValues")]
    pub ignore_unknown_values: Option<bool>,
    /// Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the JSON source format. Valid values are: GEOJSON.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonExtension")]
    pub json_extension: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "JSON". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonOptions")]
    pub json_options: Option<TableInitProviderExternalDataConfigurationJsonOptions>,
    /// The maximum number of bad records that
    /// BigQuery can ignore when reading data.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxBadRecords")]
    pub max_bad_records: Option<f64>,
    /// Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are AUTOMATIC and MANUAL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metadataCacheMode")]
    pub metadata_cache_mode: Option<String>,
    /// Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If object_metadata is set, source_format should be omitted.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "objectMetadata")]
    pub object_metadata: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "PARQUET". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parquetOptions")]
    pub parquet_options: Option<TableInitProviderExternalDataConfigurationParquetOptions>,
    /// When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referenceFileSchemaUri")]
    pub reference_file_schema_uri: Option<String>,
    /// A JSON schema for the external table. Schema is required
    /// for CSV and JSON formats if autodetect is not on. Schema is disallowed
    /// for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
    /// ~>NOTE: Because this field expects a JSON string, any changes to the
    /// string will create a diff, even if the JSON itself hasn't changed.
    /// Furthermore drift for this field cannot not be detected because BigQuery
    /// only uses this schema to compute the effective schema for the table, therefore
    /// any changes on the configured value will force the table to be recreated.
    /// This schema is effectively only applied when creating a table from an external
    /// datasource, after creation the computed schema will be stored in
    /// google_bigquery_table.schema
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schema: Option<String>,
    /// The data format. Please see sourceFormat under
    /// ExternalDataConfiguration
    /// in Bigquery's public API documentation for supported formats. To use "GOOGLE_SHEETS"
    /// the scopes must include "https://www.googleapis.com/auth/drive.readonly".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceFormat")]
    pub source_format: Option<String>,
    /// A list of the fully-qualified URIs that point to
    /// your data in Google Cloud.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUris")]
    pub source_uris: Option<Vec<String>>,
}

/// Additional options if source_format is set to
/// "AVRO".  Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationAvroOptions {
    /// If is set to true, indicates whether
    /// to interpret logical types as the corresponding BigQuery data type
    /// (for example, TIMESTAMP), instead of using the raw type (for example, INTEGER).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useAvroLogicalTypes")]
    pub use_avro_logical_types: Option<bool>,
}

/// Additional properties to set if
/// source_format is set to "BIGTABLE". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationBigtableOptions {
    /// A list of column families to expose in the table schema along with their types. This list restricts the column families that can be referenced in queries and specifies their value types. You can use this list to do type conversions - see the 'type' field for more details. If you leave this list empty, all column families are present in the table schema and their values are read as BYTES. During a query only the column families referenced in that query are read from Bigtable.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "columnFamily")]
    pub column_family: Option<Vec<TableInitProviderExternalDataConfigurationBigtableOptionsColumnFamily>>,
    /// If field is true, then the column families that are not specified in columnFamilies list are not exposed in the table schema. Otherwise, they are read with BYTES type values. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnspecifiedColumnFamilies")]
    pub ignore_unspecified_column_families: Option<bool>,
    /// If field is true, then each column family will be read as a single JSON column. Otherwise they are read as a repeated cell structure containing timestamp/value tuples. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "outputColumnFamiliesAsJson")]
    pub output_column_families_as_json: Option<bool>,
    /// If field is true, then the rowkey column families will be read and converted to string. Otherwise they are read with BYTES type values and users need to manually cast them with CAST if necessary. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readRowkeyAsString")]
    pub read_rowkey_as_string: Option<bool>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationBigtableOptionsColumnFamily {
    /// A List of columns that should be exposed as individual fields as opposed to a list of (column name, value) pairs. All columns whose qualifier matches a qualifier in this list can be accessed as Other columns can be accessed as a list through column field.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub column: Option<Vec<TableInitProviderExternalDataConfigurationBigtableOptionsColumnFamilyColumn>>,
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// Identifier of the column family.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "familyId")]
    pub family_id: Option<String>,
    /// If this is set only the latest version of value are exposed for all columns in this column family. This can be overridden for a specific column by listing that column in 'columns' and specifying a different setting for that column.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlyReadLatest")]
    pub only_read_latest: Option<bool>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationBigtableOptionsColumnFamilyColumn {
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// If the qualifier is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as the column field name and is used as field name in queries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldName")]
    pub field_name: Option<String>,
    /// If this is set only the latest version of value are exposed for all columns in this column family. This can be overridden for a specific column by listing that column in 'columns' and specifying a different setting for that column.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlyReadLatest")]
    pub only_read_latest: Option<bool>,
    /// Qualifier of the column. Columns in the parent column family that has this exact qualifier are exposed as . field. If the qualifier is valid UTF-8 string, it can be specified in the qualifierString field. Otherwise, a base-64 encoded value must be set to qualifierEncoded. The column field name is the same as the column qualifier. However, if the qualifier is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as fieldName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "qualifierEncoded")]
    pub qualifier_encoded: Option<String>,
    /// Qualifier string.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "qualifierString")]
    pub qualifier_string: Option<String>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "CSV". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationCsvOptions {
    /// Indicates if BigQuery should accept rows
    /// that are missing trailing optional columns.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowJaggedRows")]
    pub allow_jagged_rows: Option<bool>,
    /// Indicates if BigQuery should allow
    /// quoted data sections that contain newline characters in a CSV file.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowQuotedNewlines")]
    pub allow_quoted_newlines: Option<bool>,
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// The separator for fields in a CSV file.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    pub field_delimiter: Option<String>,
    /// The value that is used to quote data sections in a
    /// CSV file. If your data does not contain quoted sections, set the
    /// property value to an empty string. If your data contains quoted newline
    /// characters, you must also set the allow_quoted_newlines property to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub quote: Option<String>,
    /// The number of rows at the top of the sheet
    /// that BigQuery will skip when reading the data. At least one of range or
    /// skip_leading_rows must be set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    pub skip_leading_rows: Option<f64>,
}

/// Additional options if
/// source_format is set to "GOOGLE_SHEETS". Structure is
/// documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationGoogleSheetsOptions {
    /// Information required to partition based on ranges.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub range: Option<String>,
    /// The number of rows at the top of the sheet
    /// that BigQuery will skip when reading the data. At least one of range or
    /// skip_leading_rows must be set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    pub skip_leading_rows: Option<f64>,
}

/// When set, configures hive partitioning
/// support. Not all storage formats support hive partitioning -- requesting hive
/// partitioning on an unsupported format will lead to an error, as will providing
/// an invalid specification. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationHivePartitioningOptions {
    /// When set, what mode of hive partitioning to use when
    /// reading data. The following modes are supported.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<String>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified. require_partition_filter is deprecated and will be removed in
    /// a future major release. Use the top level field with the same name instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// When hive partition detection is requested,
    /// a common for all source uris must be required. The prefix must end immediately
    /// before the partition key encoding begins. For example, consider files following
    /// this data layout. gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
    /// gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive
    /// partitioning is requested with either AUTO or STRINGS detection, the common prefix
    /// can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/.
    /// Note that when mode is set to CUSTOM, you must encode the partition key schema within the source_uri_prefix by setting source_uri_prefix to gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUriPrefix")]
    pub source_uri_prefix: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "JSON". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationJsonOptions {
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "PARQUET". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderExternalDataConfigurationParquetOptions {
    /// Indicates whether to use schema inference specifically for Parquet LIST logical type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableListInference")]
    pub enable_list_inference: Option<bool>,
    /// Indicates whether to infer Parquet ENUM logical type as STRING instead of BYTES by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enumAsString")]
    pub enum_as_string: Option<bool>,
}

/// If specified, configures this table as a materialized view.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderMaterializedView {
    /// Allow non incremental materialized view definition.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowNonIncrementalDefinition")]
    pub allow_non_incremental_definition: Option<bool>,
    /// Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
    /// The default value is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableRefresh")]
    pub enable_refresh: Option<bool>,
    /// A query whose result is persisted.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// The maximum frequency at which this materialized view will be refreshed.
    /// The default value is 1800000
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "refreshIntervalMs")]
    pub refresh_interval_ms: Option<f64>,
}

/// If specified, configures range-based
/// partitioning for this table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderRangePartitioning {
    /// The field used to determine how to create a range-based
    /// partition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub field: Option<String>,
    /// Information required to partition based on ranges.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub range: Option<TableInitProviderRangePartitioningRange>,
}

/// Information required to partition based on ranges.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderRangePartitioningRange {
    /// End of the range partitioning, exclusive.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub end: Option<f64>,
    /// The width of each range within the partition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub interval: Option<f64>,
    /// Start of the range partitioning, inclusive.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub start: Option<f64>,
}

/// Defines the primary key and foreign keys.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTableConstraints {
    /// Present only if the table has a foreign key.
    /// The foreign key is not enforced.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "foreignKeys")]
    pub foreign_keys: Option<Vec<TableInitProviderTableConstraintsForeignKeys>>,
    /// Represents the primary key constraint
    /// on a table's columns. Present only if the table has a primary key.
    /// The primary key is not enforced.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryKey")]
    pub primary_key: Option<TableInitProviderTableConstraintsPrimaryKey>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTableConstraintsForeignKeys {
    /// :  The pair of the foreign key column and primary key column.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "columnReferences")]
    pub column_references: Option<TableInitProviderTableConstraintsForeignKeysColumnReferences>,
    /// :  Set only if the foreign key constraint is named.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// :  The table that holds the primary key
    /// and is referenced by this foreign key.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencedTable")]
    pub referenced_table: Option<TableInitProviderTableConstraintsForeignKeysReferencedTable>,
}

/// :  The pair of the foreign key column and primary key column.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTableConstraintsForeignKeysColumnReferences {
    /// :  The column in the primary key that are
    /// referenced by the referencingColumn
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencedColumn")]
    pub referenced_column: Option<String>,
    /// :  The column that composes the foreign key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencingColumn")]
    pub referencing_column: Option<String>,
}

/// :  The table that holds the primary key
/// and is referenced by this foreign key.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTableConstraintsForeignKeysReferencedTable {
    /// :  The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    pub project_id: Option<String>,
    /// A unique ID for the resource.
    /// Changing this forces a new resource to be created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    pub table_id: Option<String>,
}

/// Represents the primary key constraint
/// on a table's columns. Present only if the table has a primary key.
/// The primary key is not enforced.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTableConstraintsPrimaryKey {
    /// :  The columns that are composed of the primary key constraint.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub columns: Option<Vec<String>>,
}

/// Replication info of a table created
/// using "AS REPLICA" DDL like:
/// CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTableReplicationInfo {
    /// The interval at which the source
    /// materialized view is polled for updates. The default is 300000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationIntervalMs")]
    pub replication_interval_ms: Option<f64>,
    /// The ID of the source dataset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceDatasetId")]
    pub source_dataset_id: Option<String>,
    /// The ID of the source project.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceProjectId")]
    pub source_project_id: Option<String>,
    /// The ID of the source materialized view.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTableId")]
    pub source_table_id: Option<String>,
}

/// If specified, configures time-based
/// partitioning for this table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderTimePartitioning {
    /// Number of milliseconds for which to keep the
    /// storage for a partition.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationMs")]
    pub expiration_ms: Option<f64>,
    /// The field used to determine how to create a time-based
    /// partition. If time-based partitioning is enabled without this value, the
    /// table is partitioned based on the load time.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub field: Option<String>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified. require_partition_filter is deprecated and will be removed in
    /// a future major release. Use the top level field with the same name instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// The supported types are DAY, HOUR, MONTH, and YEAR,
    /// which will generate one partition per day, hour, month, and year, respectively.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// If specified, configures this table as a view.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableInitProviderView {
    /// A query that BigQuery executes when the view is referenced.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// Specifies whether to use BigQuery's legacy SQL for this view.
    /// The default value is true. If set to false, the view will use BigQuery's standard SQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useLegacySql")]
    pub use_legacy_sql: Option<bool>,
}

/// ProviderConfigReference specifies how the provider that will be used to
/// create, observe, update, and delete this managed resource should be
/// configured.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableProviderConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<TableProviderConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableProviderConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<TableProviderConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<TableProviderConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableProviderConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TableProviderConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// PublishConnectionDetailsTo specifies the connection secret config which
/// contains a name, metadata and a reference to secret store config to
/// which any connection details for this managed resource should be written.
/// Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TablePublishConnectionDetailsTo {
    /// SecretStoreConfigRef specifies which secret store config should be used
    /// for this ConnectionSecret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configRef")]
    pub config_ref: Option<TablePublishConnectionDetailsToConfigRef>,
    /// Metadata is the metadata for connection secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub metadata: Option<TablePublishConnectionDetailsToMetadata>,
    /// Name is the name of the connection secret.
    pub name: String,
}

/// SecretStoreConfigRef specifies which secret store config should be used
/// for this ConnectionSecret.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TablePublishConnectionDetailsToConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub policy: Option<TablePublishConnectionDetailsToConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TablePublishConnectionDetailsToConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolution: Option<TablePublishConnectionDetailsToConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub resolve: Option<TablePublishConnectionDetailsToConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TablePublishConnectionDetailsToConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum TablePublishConnectionDetailsToConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Metadata is the metadata for connection secret.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TablePublishConnectionDetailsToMetadata {
    /// Annotations are the annotations to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.annotations".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub annotations: Option<HashMap<String, String>>,
    /// Labels are the labels/tags to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.labels".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<HashMap<String, String>>,
    /// Type is the SecretType for the connection secret.
    /// - Only valid for Kubernetes Secret Stores.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// WriteConnectionSecretToReference specifies the namespace and name of a
/// Secret to which any connection details for this managed resource should
/// be written. Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
/// This field is planned to be replaced in a future release in favor of
/// PublishConnectionDetailsTo. Currently, both could be set independently
/// and connection details would be published to both without affecting
/// each other.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableWriteConnectionSecretToRef {
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// TableStatus defines the observed state of Table.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatus {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "atProvider")]
    pub at_provider: Option<TableStatusAtProvider>,
    /// Conditions of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub conditions: Option<Vec<Condition>>,
    /// ObservedGeneration is the latest metadata.generation
    /// which resulted in either a ready state, or stalled due to error
    /// it can not recover from without human intervention.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    pub observed_generation: Option<i64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProvider {
    /// If set to true, it allows table
    /// deletion when there are still resource tags attached. The default value is
    /// false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowResourceTagsOnDeletion")]
    pub allow_resource_tags_on_deletion: Option<bool>,
    /// Specifies column names to use for data clustering.
    /// Up to four top-level columns are allowed, and should be specified in
    /// descending priority order.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub clustering: Option<Vec<String>>,
    /// The time when this table was created, in milliseconds since the epoch.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "creationTime")]
    pub creation_time: Option<f64>,
    /// The dataset ID to create the table in.
    /// Changing this forces a new resource to be created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    pub dataset_id: Option<String>,
    /// When the field is set to false, deleting the table is allowed..
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionProtection")]
    pub deletion_protection: Option<bool>,
    /// The field description.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "effectiveLabels")]
    pub effective_labels: Option<HashMap<String, String>>,
    /// Specifies how the table should be encrypted.
    /// If left blank, the table will be encrypted with a Google-managed key; that process
    /// is transparent to the user.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "encryptionConfiguration")]
    pub encryption_configuration: Option<TableStatusAtProviderEncryptionConfiguration>,
    /// A hash of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub etag: Option<String>,
    /// The time when this table expires, in
    /// milliseconds since the epoch. If not present, the table will persist
    /// indefinitely. Expired tables will be deleted and their storage
    /// reclaimed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationTime")]
    pub expiration_time: Option<f64>,
    /// Describes the data format,
    /// location, and other properties of a table stored outside of BigQuery.
    /// By defining these properties, the data source can then be queried as
    /// if it were a standard BigQuery table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "externalDataConfiguration")]
    pub external_data_configuration: Option<TableStatusAtProviderExternalDataConfiguration>,
    /// A descriptive name for the table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "friendlyName")]
    pub friendly_name: Option<String>,
    /// an identifier for the resource with format projects/{{project}}/datasets/{{dataset}}/tables/{{name}}
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub id: Option<String>,
    /// A mapping of labels to assign to the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub labels: Option<HashMap<String, String>>,
    /// The time when this table was last modified, in milliseconds since the epoch.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "lastModifiedTime")]
    pub last_modified_time: Option<f64>,
    /// The geographic location where the table resides. This value is inherited from the dataset.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub location: Option<String>,
    /// If specified, configures this table as a materialized view.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "materializedView")]
    pub materialized_view: Option<TableStatusAtProviderMaterializedView>,
    /// :  The maximum staleness of data that could be
    /// returned when the table (or stale MV) is queried. Staleness encoded as a
    /// string encoding of SQL IntervalValue
    /// type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxStaleness")]
    pub max_staleness: Option<String>,
    /// The size of this table in bytes, excluding any data in the streaming buffer.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "numBytes")]
    pub num_bytes: Option<f64>,
    /// The number of bytes in the table that are considered "long-term storage".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "numLongTermBytes")]
    pub num_long_term_bytes: Option<f64>,
    /// The number of rows of data in this table, excluding any data in the streaming buffer.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "numRows")]
    pub num_rows: Option<f64>,
    /// The ID of the project in which the resource belongs. If it
    /// is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub project: Option<String>,
    /// If specified, configures range-based
    /// partitioning for this table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "rangePartitioning")]
    pub range_partitioning: Option<TableStatusAtProviderRangePartitioning>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// The tags attached to this table. Tag keys are
    /// globally unique. Tag key is expected to be in the namespaced format, for
    /// example "123456789012/environment" where 123456789012 is the ID of the
    /// parent organization or project resource for this tag key. Tag value is
    /// expected to be the short name, for example "Production".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceTags")]
    pub resource_tags: Option<HashMap<String, String>>,
    /// A JSON schema for the table.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schema: Option<String>,
    /// The URI of the created resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "selfLink")]
    pub self_link: Option<String>,
    /// Defines the primary key and foreign keys.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableConstraints")]
    pub table_constraints: Option<TableStatusAtProviderTableConstraints>,
    /// Replication info of a table created
    /// using "AS REPLICA" DDL like:
    /// CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableReplicationInfo")]
    pub table_replication_info: Option<TableStatusAtProviderTableReplicationInfo>,
    /// The combination of labels configured directly on the resource and default labels configured on the provider.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "terraformLabels")]
    pub terraform_labels: Option<HashMap<String, String>>,
    /// If specified, configures time-based
    /// partitioning for this table. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timePartitioning")]
    pub time_partitioning: Option<TableStatusAtProviderTimePartitioning>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
    /// If specified, configures this table as a view.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub view: Option<TableStatusAtProviderView>,
}

/// Specifies how the table should be encrypted.
/// If left blank, the table will be encrypted with a Google-managed key; that process
/// is transparent to the user.  Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderEncryptionConfiguration {
    /// The self link or full name of a key which should be used to
    /// encrypt this table.  Note that the default bigquery service account will need to have
    /// encrypt/decrypt permissions on this key - you may want to see the
    /// google_bigquery_default_service_account datasource and the
    /// google_kms_crypto_key_iam_binding resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    pub kms_key_name: Option<String>,
    /// The self link or full name of the kms key version used to encrypt this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyVersion")]
    pub kms_key_version: Option<String>,
}

/// Describes the data format,
/// location, and other properties of a table stored outside of BigQuery.
/// By defining these properties, the data source can then be queried as
/// if it were a standard BigQuery table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfiguration {
    /// - Let BigQuery try to autodetect the schema
    /// and format of the table.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub autodetect: Option<bool>,
    /// Additional options if source_format is set to
    /// "AVRO".  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "avroOptions")]
    pub avro_options: Option<TableStatusAtProviderExternalDataConfigurationAvroOptions>,
    /// Additional properties to set if
    /// source_format is set to "BIGTABLE". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "bigtableOptions")]
    pub bigtable_options: Option<TableStatusAtProviderExternalDataConfigurationBigtableOptions>,
    /// The compression type of the data source.
    /// Valid values are "NONE" or "GZIP".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub compression: Option<String>,
    /// The connection specifying the credentials to be used to read
    /// external storage, such as Azure Blob, Cloud Storage, or S3. The connection_id can have
    /// the form {{project}}.{{location}}.{{connection_id}}
    /// or projects/{{project}}/locations/{{location}}/connections/{{connection_id}}.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "connectionId")]
    pub connection_id: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "CSV". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "csvOptions")]
    pub csv_options: Option<TableStatusAtProviderExternalDataConfigurationCsvOptions>,
    /// Specifies how source URIs are interpreted for constructing the file set to load.
    /// By default source URIs are expanded against the underlying storage.
    /// Other options include specifying manifest files. Only applicable to object storage systems. Docs
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fileSetSpecType")]
    pub file_set_spec_type: Option<String>,
    /// Additional options if
    /// source_format is set to "GOOGLE_SHEETS". Structure is
    /// documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "googleSheetsOptions")]
    pub google_sheets_options: Option<TableStatusAtProviderExternalDataConfigurationGoogleSheetsOptions>,
    /// When set, configures hive partitioning
    /// support. Not all storage formats support hive partitioning -- requesting hive
    /// partitioning on an unsupported format will lead to an error, as will providing
    /// an invalid specification. Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "hivePartitioningOptions")]
    pub hive_partitioning_options: Option<TableStatusAtProviderExternalDataConfigurationHivePartitioningOptions>,
    /// Indicates if BigQuery should
    /// allow extra values that are not represented in the table schema.
    /// If true, the extra values are ignored. If false, records with
    /// extra columns are treated as bad records, and if there are too
    /// many bad records, an invalid error is returned in the job result.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnknownValues")]
    pub ignore_unknown_values: Option<bool>,
    /// Used to indicate that a JSON variant, rather than normal JSON, is being used as the sourceFormat. This should only be used in combination with the JSON source format. Valid values are: GEOJSON.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonExtension")]
    pub json_extension: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "JSON". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonOptions")]
    pub json_options: Option<TableStatusAtProviderExternalDataConfigurationJsonOptions>,
    /// The maximum number of bad records that
    /// BigQuery can ignore when reading data.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxBadRecords")]
    pub max_bad_records: Option<f64>,
    /// Metadata Cache Mode for the table. Set this to enable caching of metadata from external data source. Valid values are AUTOMATIC and MANUAL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "metadataCacheMode")]
    pub metadata_cache_mode: Option<String>,
    /// Object Metadata is used to create Object Tables. Object Tables contain a listing of objects (with their metadata) found at the sourceUris. If object_metadata is set, source_format should be omitted.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "objectMetadata")]
    pub object_metadata: Option<String>,
    /// Additional properties to set if
    /// source_format is set to "PARQUET". Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parquetOptions")]
    pub parquet_options: Option<TableStatusAtProviderExternalDataConfigurationParquetOptions>,
    /// When creating an external table, the user can provide a reference file with the table schema. This is enabled for the following formats: AVRO, PARQUET, ORC.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referenceFileSchemaUri")]
    pub reference_file_schema_uri: Option<String>,
    /// A JSON schema for the external table. Schema is required
    /// for CSV and JSON formats if autodetect is not on. Schema is disallowed
    /// for Google Cloud Bigtable, Cloud Datastore backups, Avro, Iceberg, ORC and Parquet formats.
    /// ~>NOTE: Because this field expects a JSON string, any changes to the
    /// string will create a diff, even if the JSON itself hasn't changed.
    /// Furthermore drift for this field cannot not be detected because BigQuery
    /// only uses this schema to compute the effective schema for the table, therefore
    /// any changes on the configured value will force the table to be recreated.
    /// This schema is effectively only applied when creating a table from an external
    /// datasource, after creation the computed schema will be stored in
    /// google_bigquery_table.schema
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub schema: Option<String>,
    /// The data format. Please see sourceFormat under
    /// ExternalDataConfiguration
    /// in Bigquery's public API documentation for supported formats. To use "GOOGLE_SHEETS"
    /// the scopes must include "https://www.googleapis.com/auth/drive.readonly".
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceFormat")]
    pub source_format: Option<String>,
    /// A list of the fully-qualified URIs that point to
    /// your data in Google Cloud.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUris")]
    pub source_uris: Option<Vec<String>>,
}

/// Additional options if source_format is set to
/// "AVRO".  Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationAvroOptions {
    /// If is set to true, indicates whether
    /// to interpret logical types as the corresponding BigQuery data type
    /// (for example, TIMESTAMP), instead of using the raw type (for example, INTEGER).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useAvroLogicalTypes")]
    pub use_avro_logical_types: Option<bool>,
}

/// Additional properties to set if
/// source_format is set to "BIGTABLE". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationBigtableOptions {
    /// A list of column families to expose in the table schema along with their types. This list restricts the column families that can be referenced in queries and specifies their value types. You can use this list to do type conversions - see the 'type' field for more details. If you leave this list empty, all column families are present in the table schema and their values are read as BYTES. During a query only the column families referenced in that query are read from Bigtable.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "columnFamily")]
    pub column_family: Option<Vec<TableStatusAtProviderExternalDataConfigurationBigtableOptionsColumnFamily>>,
    /// If field is true, then the column families that are not specified in columnFamilies list are not exposed in the table schema. Otherwise, they are read with BYTES type values. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnspecifiedColumnFamilies")]
    pub ignore_unspecified_column_families: Option<bool>,
    /// If field is true, then each column family will be read as a single JSON column. Otherwise they are read as a repeated cell structure containing timestamp/value tuples. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "outputColumnFamiliesAsJson")]
    pub output_column_families_as_json: Option<bool>,
    /// If field is true, then the rowkey column families will be read and converted to string. Otherwise they are read with BYTES type values and users need to manually cast them with CAST if necessary. The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "readRowkeyAsString")]
    pub read_rowkey_as_string: Option<bool>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationBigtableOptionsColumnFamily {
    /// A List of columns that should be exposed as individual fields as opposed to a list of (column name, value) pairs. All columns whose qualifier matches a qualifier in this list can be accessed as Other columns can be accessed as a list through column field.  Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub column: Option<Vec<TableStatusAtProviderExternalDataConfigurationBigtableOptionsColumnFamilyColumn>>,
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// Identifier of the column family.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "familyId")]
    pub family_id: Option<String>,
    /// If this is set only the latest version of value are exposed for all columns in this column family. This can be overridden for a specific column by listing that column in 'columns' and specifying a different setting for that column.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlyReadLatest")]
    pub only_read_latest: Option<bool>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationBigtableOptionsColumnFamilyColumn {
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// If the qualifier is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as the column field name and is used as field name in queries.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldName")]
    pub field_name: Option<String>,
    /// If this is set only the latest version of value are exposed for all columns in this column family. This can be overridden for a specific column by listing that column in 'columns' and specifying a different setting for that column.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "onlyReadLatest")]
    pub only_read_latest: Option<bool>,
    /// Qualifier of the column. Columns in the parent column family that has this exact qualifier are exposed as . field. If the qualifier is valid UTF-8 string, it can be specified in the qualifierString field. Otherwise, a base-64 encoded value must be set to qualifierEncoded. The column field name is the same as the column qualifier. However, if the qualifier is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as fieldName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "qualifierEncoded")]
    pub qualifier_encoded: Option<String>,
    /// Qualifier string.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "qualifierString")]
    pub qualifier_string: Option<String>,
    /// Describes the table type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "CSV". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationCsvOptions {
    /// Indicates if BigQuery should accept rows
    /// that are missing trailing optional columns.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowJaggedRows")]
    pub allow_jagged_rows: Option<bool>,
    /// Indicates if BigQuery should allow
    /// quoted data sections that contain newline characters in a CSV file.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowQuotedNewlines")]
    pub allow_quoted_newlines: Option<bool>,
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
    /// The separator for fields in a CSV file.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    pub field_delimiter: Option<String>,
    /// The value that is used to quote data sections in a
    /// CSV file. If your data does not contain quoted sections, set the
    /// property value to an empty string. If your data contains quoted newline
    /// characters, you must also set the allow_quoted_newlines property to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub quote: Option<String>,
    /// The number of rows at the top of the sheet
    /// that BigQuery will skip when reading the data. At least one of range or
    /// skip_leading_rows must be set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    pub skip_leading_rows: Option<f64>,
}

/// Additional options if
/// source_format is set to "GOOGLE_SHEETS". Structure is
/// documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationGoogleSheetsOptions {
    /// Information required to partition based on ranges.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub range: Option<String>,
    /// The number of rows at the top of the sheet
    /// that BigQuery will skip when reading the data. At least one of range or
    /// skip_leading_rows must be set.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    pub skip_leading_rows: Option<f64>,
}

/// When set, configures hive partitioning
/// support. Not all storage formats support hive partitioning -- requesting hive
/// partitioning on an unsupported format will lead to an error, as will providing
/// an invalid specification. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationHivePartitioningOptions {
    /// When set, what mode of hive partitioning to use when
    /// reading data. The following modes are supported.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub mode: Option<String>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified. require_partition_filter is deprecated and will be removed in
    /// a future major release. Use the top level field with the same name instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// When hive partition detection is requested,
    /// a common for all source uris must be required. The prefix must end immediately
    /// before the partition key encoding begins. For example, consider files following
    /// this data layout. gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro
    /// gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro When hive
    /// partitioning is requested with either AUTO or STRINGS detection, the common prefix
    /// can be either of gs://bucket/path_to_table or gs://bucket/path_to_table/.
    /// Note that when mode is set to CUSTOM, you must encode the partition key schema within the source_uri_prefix by setting source_uri_prefix to gs://bucket/path_to_table/{key1:TYPE1}/{key2:TYPE2}/{key3:TYPE3}.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUriPrefix")]
    pub source_uri_prefix: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "JSON". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationJsonOptions {
    /// The character encoding of the data. The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub encoding: Option<String>,
}

/// Additional properties to set if
/// source_format is set to "PARQUET". Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderExternalDataConfigurationParquetOptions {
    /// Indicates whether to use schema inference specifically for Parquet LIST logical type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableListInference")]
    pub enable_list_inference: Option<bool>,
    /// Indicates whether to infer Parquet ENUM logical type as STRING instead of BYTES by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enumAsString")]
    pub enum_as_string: Option<bool>,
}

/// If specified, configures this table as a materialized view.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderMaterializedView {
    /// Allow non incremental materialized view definition.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowNonIncrementalDefinition")]
    pub allow_non_incremental_definition: Option<bool>,
    /// Specifies whether to use BigQuery's automatic refresh for this materialized view when the base table is updated.
    /// The default value is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableRefresh")]
    pub enable_refresh: Option<bool>,
    /// A query whose result is persisted.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// The maximum frequency at which this materialized view will be refreshed.
    /// The default value is 1800000
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "refreshIntervalMs")]
    pub refresh_interval_ms: Option<f64>,
}

/// If specified, configures range-based
/// partitioning for this table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderRangePartitioning {
    /// The field used to determine how to create a range-based
    /// partition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub field: Option<String>,
    /// Information required to partition based on ranges.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub range: Option<TableStatusAtProviderRangePartitioningRange>,
}

/// Information required to partition based on ranges.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderRangePartitioningRange {
    /// End of the range partitioning, exclusive.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub end: Option<f64>,
    /// The width of each range within the partition.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub interval: Option<f64>,
    /// Start of the range partitioning, inclusive.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub start: Option<f64>,
}

/// Defines the primary key and foreign keys.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTableConstraints {
    /// Present only if the table has a foreign key.
    /// The foreign key is not enforced.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "foreignKeys")]
    pub foreign_keys: Option<Vec<TableStatusAtProviderTableConstraintsForeignKeys>>,
    /// Represents the primary key constraint
    /// on a table's columns. Present only if the table has a primary key.
    /// The primary key is not enforced.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryKey")]
    pub primary_key: Option<TableStatusAtProviderTableConstraintsPrimaryKey>,
}

#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTableConstraintsForeignKeys {
    /// :  The pair of the foreign key column and primary key column.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "columnReferences")]
    pub column_references: Option<TableStatusAtProviderTableConstraintsForeignKeysColumnReferences>,
    /// :  Set only if the foreign key constraint is named.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// :  The table that holds the primary key
    /// and is referenced by this foreign key.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencedTable")]
    pub referenced_table: Option<TableStatusAtProviderTableConstraintsForeignKeysReferencedTable>,
}

/// :  The pair of the foreign key column and primary key column.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTableConstraintsForeignKeysColumnReferences {
    /// :  The column in the primary key that are
    /// referenced by the referencingColumn
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencedColumn")]
    pub referenced_column: Option<String>,
    /// :  The column that composes the foreign key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "referencingColumn")]
    pub referencing_column: Option<String>,
}

/// :  The table that holds the primary key
/// and is referenced by this foreign key.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTableConstraintsForeignKeysReferencedTable {
    /// :  The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    pub dataset_id: Option<String>,
    /// :  The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    pub project_id: Option<String>,
    /// A unique ID for the resource.
    /// Changing this forces a new resource to be created.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    pub table_id: Option<String>,
}

/// Represents the primary key constraint
/// on a table's columns. Present only if the table has a primary key.
/// The primary key is not enforced.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTableConstraintsPrimaryKey {
    /// :  The columns that are composed of the primary key constraint.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub columns: Option<Vec<String>>,
}

/// Replication info of a table created
/// using "AS REPLICA" DDL like:
/// CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTableReplicationInfo {
    /// The interval at which the source
    /// materialized view is polled for updates. The default is 300000.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "replicationIntervalMs")]
    pub replication_interval_ms: Option<f64>,
    /// The ID of the source dataset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceDatasetId")]
    pub source_dataset_id: Option<String>,
    /// The ID of the source project.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceProjectId")]
    pub source_project_id: Option<String>,
    /// The ID of the source materialized view.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTableId")]
    pub source_table_id: Option<String>,
}

/// If specified, configures time-based
/// partitioning for this table. Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderTimePartitioning {
    /// Number of milliseconds for which to keep the
    /// storage for a partition.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationMs")]
    pub expiration_ms: Option<f64>,
    /// The field used to determine how to create a time-based
    /// partition. If time-based partitioning is enabled without this value, the
    /// table is partitioned based on the load time.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub field: Option<String>,
    /// If set to true, queries over this table
    /// require a partition filter that can be used for partition elimination to be
    /// specified. require_partition_filter is deprecated and will be removed in
    /// a future major release. Use the top level field with the same name instead.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "requirePartitionFilter")]
    pub require_partition_filter: Option<bool>,
    /// The supported types are DAY, HOUR, MONTH, and YEAR,
    /// which will generate one partition per day, hour, month, and year, respectively.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    pub r#type: Option<String>,
}

/// If specified, configures this table as a view.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub struct TableStatusAtProviderView {
    /// A query that BigQuery executes when the view is referenced.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub query: Option<String>,
    /// Specifies whether to use BigQuery's legacy SQL for this view.
    /// The default value is true. If set to false, the view will use BigQuery's standard SQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useLegacySql")]
    pub use_legacy_sql: Option<bool>,
}

