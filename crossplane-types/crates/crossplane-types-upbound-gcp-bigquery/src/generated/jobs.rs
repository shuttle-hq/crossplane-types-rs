// WARNING: generated by kopium - manual changes will be overwritten
// kopium version: 0.21.2

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use typed_builder::TypedBuilder;
    pub use schemars::JsonSchema;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::HashMap;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// JobSpec defines the desired state of Job
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
#[kube(group = "bigquery.gcp.upbound.io", version = "v1beta2", kind = "Job", plural = "jobs")]
#[kube(status = "JobStatus")]
pub struct JobSpec {
    /// DeletionPolicy specifies what will happen to the underlying external
    /// when this managed resource is deleted - either "Delete" or "Orphan" the
    /// external resource.
    /// This field is planned to be deprecated in favor of the ManagementPolicies
    /// field in a future release. Currently, both could be set independently and
    /// non-default values would be honored if the feature flag is enabled.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionPolicy")]
    #[builder(default)]
    pub deletion_policy: Option<JobDeletionPolicy>,
    #[serde(rename = "forProvider")]
    pub for_provider: JobForProvider,
    /// THIS IS A BETA FIELD. It will be honored
    /// unless the Management Policies feature flag is disabled.
    /// InitProvider holds the same fields as ForProvider, with the exception
    /// of Identifier and other resource reference fields. The fields that are
    /// in InitProvider are merged into ForProvider when the resource is created.
    /// The same fields are also added to the terraform ignore_changes hook, to
    /// avoid updating them after creation. This is useful for fields that are
    /// required on creation, but we do not desire to update them after creation,
    /// for example because of an external controller is managing them, like an
    /// autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initProvider")]
    #[builder(default)]
    pub init_provider: Option<JobInitProvider>,
    /// THIS IS A BETA FIELD. It is on by default but can be opted out
    /// through a Crossplane feature flag.
    /// ManagementPolicies specify the array of actions Crossplane is allowed to
    /// take on the managed and external resources.
    /// This field is planned to replace the DeletionPolicy field in a future
    /// release. Currently, both could be set independently and non-default
    /// values would be honored if the feature flag is enabled. If both are
    /// custom, the DeletionPolicy field will be ignored.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    /// and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managementPolicies")]
    #[builder(default)]
    pub management_policies: Option<Vec<String>>,
    /// ProviderConfigReference specifies how the provider that will be used to
    /// create, observe, update, and delete this managed resource should be
    /// configured.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providerConfigRef")]
    #[builder(default)]
    pub provider_config_ref: Option<JobProviderConfigRef>,
    /// PublishConnectionDetailsTo specifies the connection secret config which
    /// contains a name, metadata and a reference to secret store config to
    /// which any connection details for this managed resource should be written.
    /// Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "publishConnectionDetailsTo")]
    #[builder(default)]
    pub publish_connection_details_to: Option<JobPublishConnectionDetailsTo>,
    /// WriteConnectionSecretToReference specifies the namespace and name of a
    /// Secret to which any connection details for this managed resource should
    /// be written. Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    /// This field is planned to be replaced in a future release in favor of
    /// PublishConnectionDetailsTo. Currently, both could be set independently
    /// and connection details would be published to both without affecting
    /// each other.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeConnectionSecretToRef")]
    #[builder(default)]
    pub write_connection_secret_to_ref: Option<JobWriteConnectionSecretToRef>,
}

/// JobSpec defines the desired state of Job
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobDeletionPolicy {
    Orphan,
    Delete,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProvider {
    /// Copies a table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub copy: Option<JobForProviderCopy>,
    /// Configures an extract job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub extract: Option<JobForProviderExtract>,
    /// The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobId")]
    #[builder(default)]
    pub job_id: Option<String>,
    /// Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobTimeoutMs")]
    #[builder(default)]
    pub job_timeout_ms: Option<String>,
    /// The labels associated with this job. You can use these to organize and group your jobs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub labels: Option<HashMap<String, String>>,
    /// Configures a load job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub load: Option<JobForProviderLoad>,
    /// The geographic location of the job. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub location: Option<String>,
    /// The ID of the project in which the resource belongs.
    /// If it is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub project: Option<String>,
    /// Configures a query job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub query: Option<JobForProviderQuery>,
}

/// Copies a table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopy {
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobForProviderCopyDestinationEncryptionConfiguration>,
    /// The destination table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobForProviderCopyDestinationTable>,
    /// Source tables to copy.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTables")]
    #[builder(default)]
    pub source_tables: Option<Vec<JobForProviderCopySourceTables>>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
    /// Reference to a CryptoKey in kms to populate kmsKeyName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyNameRef")]
    #[builder(default)]
    pub kms_key_name_ref: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRef>,
    /// Selector for a CryptoKey in kms to populate kmsKeyName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyNameSelector")]
    #[builder(default)]
    pub kms_key_name_selector: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelector>,
}

/// Reference to a CryptoKey in kms to populate kmsKeyName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a CryptoKey in kms to populate kmsKeyName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// The destination table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobForProviderCopyDestinationTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobForProviderCopyDestinationTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobForProviderCopyDestinationTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobForProviderCopyDestinationTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderCopyDestinationTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderCopyDestinationTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderCopyDestinationTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderCopyDestinationTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderCopyDestinationTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderCopyDestinationTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderCopyDestinationTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderCopyDestinationTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderCopyDestinationTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderCopyDestinationTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopyDestinationTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderCopyDestinationTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderCopyDestinationTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderCopyDestinationTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderCopySourceTables {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

/// Configures an extract job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtract {
    /// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
    /// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub compression: Option<String>,
    /// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
    /// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
    /// The default value for models is SAVED_MODEL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationFormat")]
    #[builder(default)]
    pub destination_format: Option<String>,
    /// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationUris")]
    #[builder(default)]
    pub destination_uris: Option<Vec<String>>,
    /// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
    /// Default is ','
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    #[builder(default)]
    pub field_delimiter: Option<String>,
    /// Whether to print out a header row in the results. Default is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "printHeader")]
    #[builder(default)]
    pub print_header: Option<bool>,
    /// A reference to the model being exported.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceModel")]
    #[builder(default)]
    pub source_model: Option<JobForProviderExtractSourceModel>,
    /// A reference to the table being exported.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTable")]
    #[builder(default)]
    pub source_table: Option<JobForProviderExtractSourceTable>,
    /// Whether to use logical types when extracting to AVRO format.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useAvroLogicalTypes")]
    #[builder(default)]
    pub use_avro_logical_types: Option<bool>,
}

/// A reference to the model being exported.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceModel {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelId")]
    #[builder(default)]
    pub model_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
}

/// A reference to the table being exported.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobForProviderExtractSourceTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobForProviderExtractSourceTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobForProviderExtractSourceTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobForProviderExtractSourceTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderExtractSourceTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderExtractSourceTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderExtractSourceTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderExtractSourceTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderExtractSourceTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderExtractSourceTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderExtractSourceTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderExtractSourceTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderExtractSourceTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderExtractSourceTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderExtractSourceTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderExtractSourceTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderExtractSourceTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderExtractSourceTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Configures a load job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoad {
    /// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
    /// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
    /// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowJaggedRows")]
    #[builder(default)]
    pub allow_jagged_rows: Option<bool>,
    /// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowQuotedNewlines")]
    #[builder(default)]
    pub allow_quoted_newlines: Option<bool>,
    /// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub autodetect: Option<bool>,
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobForProviderLoadDestinationEncryptionConfiguration>,
    /// The destination table to load the data into.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobForProviderLoadDestinationTable>,
    /// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
    /// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
    /// has been split using the values of the quote and fieldDelimiter properties.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub encoding: Option<String>,
    /// The separator for fields in a CSV file. The separator can be any ISO-8859-1 single-byte character.
    /// To use a character in the range 128-255, you must encode the character as UTF8. BigQuery converts
    /// the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the
    /// data in its raw, binary state. BigQuery also supports the escape sequence "\t" to specify a tab separator.
    /// The default value is a comma (',').
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    #[builder(default)]
    pub field_delimiter: Option<String>,
    /// Indicates if BigQuery should allow extra values that are not represented in the table schema.
    /// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
    /// and if there are too many bad records, an invalid error is returned in the job result.
    /// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
    /// CSV: Trailing columns
    /// JSON: Named values that don't match any column names
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnknownValues")]
    #[builder(default)]
    pub ignore_unknown_values: Option<bool>,
    /// If sourceFormat is set to newline-delimited JSON, indicates whether it should be processed as a JSON variant such as GeoJSON.
    /// For a sourceFormat other than JSON, omit this field. If the sourceFormat is newline-delimited JSON: - for newline-delimited
    /// GeoJSON: set to GEOJSON.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonExtension")]
    #[builder(default)]
    pub json_extension: Option<String>,
    /// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
    /// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxBadRecords")]
    #[builder(default)]
    pub max_bad_records: Option<f64>,
    /// Specifies a string that represents a null value in a CSV file. For example, if you specify "\N", BigQuery interprets "\N" as a null value
    /// when loading a CSV file. The default value is the empty string. If you set this property to a custom value, BigQuery throws an error if an
    /// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
    /// an empty value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nullMarker")]
    #[builder(default)]
    pub null_marker: Option<String>,
    /// Parquet Options for load and make external tables.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parquetOptions")]
    #[builder(default)]
    pub parquet_options: Option<JobForProviderLoadParquetOptions>,
    /// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
    /// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
    /// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectionFields")]
    #[builder(default)]
    pub projection_fields: Option<Vec<String>>,
    /// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
    /// and then uses the first byte of the encoded string to split the data in its raw, binary state.
    /// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
    /// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub quote: Option<String>,
    /// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
    /// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
    /// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
    /// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
    /// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
    /// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaUpdateOptions")]
    #[builder(default)]
    pub schema_update_options: Option<Vec<String>>,
    /// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
    /// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
    /// When autodetect is on, the behavior is the following:
    /// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
    /// the row is read as data. Otherwise data is read starting from the second row.
    /// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
    /// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
    /// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    #[builder(default)]
    pub skip_leading_rows: Option<f64>,
    /// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
    /// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
    /// For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
    /// The default value is CSV.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceFormat")]
    #[builder(default)]
    pub source_format: Option<String>,
    /// The fully-qualified URIs that point to your data in Google Cloud.
    /// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
    /// and it must come after the 'bucket' name. Size limits related to load jobs apply
    /// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
    /// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
    /// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUris")]
    #[builder(default)]
    pub source_uris: Option<Vec<String>>,
    /// Time-based partitioning specification for the destination table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timePartitioning")]
    #[builder(default)]
    pub time_partitioning: Option<JobForProviderLoadTimePartitioning>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
}

/// The destination table to load the data into.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobForProviderLoadDestinationTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobForProviderLoadDestinationTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobForProviderLoadDestinationTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobForProviderLoadDestinationTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderLoadDestinationTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderLoadDestinationTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderLoadDestinationTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderLoadDestinationTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderLoadDestinationTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderLoadDestinationTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderLoadDestinationTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderLoadDestinationTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderLoadDestinationTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderLoadDestinationTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadDestinationTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderLoadDestinationTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderLoadDestinationTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderLoadDestinationTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Parquet Options for load and make external tables.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadParquetOptions {
    /// If sourceFormat is set to PARQUET, indicates whether to use schema inference specifically for Parquet LIST logical type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableListInference")]
    #[builder(default)]
    pub enable_list_inference: Option<bool>,
    /// If sourceFormat is set to PARQUET, indicates whether to infer Parquet ENUM logical type as STRING instead of BYTES by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enumAsString")]
    #[builder(default)]
    pub enum_as_string: Option<bool>,
}

/// Time-based partitioning specification for the destination table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderLoadTimePartitioning {
    /// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationMs")]
    #[builder(default)]
    pub expiration_ms: Option<String>,
    /// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
    /// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
    /// A wrapper is used here because an empty string is an invalid value.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub field: Option<String>,
    /// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
    /// but in OnePlatform the field will be treated as unset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    #[builder(default)]
    pub r#type: Option<String>,
}

/// Configures a query job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQuery {
    /// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
    /// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
    /// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowLargeResults")]
    #[builder(default)]
    pub allow_large_results: Option<bool>,
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "defaultDataset")]
    #[builder(default)]
    pub default_dataset: Option<JobForProviderQueryDefaultDataset>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobForProviderQueryDestinationEncryptionConfiguration>,
    /// Describes the table where the query results should be stored.
    /// This property must be set for large results that exceed the maximum response size.
    /// For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobForProviderQueryDestinationTable>,
    /// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
    /// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "flattenResults")]
    #[builder(default)]
    pub flatten_results: Option<bool>,
    /// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
    /// If unspecified, this will be set to your project default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBillingTier")]
    #[builder(default)]
    pub maximum_billing_tier: Option<f64>,
    /// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
    /// If unspecified, this will be set to your project default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBytesBilled")]
    #[builder(default)]
    pub maximum_bytes_billed: Option<String>,
    /// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parameterMode")]
    #[builder(default)]
    pub parameter_mode: Option<String>,
    /// Specifies a priority for the query.
    /// Default value is INTERACTIVE.
    /// Possible values are: INTERACTIVE, BATCH.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub priority: Option<String>,
    /// SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or standard SQL.
    /// NOTE: queries containing DML language
    /// (DELETE, UPDATE, MERGE, INSERT) must specify create_disposition = "" and write_disposition = "".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub query: Option<String>,
    /// Allows the schema of the destination table to be updated as a side effect of the query job.
    /// Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
    /// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table,
    /// specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema.
    /// One or more of the following values are specified:
    /// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
    /// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaUpdateOptions")]
    #[builder(default)]
    pub schema_update_options: Option<Vec<String>>,
    /// Options controlling the execution of scripts.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scriptOptions")]
    #[builder(default)]
    pub script_options: Option<JobForProviderQueryScriptOptions>,
    /// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
    /// If set to false, the query will use BigQuery's standard SQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useLegacySql")]
    #[builder(default)]
    pub use_legacy_sql: Option<bool>,
    /// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
    /// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
    /// The default value is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useQueryCache")]
    #[builder(default)]
    pub use_query_cache: Option<bool>,
    /// Describes user-defined function resources used in the query.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userDefinedFunctionResources")]
    #[builder(default)]
    pub user_defined_function_resources: Option<Vec<JobForProviderQueryUserDefinedFunctionResources>>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDefaultDataset {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobForProviderQueryDefaultDatasetDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobForProviderQueryDefaultDatasetDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDefaultDatasetDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderQueryDefaultDatasetDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDefaultDatasetDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderQueryDefaultDatasetDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderQueryDefaultDatasetDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDefaultDatasetDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDefaultDatasetDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDefaultDatasetDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderQueryDefaultDatasetDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDefaultDatasetDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
}

/// Describes the table where the query results should be stored.
/// This property must be set for large results that exceed the maximum response size.
/// For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobForProviderQueryDestinationTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobForProviderQueryDestinationTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobForProviderQueryDestinationTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobForProviderQueryDestinationTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderQueryDestinationTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderQueryDestinationTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderQueryDestinationTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderQueryDestinationTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderQueryDestinationTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderQueryDestinationTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderQueryDestinationTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderQueryDestinationTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderQueryDestinationTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobForProviderQueryDestinationTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryDestinationTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobForProviderQueryDestinationTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobForProviderQueryDestinationTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobForProviderQueryDestinationTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Options controlling the execution of scripts.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryScriptOptions {
    /// Determines which statement in the script represents the "key result",
    /// used to populate the schema and query results of the script job.
    /// Possible values are: LAST, FIRST_SELECT.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "keyResultStatement")]
    #[builder(default)]
    pub key_result_statement: Option<String>,
    /// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statementByteBudget")]
    #[builder(default)]
    pub statement_byte_budget: Option<String>,
    /// Timeout period for each statement in a script.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statementTimeoutMs")]
    #[builder(default)]
    pub statement_timeout_ms: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobForProviderQueryUserDefinedFunctionResources {
    /// An inline resource that contains code for a user-defined function (UDF).
    /// Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inlineCode")]
    #[builder(default)]
    pub inline_code: Option<String>,
    /// A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceUri")]
    #[builder(default)]
    pub resource_uri: Option<String>,
}

/// THIS IS A BETA FIELD. It will be honored
/// unless the Management Policies feature flag is disabled.
/// InitProvider holds the same fields as ForProvider, with the exception
/// of Identifier and other resource reference fields. The fields that are
/// in InitProvider are merged into ForProvider when the resource is created.
/// The same fields are also added to the terraform ignore_changes hook, to
/// avoid updating them after creation. This is useful for fields that are
/// required on creation, but we do not desire to update them after creation,
/// for example because of an external controller is managing them, like an
/// autoscaler.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProvider {
    /// Copies a table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub copy: Option<JobInitProviderCopy>,
    /// Configures an extract job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub extract: Option<JobInitProviderExtract>,
    /// The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobId")]
    #[builder(default)]
    pub job_id: Option<String>,
    /// Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobTimeoutMs")]
    #[builder(default)]
    pub job_timeout_ms: Option<String>,
    /// The labels associated with this job. You can use these to organize and group your jobs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub labels: Option<HashMap<String, String>>,
    /// Configures a load job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub load: Option<JobInitProviderLoad>,
    /// The geographic location of the job. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub location: Option<String>,
    /// The ID of the project in which the resource belongs.
    /// If it is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub project: Option<String>,
    /// Configures a query job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub query: Option<JobInitProviderQuery>,
}

/// Copies a table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopy {
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobInitProviderCopyDestinationEncryptionConfiguration>,
    /// The destination table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobInitProviderCopyDestinationTable>,
    /// Source tables to copy.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTables")]
    #[builder(default)]
    pub source_tables: Option<Vec<JobInitProviderCopySourceTables>>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
    /// Reference to a CryptoKey in kms to populate kmsKeyName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyNameRef")]
    #[builder(default)]
    pub kms_key_name_ref: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRef>,
    /// Selector for a CryptoKey in kms to populate kmsKeyName.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyNameSelector")]
    #[builder(default)]
    pub kms_key_name_selector: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelector>,
}

/// Reference to a CryptoKey in kms to populate kmsKeyName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a CryptoKey in kms to populate kmsKeyName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationEncryptionConfigurationKmsKeyNameSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// The destination table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobInitProviderCopyDestinationTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobInitProviderCopyDestinationTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobInitProviderCopyDestinationTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobInitProviderCopyDestinationTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderCopyDestinationTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderCopyDestinationTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderCopyDestinationTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderCopyDestinationTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderCopyDestinationTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderCopyDestinationTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderCopyDestinationTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderCopyDestinationTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderCopyDestinationTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderCopyDestinationTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopyDestinationTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderCopyDestinationTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderCopyDestinationTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderCopyDestinationTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderCopySourceTables {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

/// Configures an extract job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtract {
    /// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
    /// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub compression: Option<String>,
    /// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
    /// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
    /// The default value for models is SAVED_MODEL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationFormat")]
    #[builder(default)]
    pub destination_format: Option<String>,
    /// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationUris")]
    #[builder(default)]
    pub destination_uris: Option<Vec<String>>,
    /// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
    /// Default is ','
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    #[builder(default)]
    pub field_delimiter: Option<String>,
    /// Whether to print out a header row in the results. Default is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "printHeader")]
    #[builder(default)]
    pub print_header: Option<bool>,
    /// A reference to the model being exported.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceModel")]
    #[builder(default)]
    pub source_model: Option<JobInitProviderExtractSourceModel>,
    /// A reference to the table being exported.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTable")]
    #[builder(default)]
    pub source_table: Option<JobInitProviderExtractSourceTable>,
    /// Whether to use logical types when extracting to AVRO format.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useAvroLogicalTypes")]
    #[builder(default)]
    pub use_avro_logical_types: Option<bool>,
}

/// A reference to the model being exported.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceModel {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelId")]
    #[builder(default)]
    pub model_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
}

/// A reference to the table being exported.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobInitProviderExtractSourceTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobInitProviderExtractSourceTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobInitProviderExtractSourceTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobInitProviderExtractSourceTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderExtractSourceTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderExtractSourceTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderExtractSourceTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderExtractSourceTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderExtractSourceTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderExtractSourceTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderExtractSourceTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderExtractSourceTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderExtractSourceTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderExtractSourceTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderExtractSourceTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderExtractSourceTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderExtractSourceTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderExtractSourceTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Configures a load job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoad {
    /// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
    /// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
    /// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowJaggedRows")]
    #[builder(default)]
    pub allow_jagged_rows: Option<bool>,
    /// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowQuotedNewlines")]
    #[builder(default)]
    pub allow_quoted_newlines: Option<bool>,
    /// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub autodetect: Option<bool>,
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobInitProviderLoadDestinationEncryptionConfiguration>,
    /// The destination table to load the data into.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobInitProviderLoadDestinationTable>,
    /// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
    /// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
    /// has been split using the values of the quote and fieldDelimiter properties.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub encoding: Option<String>,
    /// The separator for fields in a CSV file. The separator can be any ISO-8859-1 single-byte character.
    /// To use a character in the range 128-255, you must encode the character as UTF8. BigQuery converts
    /// the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the
    /// data in its raw, binary state. BigQuery also supports the escape sequence "\t" to specify a tab separator.
    /// The default value is a comma (',').
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    #[builder(default)]
    pub field_delimiter: Option<String>,
    /// Indicates if BigQuery should allow extra values that are not represented in the table schema.
    /// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
    /// and if there are too many bad records, an invalid error is returned in the job result.
    /// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
    /// CSV: Trailing columns
    /// JSON: Named values that don't match any column names
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnknownValues")]
    #[builder(default)]
    pub ignore_unknown_values: Option<bool>,
    /// If sourceFormat is set to newline-delimited JSON, indicates whether it should be processed as a JSON variant such as GeoJSON.
    /// For a sourceFormat other than JSON, omit this field. If the sourceFormat is newline-delimited JSON: - for newline-delimited
    /// GeoJSON: set to GEOJSON.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonExtension")]
    #[builder(default)]
    pub json_extension: Option<String>,
    /// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
    /// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxBadRecords")]
    #[builder(default)]
    pub max_bad_records: Option<f64>,
    /// Specifies a string that represents a null value in a CSV file. For example, if you specify "\N", BigQuery interprets "\N" as a null value
    /// when loading a CSV file. The default value is the empty string. If you set this property to a custom value, BigQuery throws an error if an
    /// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
    /// an empty value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nullMarker")]
    #[builder(default)]
    pub null_marker: Option<String>,
    /// Parquet Options for load and make external tables.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parquetOptions")]
    #[builder(default)]
    pub parquet_options: Option<JobInitProviderLoadParquetOptions>,
    /// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
    /// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
    /// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectionFields")]
    #[builder(default)]
    pub projection_fields: Option<Vec<String>>,
    /// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
    /// and then uses the first byte of the encoded string to split the data in its raw, binary state.
    /// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
    /// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub quote: Option<String>,
    /// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
    /// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
    /// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
    /// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
    /// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
    /// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaUpdateOptions")]
    #[builder(default)]
    pub schema_update_options: Option<Vec<String>>,
    /// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
    /// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
    /// When autodetect is on, the behavior is the following:
    /// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
    /// the row is read as data. Otherwise data is read starting from the second row.
    /// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
    /// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
    /// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    #[builder(default)]
    pub skip_leading_rows: Option<f64>,
    /// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
    /// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
    /// For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
    /// The default value is CSV.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceFormat")]
    #[builder(default)]
    pub source_format: Option<String>,
    /// The fully-qualified URIs that point to your data in Google Cloud.
    /// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
    /// and it must come after the 'bucket' name. Size limits related to load jobs apply
    /// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
    /// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
    /// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUris")]
    #[builder(default)]
    pub source_uris: Option<Vec<String>>,
    /// Time-based partitioning specification for the destination table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timePartitioning")]
    #[builder(default)]
    pub time_partitioning: Option<JobInitProviderLoadTimePartitioning>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
}

/// The destination table to load the data into.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobInitProviderLoadDestinationTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobInitProviderLoadDestinationTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobInitProviderLoadDestinationTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobInitProviderLoadDestinationTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderLoadDestinationTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderLoadDestinationTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderLoadDestinationTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderLoadDestinationTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderLoadDestinationTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderLoadDestinationTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderLoadDestinationTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderLoadDestinationTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderLoadDestinationTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderLoadDestinationTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadDestinationTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderLoadDestinationTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderLoadDestinationTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderLoadDestinationTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Parquet Options for load and make external tables.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadParquetOptions {
    /// If sourceFormat is set to PARQUET, indicates whether to use schema inference specifically for Parquet LIST logical type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableListInference")]
    #[builder(default)]
    pub enable_list_inference: Option<bool>,
    /// If sourceFormat is set to PARQUET, indicates whether to infer Parquet ENUM logical type as STRING instead of BYTES by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enumAsString")]
    #[builder(default)]
    pub enum_as_string: Option<bool>,
}

/// Time-based partitioning specification for the destination table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderLoadTimePartitioning {
    /// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationMs")]
    #[builder(default)]
    pub expiration_ms: Option<String>,
    /// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
    /// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
    /// A wrapper is used here because an empty string is an invalid value.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub field: Option<String>,
    /// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
    /// but in OnePlatform the field will be treated as unset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    #[builder(default)]
    pub r#type: Option<String>,
}

/// Configures a query job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQuery {
    /// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
    /// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
    /// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowLargeResults")]
    #[builder(default)]
    pub allow_large_results: Option<bool>,
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "defaultDataset")]
    #[builder(default)]
    pub default_dataset: Option<JobInitProviderQueryDefaultDataset>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobInitProviderQueryDestinationEncryptionConfiguration>,
    /// Describes the table where the query results should be stored.
    /// This property must be set for large results that exceed the maximum response size.
    /// For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobInitProviderQueryDestinationTable>,
    /// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
    /// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "flattenResults")]
    #[builder(default)]
    pub flatten_results: Option<bool>,
    /// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
    /// If unspecified, this will be set to your project default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBillingTier")]
    #[builder(default)]
    pub maximum_billing_tier: Option<f64>,
    /// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
    /// If unspecified, this will be set to your project default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBytesBilled")]
    #[builder(default)]
    pub maximum_bytes_billed: Option<String>,
    /// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parameterMode")]
    #[builder(default)]
    pub parameter_mode: Option<String>,
    /// Specifies a priority for the query.
    /// Default value is INTERACTIVE.
    /// Possible values are: INTERACTIVE, BATCH.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub priority: Option<String>,
    /// SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or standard SQL.
    /// NOTE: queries containing DML language
    /// (DELETE, UPDATE, MERGE, INSERT) must specify create_disposition = "" and write_disposition = "".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub query: Option<String>,
    /// Allows the schema of the destination table to be updated as a side effect of the query job.
    /// Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
    /// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table,
    /// specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema.
    /// One or more of the following values are specified:
    /// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
    /// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaUpdateOptions")]
    #[builder(default)]
    pub schema_update_options: Option<Vec<String>>,
    /// Options controlling the execution of scripts.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scriptOptions")]
    #[builder(default)]
    pub script_options: Option<JobInitProviderQueryScriptOptions>,
    /// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
    /// If set to false, the query will use BigQuery's standard SQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useLegacySql")]
    #[builder(default)]
    pub use_legacy_sql: Option<bool>,
    /// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
    /// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
    /// The default value is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useQueryCache")]
    #[builder(default)]
    pub use_query_cache: Option<bool>,
    /// Describes user-defined function resources used in the query.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userDefinedFunctionResources")]
    #[builder(default)]
    pub user_defined_function_resources: Option<Vec<JobInitProviderQueryUserDefinedFunctionResources>>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDefaultDataset {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobInitProviderQueryDefaultDatasetDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobInitProviderQueryDefaultDatasetDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDefaultDatasetDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderQueryDefaultDatasetDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDefaultDatasetDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderQueryDefaultDatasetDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderQueryDefaultDatasetDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDefaultDatasetDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDefaultDatasetDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDefaultDatasetDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderQueryDefaultDatasetDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDefaultDatasetDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDefaultDatasetDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
}

/// Describes the table where the query results should be stored.
/// This property must be set for large results that exceed the maximum response size.
/// For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// Reference to a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdRef")]
    #[builder(default)]
    pub dataset_id_ref: Option<JobInitProviderQueryDestinationTableDatasetIdRef>,
    /// Selector for a Dataset in bigquery to populate datasetId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetIdSelector")]
    #[builder(default)]
    pub dataset_id_selector: Option<JobInitProviderQueryDestinationTableDatasetIdSelector>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
    /// Reference to a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdRef")]
    #[builder(default)]
    pub table_id_ref: Option<JobInitProviderQueryDestinationTableTableIdRef>,
    /// Selector for a Table in bigquery to populate tableId.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableIdSelector")]
    #[builder(default)]
    pub table_id_selector: Option<JobInitProviderQueryDestinationTableTableIdSelector>,
}

/// Reference to a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableDatasetIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderQueryDestinationTableDatasetIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableDatasetIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderQueryDestinationTableDatasetIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderQueryDestinationTableDatasetIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableDatasetIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableDatasetIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Dataset in bigquery to populate datasetId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableDatasetIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderQueryDestinationTableDatasetIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableDatasetIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderQueryDestinationTableDatasetIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderQueryDestinationTableDatasetIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableDatasetIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableDatasetIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Reference to a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableTableIdRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderQueryDestinationTableTableIdRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableTableIdRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderQueryDestinationTableTableIdRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderQueryDestinationTableTableIdRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableTableIdRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableTableIdRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Table in bigquery to populate tableId.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableTableIdSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobInitProviderQueryDestinationTableTableIdSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryDestinationTableTableIdSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobInitProviderQueryDestinationTableTableIdSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobInitProviderQueryDestinationTableTableIdSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableTableIdSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobInitProviderQueryDestinationTableTableIdSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Options controlling the execution of scripts.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryScriptOptions {
    /// Determines which statement in the script represents the "key result",
    /// used to populate the schema and query results of the script job.
    /// Possible values are: LAST, FIRST_SELECT.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "keyResultStatement")]
    #[builder(default)]
    pub key_result_statement: Option<String>,
    /// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statementByteBudget")]
    #[builder(default)]
    pub statement_byte_budget: Option<String>,
    /// Timeout period for each statement in a script.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statementTimeoutMs")]
    #[builder(default)]
    pub statement_timeout_ms: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobInitProviderQueryUserDefinedFunctionResources {
    /// An inline resource that contains code for a user-defined function (UDF).
    /// Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inlineCode")]
    #[builder(default)]
    pub inline_code: Option<String>,
    /// A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceUri")]
    #[builder(default)]
    pub resource_uri: Option<String>,
}

/// ProviderConfigReference specifies how the provider that will be used to
/// create, observe, update, and delete this managed resource should be
/// configured.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobProviderConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobProviderConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobProviderConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobProviderConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobProviderConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobProviderConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobProviderConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// PublishConnectionDetailsTo specifies the connection secret config which
/// contains a name, metadata and a reference to secret store config to
/// which any connection details for this managed resource should be written.
/// Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobPublishConnectionDetailsTo {
    /// SecretStoreConfigRef specifies which secret store config should be used
    /// for this ConnectionSecret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configRef")]
    #[builder(default)]
    pub config_ref: Option<JobPublishConnectionDetailsToConfigRef>,
    /// Metadata is the metadata for connection secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub metadata: Option<JobPublishConnectionDetailsToMetadata>,
    /// Name is the name of the connection secret.
    pub name: String,
}

/// SecretStoreConfigRef specifies which secret store config should be used
/// for this ConnectionSecret.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobPublishConnectionDetailsToConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<JobPublishConnectionDetailsToConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobPublishConnectionDetailsToConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<JobPublishConnectionDetailsToConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<JobPublishConnectionDetailsToConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobPublishConnectionDetailsToConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum JobPublishConnectionDetailsToConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Metadata is the metadata for connection secret.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobPublishConnectionDetailsToMetadata {
    /// Annotations are the annotations to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.annotations".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub annotations: Option<HashMap<String, String>>,
    /// Labels are the labels/tags to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.labels".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub labels: Option<HashMap<String, String>>,
    /// Type is the SecretType for the connection secret.
    /// - Only valid for Kubernetes Secret Stores.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    #[builder(default)]
    pub r#type: Option<String>,
}

/// WriteConnectionSecretToReference specifies the namespace and name of a
/// Secret to which any connection details for this managed resource should
/// be written. Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
/// This field is planned to be replaced in a future release in favor of
/// PublishConnectionDetailsTo. Currently, both could be set independently
/// and connection details would be published to both without affecting
/// each other.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobWriteConnectionSecretToRef {
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// JobStatus defines the observed state of Job.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatus {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "atProvider")]
    #[builder(default)]
    pub at_provider: Option<JobStatusAtProvider>,
    /// Conditions of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub conditions: Option<Vec<Condition>>,
    /// ObservedGeneration is the latest metadata.generation
    /// which resulted in either a ready state, or stalled due to error
    /// it can not recover from without human intervention.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    #[builder(default)]
    pub observed_generation: Option<i64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProvider {
    /// Copies a table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub copy: Option<JobStatusAtProviderCopy>,
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "effectiveLabels")]
    #[builder(default)]
    pub effective_labels: Option<HashMap<String, String>>,
    /// Configures an extract job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub extract: Option<JobStatusAtProviderExtract>,
    /// an identifier for the resource with format projects/{{project}}/jobs/{{job_id}}
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub id: Option<String>,
    /// The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobId")]
    #[builder(default)]
    pub job_id: Option<String>,
    /// Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobTimeoutMs")]
    #[builder(default)]
    pub job_timeout_ms: Option<String>,
    /// (Output)
    /// The type of the job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jobType")]
    #[builder(default)]
    pub job_type: Option<String>,
    /// The labels associated with this job. You can use these to organize and group your jobs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub labels: Option<HashMap<String, String>>,
    /// Configures a load job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub load: Option<JobStatusAtProviderLoad>,
    /// The geographic location of the job. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub location: Option<String>,
    /// The ID of the project in which the resource belongs.
    /// If it is not provided, the provider project is used.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub project: Option<String>,
    /// Configures a query job.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub query: Option<JobStatusAtProviderQuery>,
    /// The status of this job. Examine this value when polling an asynchronous job to see if the job is complete.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<Vec<JobStatusAtProviderStatus>>,
    /// (Output)
    /// The combination of labels configured directly on the resource
    /// and default labels configured on the provider.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "terraformLabels")]
    #[builder(default)]
    pub terraform_labels: Option<HashMap<String, String>>,
    /// Email address of the user who ran the job.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userEmail")]
    #[builder(default)]
    pub user_email: Option<String>,
}

/// Copies a table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderCopy {
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobStatusAtProviderCopyDestinationEncryptionConfiguration>,
    /// The destination table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobStatusAtProviderCopyDestinationTable>,
    /// Source tables to copy.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTables")]
    #[builder(default)]
    pub source_tables: Option<Vec<JobStatusAtProviderCopySourceTables>>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderCopyDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
    /// (Output)
    /// Describes the Cloud KMS encryption key version used to protect destination BigQuery table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyVersion")]
    #[builder(default)]
    pub kms_key_version: Option<String>,
}

/// The destination table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderCopyDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderCopySourceTables {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

/// Configures an extract job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderExtract {
    /// The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
    /// The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub compression: Option<String>,
    /// The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
    /// The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
    /// The default value for models is SAVED_MODEL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationFormat")]
    #[builder(default)]
    pub destination_format: Option<String>,
    /// A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationUris")]
    #[builder(default)]
    pub destination_uris: Option<Vec<String>>,
    /// When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
    /// Default is ','
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    #[builder(default)]
    pub field_delimiter: Option<String>,
    /// Whether to print out a header row in the results. Default is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "printHeader")]
    #[builder(default)]
    pub print_header: Option<bool>,
    /// A reference to the model being exported.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceModel")]
    #[builder(default)]
    pub source_model: Option<JobStatusAtProviderExtractSourceModel>,
    /// A reference to the table being exported.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceTable")]
    #[builder(default)]
    pub source_table: Option<JobStatusAtProviderExtractSourceTable>,
    /// Whether to use logical types when extracting to AVRO format.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useAvroLogicalTypes")]
    #[builder(default)]
    pub use_avro_logical_types: Option<bool>,
}

/// A reference to the model being exported.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderExtractSourceModel {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelId")]
    #[builder(default)]
    pub model_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
}

/// A reference to the table being exported.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderExtractSourceTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

/// Configures a load job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderLoad {
    /// Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
    /// If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
    /// an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowJaggedRows")]
    #[builder(default)]
    pub allow_jagged_rows: Option<bool>,
    /// Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
    /// The default value is false.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowQuotedNewlines")]
    #[builder(default)]
    pub allow_quoted_newlines: Option<bool>,
    /// Indicates if we should automatically infer the options and schema for CSV and JSON sources.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub autodetect: Option<bool>,
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobStatusAtProviderLoadDestinationEncryptionConfiguration>,
    /// The destination table to load the data into.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobStatusAtProviderLoadDestinationTable>,
    /// The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
    /// The default value is UTF-8. BigQuery decodes the data after the raw, binary data
    /// has been split using the values of the quote and fieldDelimiter properties.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub encoding: Option<String>,
    /// The separator for fields in a CSV file. The separator can be any ISO-8859-1 single-byte character.
    /// To use a character in the range 128-255, you must encode the character as UTF8. BigQuery converts
    /// the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the
    /// data in its raw, binary state. BigQuery also supports the escape sequence "\t" to specify a tab separator.
    /// The default value is a comma (',').
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "fieldDelimiter")]
    #[builder(default)]
    pub field_delimiter: Option<String>,
    /// Indicates if BigQuery should allow extra values that are not represented in the table schema.
    /// If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
    /// and if there are too many bad records, an invalid error is returned in the job result.
    /// The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
    /// CSV: Trailing columns
    /// JSON: Named values that don't match any column names
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "ignoreUnknownValues")]
    #[builder(default)]
    pub ignore_unknown_values: Option<bool>,
    /// If sourceFormat is set to newline-delimited JSON, indicates whether it should be processed as a JSON variant such as GeoJSON.
    /// For a sourceFormat other than JSON, omit this field. If the sourceFormat is newline-delimited JSON: - for newline-delimited
    /// GeoJSON: set to GEOJSON.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "jsonExtension")]
    #[builder(default)]
    pub json_extension: Option<String>,
    /// The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
    /// an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maxBadRecords")]
    #[builder(default)]
    pub max_bad_records: Option<f64>,
    /// Specifies a string that represents a null value in a CSV file. For example, if you specify "\N", BigQuery interprets "\N" as a null value
    /// when loading a CSV file. The default value is the empty string. If you set this property to a custom value, BigQuery throws an error if an
    /// empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
    /// an empty value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "nullMarker")]
    #[builder(default)]
    pub null_marker: Option<String>,
    /// Parquet Options for load and make external tables.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parquetOptions")]
    #[builder(default)]
    pub parquet_options: Option<JobStatusAtProviderLoadParquetOptions>,
    /// If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
    /// Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
    /// If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectionFields")]
    #[builder(default)]
    pub projection_fields: Option<Vec<String>>,
    /// The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
    /// and then uses the first byte of the encoded string to split the data in its raw, binary state.
    /// The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
    /// If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub quote: Option<String>,
    /// Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
    /// supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
    /// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
    /// For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
    /// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
    /// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaUpdateOptions")]
    #[builder(default)]
    pub schema_update_options: Option<Vec<String>>,
    /// The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
    /// The default value is 0. This property is useful if you have header rows in the file that should be skipped.
    /// When autodetect is on, the behavior is the following:
    /// skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
    /// the row is read as data. Otherwise data is read starting from the second row.
    /// skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
    /// skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
    /// row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "skipLeadingRows")]
    #[builder(default)]
    pub skip_leading_rows: Option<f64>,
    /// The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
    /// For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
    /// For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
    /// The default value is CSV.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceFormat")]
    #[builder(default)]
    pub source_format: Option<String>,
    /// The fully-qualified URIs that point to your data in Google Cloud.
    /// For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
    /// and it must come after the 'bucket' name. Size limits related to load jobs apply
    /// to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
    /// specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
    /// For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "sourceUris")]
    #[builder(default)]
    pub source_uris: Option<Vec<String>>,
    /// Time-based partitioning specification for the destination table.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "timePartitioning")]
    #[builder(default)]
    pub time_partitioning: Option<JobStatusAtProviderLoadTimePartitioning>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderLoadDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
    /// (Output)
    /// Describes the Cloud KMS encryption key version used to protect destination BigQuery table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyVersion")]
    #[builder(default)]
    pub kms_key_version: Option<String>,
}

/// The destination table to load the data into.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderLoadDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

/// Parquet Options for load and make external tables.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderLoadParquetOptions {
    /// If sourceFormat is set to PARQUET, indicates whether to use schema inference specifically for Parquet LIST logical type.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableListInference")]
    #[builder(default)]
    pub enable_list_inference: Option<bool>,
    /// If sourceFormat is set to PARQUET, indicates whether to infer Parquet ENUM logical type as STRING instead of BYTES by default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enumAsString")]
    #[builder(default)]
    pub enum_as_string: Option<bool>,
}

/// Time-based partitioning specification for the destination table.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderLoadTimePartitioning {
    /// Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "expirationMs")]
    #[builder(default)]
    pub expiration_ms: Option<String>,
    /// If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
    /// The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
    /// A wrapper is used here because an empty string is an invalid value.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub field: Option<String>,
    /// The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
    /// but in OnePlatform the field will be treated as unset.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    #[builder(default)]
    pub r#type: Option<String>,
}

/// Configures a query job.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderQuery {
    /// If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
    /// Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
    /// However, you must still set destinationTable when result size exceeds the allowed maximum response size.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "allowLargeResults")]
    #[builder(default)]
    pub allow_large_results: Option<bool>,
    /// Specifies whether the job is allowed to create new tables. The following values are supported:
    /// CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
    /// CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
    /// Creation, truncation and append actions occur as one atomic update upon job completion
    /// Default value is CREATE_IF_NEEDED.
    /// Possible values are: CREATE_IF_NEEDED, CREATE_NEVER.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "createDisposition")]
    #[builder(default)]
    pub create_disposition: Option<String>,
    /// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "defaultDataset")]
    #[builder(default)]
    pub default_dataset: Option<JobStatusAtProviderQueryDefaultDataset>,
    /// Custom encryption configuration (e.g., Cloud KMS keys)
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationEncryptionConfiguration")]
    #[builder(default)]
    pub destination_encryption_configuration: Option<JobStatusAtProviderQueryDestinationEncryptionConfiguration>,
    /// Describes the table where the query results should be stored.
    /// This property must be set for large results that exceed the maximum response size.
    /// For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "destinationTable")]
    #[builder(default)]
    pub destination_table: Option<JobStatusAtProviderQueryDestinationTable>,
    /// If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
    /// allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "flattenResults")]
    #[builder(default)]
    pub flatten_results: Option<bool>,
    /// Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
    /// If unspecified, this will be set to your project default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBillingTier")]
    #[builder(default)]
    pub maximum_billing_tier: Option<f64>,
    /// Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
    /// If unspecified, this will be set to your project default.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "maximumBytesBilled")]
    #[builder(default)]
    pub maximum_bytes_billed: Option<String>,
    /// Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "parameterMode")]
    #[builder(default)]
    pub parameter_mode: Option<String>,
    /// Specifies a priority for the query.
    /// Default value is INTERACTIVE.
    /// Possible values are: INTERACTIVE, BATCH.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub priority: Option<String>,
    /// SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or standard SQL.
    /// NOTE: queries containing DML language
    /// (DELETE, UPDATE, MERGE, INSERT) must specify create_disposition = "" and write_disposition = "".
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub query: Option<String>,
    /// Allows the schema of the destination table to be updated as a side effect of the query job.
    /// Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
    /// when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table,
    /// specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema.
    /// One or more of the following values are specified:
    /// ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
    /// ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "schemaUpdateOptions")]
    #[builder(default)]
    pub schema_update_options: Option<Vec<String>>,
    /// Options controlling the execution of scripts.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "scriptOptions")]
    #[builder(default)]
    pub script_options: Option<JobStatusAtProviderQueryScriptOptions>,
    /// Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
    /// If set to false, the query will use BigQuery's standard SQL.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useLegacySql")]
    #[builder(default)]
    pub use_legacy_sql: Option<bool>,
    /// Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
    /// tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
    /// The default value is true.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "useQueryCache")]
    #[builder(default)]
    pub use_query_cache: Option<bool>,
    /// Describes user-defined function resources used in the query.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "userDefinedFunctionResources")]
    #[builder(default)]
    pub user_defined_function_resources: Option<Vec<JobStatusAtProviderQueryUserDefinedFunctionResources>>,
    /// Specifies the action that occurs if the destination table already exists. The following values are supported:
    /// WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
    /// WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
    /// WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
    /// Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
    /// Creation, truncation and append actions occur as one atomic update upon job completion.
    /// Default value is WRITE_EMPTY.
    /// Possible values are: WRITE_TRUNCATE, WRITE_APPEND, WRITE_EMPTY.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeDisposition")]
    #[builder(default)]
    pub write_disposition: Option<String>,
}

/// Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderQueryDefaultDataset {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
}

/// Custom encryption configuration (e.g., Cloud KMS keys)
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderQueryDestinationEncryptionConfiguration {
    /// Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
    /// The BigQuery Service Account associated with your project requires access to this encryption key.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyName")]
    #[builder(default)]
    pub kms_key_name: Option<String>,
    /// (Output)
    /// Describes the Cloud KMS encryption key version used to protect destination BigQuery table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyVersion")]
    #[builder(default)]
    pub kms_key_version: Option<String>,
}

/// Describes the table where the query results should be stored.
/// This property must be set for large results that exceed the maximum response size.
/// For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderQueryDestinationTable {
    /// The ID of the dataset containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "datasetId")]
    #[builder(default)]
    pub dataset_id: Option<String>,
    /// The ID of the project containing this table.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "projectId")]
    #[builder(default)]
    pub project_id: Option<String>,
    /// The table. Can be specified {{table_id}} if project_id and dataset_id are also set,
    /// or of the form projects/{{project}}/datasets/{{dataset_id}}/tables/{{table_id}} if not.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tableId")]
    #[builder(default)]
    pub table_id: Option<String>,
}

/// Options controlling the execution of scripts.
/// Structure is documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderQueryScriptOptions {
    /// Determines which statement in the script represents the "key result",
    /// used to populate the schema and query results of the script job.
    /// Possible values are: LAST, FIRST_SELECT.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "keyResultStatement")]
    #[builder(default)]
    pub key_result_statement: Option<String>,
    /// Limit on the number of bytes billed per statement. Exceeding this budget results in an error.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statementByteBudget")]
    #[builder(default)]
    pub statement_byte_budget: Option<String>,
    /// Timeout period for each statement in a script.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "statementTimeoutMs")]
    #[builder(default)]
    pub statement_timeout_ms: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderQueryUserDefinedFunctionResources {
    /// An inline resource that contains code for a user-defined function (UDF).
    /// Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inlineCode")]
    #[builder(default)]
    pub inline_code: Option<String>,
    /// A code resource to load from a Google Cloud Storage URI (gs://bucket/path).
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "resourceUri")]
    #[builder(default)]
    pub resource_uri: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderStatus {
    /// (Output)
    /// Final error result of the job. If present, indicates that the job has completed and was unsuccessful.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "errorResult")]
    #[builder(default)]
    pub error_result: Option<Vec<JobStatusAtProviderStatusErrorResult>>,
    /// (Output)
    /// The first errors encountered during the running of the job. The final message
    /// includes the number of errors that caused the process to stop. Errors here do
    /// not necessarily mean that the job has not completed or was unsuccessful.
    /// Structure is documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub errors: Option<Vec<JobStatusAtProviderStatusErrors>>,
    /// (Output)
    /// Running state of the job. Valid states include 'PENDING', 'RUNNING', and 'DONE'.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub state: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderStatusErrorResult {
    /// The geographic location of the job. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub location: Option<String>,
    /// A human-readable description of the error.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub message: Option<String>,
    /// A short error code that summarizes the error.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub reason: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct JobStatusAtProviderStatusErrors {
    /// The geographic location of the job. The default value is US.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub location: Option<String>,
    /// A human-readable description of the error.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub message: Option<String>,
    /// A short error code that summarizes the error.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub reason: Option<String>,
}

