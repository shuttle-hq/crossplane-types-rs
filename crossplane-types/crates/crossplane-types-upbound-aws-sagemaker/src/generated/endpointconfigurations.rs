// WARNING: generated by kopium - manual changes will be overwritten
// kopium version: 0.21.2

#[allow(unused_imports)]
mod prelude {
    pub use std::collections::HashMap;

    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
    pub use kube::CustomResource;
    pub use schemars::JsonSchema;
    pub use serde::{Deserialize, Serialize};
    pub use typed_builder::TypedBuilder;
}
use self::prelude::*;

/// EndpointConfigurationSpec defines the desired state of EndpointConfiguration
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
#[kube(
    group = "sagemaker.aws.upbound.io",
    version = "v1beta2",
    kind = "EndpointConfiguration",
    plural = "endpointconfigurations"
)]
#[kube(status = "EndpointConfigurationStatus")]
pub struct EndpointConfigurationSpec {
    /// DeletionPolicy specifies what will happen to the underlying external
    /// when this managed resource is deleted - either "Delete" or "Orphan" the
    /// external resource.
    /// This field is planned to be deprecated in favor of the ManagementPolicies
    /// field in a future release. Currently, both could be set independently and
    /// non-default values would be honored if the feature flag is enabled.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "deletionPolicy"
    )]
    #[builder(default)]
    pub deletion_policy: Option<EndpointConfigurationDeletionPolicy>,
    #[serde(rename = "forProvider")]
    pub for_provider: EndpointConfigurationForProvider,
    /// THIS IS A BETA FIELD. It will be honored
    /// unless the Management Policies feature flag is disabled.
    /// InitProvider holds the same fields as ForProvider, with the exception
    /// of Identifier and other resource reference fields. The fields that are
    /// in InitProvider are merged into ForProvider when the resource is created.
    /// The same fields are also added to the terraform ignore_changes hook, to
    /// avoid updating them after creation. This is useful for fields that are
    /// required on creation, but we do not desire to update them after creation,
    /// for example because of an external controller is managing them, like an
    /// autoscaler.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initProvider"
    )]
    #[builder(default)]
    pub init_provider: Option<EndpointConfigurationInitProvider>,
    /// THIS IS A BETA FIELD. It is on by default but can be opted out
    /// through a Crossplane feature flag.
    /// ManagementPolicies specify the array of actions Crossplane is allowed to
    /// take on the managed and external resources.
    /// This field is planned to replace the DeletionPolicy field in a future
    /// release. Currently, both could be set independently and non-default
    /// values would be honored if the feature flag is enabled. If both are
    /// custom, the DeletionPolicy field will be ignored.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    /// and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managementPolicies"
    )]
    #[builder(default)]
    pub management_policies: Option<Vec<String>>,
    /// ProviderConfigReference specifies how the provider that will be used to
    /// create, observe, update, and delete this managed resource should be
    /// configured.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "providerConfigRef"
    )]
    #[builder(default)]
    pub provider_config_ref: Option<EndpointConfigurationProviderConfigRef>,
    /// PublishConnectionDetailsTo specifies the connection secret config which
    /// contains a name, metadata and a reference to secret store config to
    /// which any connection details for this managed resource should be written.
    /// Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "publishConnectionDetailsTo"
    )]
    #[builder(default)]
    pub publish_connection_details_to: Option<EndpointConfigurationPublishConnectionDetailsTo>,
    /// WriteConnectionSecretToReference specifies the namespace and name of a
    /// Secret to which any connection details for this managed resource should
    /// be written. Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    /// This field is planned to be replaced in a future release in favor of
    /// PublishConnectionDetailsTo. Currently, both could be set independently
    /// and connection details would be published to both without affecting
    /// each other.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "writeConnectionSecretToRef"
    )]
    #[builder(default)]
    pub write_connection_secret_to_ref: Option<EndpointConfigurationWriteConnectionSecretToRef>,
}

/// EndpointConfigurationSpec defines the desired state of EndpointConfiguration
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationDeletionPolicy {
    Orphan,
    Delete,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProvider {
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "asyncInferenceConfig"
    )]
    #[builder(default)]
    pub async_inference_config: Option<EndpointConfigurationForProviderAsyncInferenceConfig>,
    /// Specifies the parameters to capture input/output of SageMaker models endpoints. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "dataCaptureConfig"
    )]
    #[builder(default)]
    pub data_capture_config: Option<EndpointConfigurationForProviderDataCaptureConfig>,
    /// Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArn")]
    #[builder(default)]
    pub kms_key_arn: Option<String>,
    /// Reference to a Key in kms to populate kmsKeyArn.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "kmsKeyArnRef"
    )]
    #[builder(default)]
    pub kms_key_arn_ref: Option<EndpointConfigurationForProviderKmsKeyArnRef>,
    /// Selector for a Key in kms to populate kmsKeyArn.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "kmsKeyArnSelector"
    )]
    #[builder(default)]
    pub kms_key_arn_selector: Option<EndpointConfigurationForProviderKmsKeyArnSelector>,
    /// An list of ProductionVariant objects, one for each model that you want to host at this endpoint. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "productionVariants"
    )]
    #[builder(default)]
    pub production_variants: Option<Vec<EndpointConfigurationForProviderProductionVariants>>,
    /// Region is the region you'd like your resource to be created in.
    pub region: String,
    /// Array of ProductionVariant objects. There is one for each model that you want to host at this endpoint in shadow mode with production traffic replicated from the model specified on ProductionVariants. If you use this field, you can only specify one variant for ProductionVariants and one variant for ShadowProductionVariants. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "shadowProductionVariants"
    )]
    #[builder(default)]
    pub shadow_production_variants:
        Option<Vec<EndpointConfigurationForProviderShadowProductionVariants>>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub tags: Option<HashMap<String, String>>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderAsyncInferenceConfig {
    /// Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "clientConfig"
    )]
    #[builder(default)]
    pub client_config: Option<EndpointConfigurationForProviderAsyncInferenceConfigClientConfig>,
    /// Specifies the configuration for asynchronous inference invocation outputs.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "outputConfig"
    )]
    #[builder(default)]
    pub output_config: Option<EndpointConfigurationForProviderAsyncInferenceConfigOutputConfig>,
}

/// Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderAsyncInferenceConfigClientConfig {
    /// The maximum number of concurrent requests sent by the SageMaker client to the model container. If no value is provided, Amazon SageMaker will choose an optimal value for you.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrentInvocationsPerInstance"
    )]
    #[builder(default)]
    pub max_concurrent_invocations_per_instance: Option<f64>,
}

/// Specifies the configuration for asynchronous inference invocation outputs.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderAsyncInferenceConfigOutputConfig {
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt the asynchronous inference output in Amazon S3.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
    /// Specifies the configuration for notifications of inference results for asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "notificationConfig"
    )]
    #[builder(default)]
    pub notification_config:
        Option<EndpointConfigurationForProviderAsyncInferenceConfigOutputConfigNotificationConfig>,
    /// The Amazon S3 location to upload failure inference responses to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "s3FailurePath"
    )]
    #[builder(default)]
    pub s3_failure_path: Option<String>,
    /// The Amazon S3 location to upload inference responses to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "s3OutputPath"
    )]
    #[builder(default)]
    pub s3_output_path: Option<String>,
}

/// Specifies the configuration for notifications of inference results for asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderAsyncInferenceConfigOutputConfigNotificationConfig {
    /// Amazon SNS topic to post a notification to when inference fails. If no topic is provided, no notification is sent on failure.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "errorTopic"
    )]
    #[builder(default)]
    pub error_topic: Option<String>,
    /// The Amazon SNS topics where you want the inference response to be included. Valid values are SUCCESS_NOTIFICATION_TOPIC and ERROR_NOTIFICATION_TOPIC.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "includeInferenceResponseIn"
    )]
    #[builder(default)]
    pub include_inference_response_in: Option<Vec<String>>,
    /// Amazon SNS topic to post a notification to when inference completes successfully. If no topic is provided, no notification is sent on success.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "successTopic"
    )]
    #[builder(default)]
    pub success_topic: Option<String>,
}

/// Specifies the parameters to capture input/output of SageMaker models endpoints. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderDataCaptureConfig {
    /// The content type headers to capture. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureContentTypeHeader"
    )]
    #[builder(default)]
    pub capture_content_type_header:
        Option<EndpointConfigurationForProviderDataCaptureConfigCaptureContentTypeHeader>,
    /// Specifies what data to capture. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureOptions"
    )]
    #[builder(default)]
    pub capture_options:
        Option<Vec<EndpointConfigurationForProviderDataCaptureConfigCaptureOptions>>,
    /// The URL for S3 location where the captured data is stored.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// Flag to enable data capture. Defaults to false.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableCapture"
    )]
    #[builder(default)]
    pub enable_capture: Option<bool>,
    /// Portion of data to capture. Should be between 0 and 100.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialSamplingPercentage"
    )]
    #[builder(default)]
    pub initial_sampling_percentage: Option<f64>,
    /// Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt the captured data on Amazon S3.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// The content type headers to capture. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderDataCaptureConfigCaptureContentTypeHeader {
    /// The CSV content type headers to capture.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "csvContentTypes"
    )]
    #[builder(default)]
    pub csv_content_types: Option<Vec<String>>,
    /// The JSON content type headers to capture.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "jsonContentTypes"
    )]
    #[builder(default)]
    pub json_content_types: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderDataCaptureConfigCaptureOptions {
    /// Specifies the data to be captured. Should be one of Input, Output or InputAndOutput.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureMode"
    )]
    #[builder(default)]
    pub capture_mode: Option<String>,
}

/// Reference to a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderKmsKeyArnRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationForProviderKmsKeyArnRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderKmsKeyArnRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<EndpointConfigurationForProviderKmsKeyArnRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<EndpointConfigurationForProviderKmsKeyArnRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderKmsKeyArnRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderKmsKeyArnRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderKmsKeyArnSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchControllerRef"
    )]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchLabels"
    )]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationForProviderKmsKeyArnSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderKmsKeyArnSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<EndpointConfigurationForProviderKmsKeyArnSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<EndpointConfigurationForProviderKmsKeyArnSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderKmsKeyArnSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderKmsKeyArnSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariants {
    /// The size of the Elastic Inference (EI) instance to use for the production variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "acceleratorType"
    )]
    #[builder(default)]
    pub accelerator_type: Option<String>,
    /// The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see How Your Container Should Respond to Health Check (Ping) Requests. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "containerStartupHealthCheckTimeoutInSeconds"
    )]
    #[builder(default)]
    pub container_startup_health_check_timeout_in_seconds: Option<f64>,
    /// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "coreDumpConfig"
    )]
    #[builder(default)]
    pub core_dump_config: Option<EndpointConfigurationForProviderProductionVariantsCoreDumpConfig>,
    /// You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableSsmAccess"
    )]
    #[builder(default)]
    pub enable_ssm_access: Option<bool>,
    /// Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "inferenceAmiVersion"
    )]
    #[builder(default)]
    pub inference_ami_version: Option<String>,
    /// Initial number of instances used for auto-scaling.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialInstanceCount"
    )]
    #[builder(default)]
    pub initial_instance_count: Option<f64>,
    /// Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialVariantWeight"
    )]
    #[builder(default)]
    pub initial_variant_weight: Option<f64>,
    /// The type of instance to start.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "instanceType"
    )]
    #[builder(default)]
    pub instance_type: Option<String>,
    /// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managedInstanceScaling"
    )]
    #[builder(default)]
    pub managed_instance_scaling:
        Option<EndpointConfigurationForProviderProductionVariantsManagedInstanceScaling>,
    /// The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelDataDownloadTimeoutInSeconds"
    )]
    #[builder(default)]
    pub model_data_download_timeout_in_seconds: Option<f64>,
    /// The name of the model to use.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelName")]
    #[builder(default)]
    pub model_name: Option<String>,
    /// Reference to a Model in sagemaker to populate modelName.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelNameRef"
    )]
    #[builder(default)]
    pub model_name_ref: Option<EndpointConfigurationForProviderProductionVariantsModelNameRef>,
    /// Selector for a Model in sagemaker to populate modelName.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelNameSelector"
    )]
    #[builder(default)]
    pub model_name_selector:
        Option<EndpointConfigurationForProviderProductionVariantsModelNameSelector>,
    /// Sets how the endpoint routes incoming traffic. See routing_config below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingConfig"
    )]
    #[builder(default)]
    pub routing_config:
        Option<Vec<EndpointConfigurationForProviderProductionVariantsRoutingConfig>>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "serverlessConfig"
    )]
    #[builder(default)]
    pub serverless_config:
        Option<EndpointConfigurationForProviderProductionVariantsServerlessConfig>,
    /// The name of the variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "variantName"
    )]
    #[builder(default)]
    pub variant_name: Option<String>,
    /// The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between 1 and 512.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "volumeSizeInGb"
    )]
    #[builder(default)]
    pub volume_size_in_gb: Option<f64>,
}

/// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsCoreDumpConfig {
    /// The Amazon S3 bucket to send the core dump to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that SageMaker uses to encrypt the core dump data at rest using Amazon S3 server-side encryption.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsManagedInstanceScaling {
    /// The maximum number of instances that the endpoint can provision when it scales up to accommodate an increase in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxInstanceCount"
    )]
    #[builder(default)]
    pub max_instance_count: Option<f64>,
    /// The minimum number of instances that the endpoint must retain when it scales down to accommodate a decrease in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "minInstanceCount"
    )]
    #[builder(default)]
    pub min_instance_count: Option<f64>,
    /// Indicates whether managed instance scaling is enabled. Valid values are ENABLED and DISABLED.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<String>,
}

/// Reference to a Model in sagemaker to populate modelName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsModelNameRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationForProviderProductionVariantsModelNameRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsModelNameRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution:
        Option<EndpointConfigurationForProviderProductionVariantsModelNameRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve:
        Option<EndpointConfigurationForProviderProductionVariantsModelNameRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderProductionVariantsModelNameRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderProductionVariantsModelNameRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Model in sagemaker to populate modelName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsModelNameSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchControllerRef"
    )]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchLabels"
    )]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationForProviderProductionVariantsModelNameSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsModelNameSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution:
        Option<EndpointConfigurationForProviderProductionVariantsModelNameSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve:
        Option<EndpointConfigurationForProviderProductionVariantsModelNameSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderProductionVariantsModelNameSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationForProviderProductionVariantsModelNameSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsRoutingConfig {
    /// Sets how the endpoint routes incoming traffic. Valid values are LEAST_OUTSTANDING_REQUESTS and RANDOM. LEAST_OUTSTANDING_REQUESTS routes requests to the specific instances that have more capacity to process them. RANDOM routes each request to a randomly chosen instance.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingStrategy"
    )]
    #[builder(default)]
    pub routing_strategy: Option<String>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderProductionVariantsServerlessConfig {
    /// The maximum number of concurrent invocations your serverless endpoint can process. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrency"
    )]
    #[builder(default)]
    pub max_concurrency: Option<f64>,
    /// The memory size of your serverless endpoint. Valid values are in 1 GB increments: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "memorySizeInMb"
    )]
    #[builder(default)]
    pub memory_size_in_mb: Option<f64>,
    /// The amount of provisioned concurrency to allocate for the serverless endpoint. Should be less than or equal to max_concurrency. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "provisionedConcurrency"
    )]
    #[builder(default)]
    pub provisioned_concurrency: Option<f64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderShadowProductionVariants {
    /// The size of the Elastic Inference (EI) instance to use for the production variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "acceleratorType"
    )]
    #[builder(default)]
    pub accelerator_type: Option<String>,
    /// The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see How Your Container Should Respond to Health Check (Ping) Requests. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "containerStartupHealthCheckTimeoutInSeconds"
    )]
    #[builder(default)]
    pub container_startup_health_check_timeout_in_seconds: Option<f64>,
    /// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "coreDumpConfig"
    )]
    #[builder(default)]
    pub core_dump_config:
        Option<EndpointConfigurationForProviderShadowProductionVariantsCoreDumpConfig>,
    /// You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableSsmAccess"
    )]
    #[builder(default)]
    pub enable_ssm_access: Option<bool>,
    /// Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "inferenceAmiVersion"
    )]
    #[builder(default)]
    pub inference_ami_version: Option<String>,
    /// Initial number of instances used for auto-scaling.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialInstanceCount"
    )]
    #[builder(default)]
    pub initial_instance_count: Option<f64>,
    /// Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialVariantWeight"
    )]
    #[builder(default)]
    pub initial_variant_weight: Option<f64>,
    /// The type of instance to start.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "instanceType"
    )]
    #[builder(default)]
    pub instance_type: Option<String>,
    /// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managedInstanceScaling"
    )]
    #[builder(default)]
    pub managed_instance_scaling:
        Option<EndpointConfigurationForProviderShadowProductionVariantsManagedInstanceScaling>,
    /// The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelDataDownloadTimeoutInSeconds"
    )]
    #[builder(default)]
    pub model_data_download_timeout_in_seconds: Option<f64>,
    /// The name of the model to use.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelName")]
    #[builder(default)]
    pub model_name: Option<String>,
    /// Sets how the endpoint routes incoming traffic. See routing_config below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingConfig"
    )]
    #[builder(default)]
    pub routing_config:
        Option<Vec<EndpointConfigurationForProviderShadowProductionVariantsRoutingConfig>>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "serverlessConfig"
    )]
    #[builder(default)]
    pub serverless_config:
        Option<EndpointConfigurationForProviderShadowProductionVariantsServerlessConfig>,
    /// The name of the variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "variantName"
    )]
    #[builder(default)]
    pub variant_name: Option<String>,
    /// The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between 1 and 512.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "volumeSizeInGb"
    )]
    #[builder(default)]
    pub volume_size_in_gb: Option<f64>,
}

/// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderShadowProductionVariantsCoreDumpConfig {
    /// The Amazon S3 bucket to send the core dump to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that SageMaker uses to encrypt the core dump data at rest using Amazon S3 server-side encryption.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderShadowProductionVariantsManagedInstanceScaling {
    /// The maximum number of instances that the endpoint can provision when it scales up to accommodate an increase in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxInstanceCount"
    )]
    #[builder(default)]
    pub max_instance_count: Option<f64>,
    /// The minimum number of instances that the endpoint must retain when it scales down to accommodate a decrease in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "minInstanceCount"
    )]
    #[builder(default)]
    pub min_instance_count: Option<f64>,
    /// Indicates whether managed instance scaling is enabled. Valid values are ENABLED and DISABLED.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderShadowProductionVariantsRoutingConfig {
    /// Sets how the endpoint routes incoming traffic. Valid values are LEAST_OUTSTANDING_REQUESTS and RANDOM. LEAST_OUTSTANDING_REQUESTS routes requests to the specific instances that have more capacity to process them. RANDOM routes each request to a randomly chosen instance.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingStrategy"
    )]
    #[builder(default)]
    pub routing_strategy: Option<String>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationForProviderShadowProductionVariantsServerlessConfig {
    /// The maximum number of concurrent invocations your serverless endpoint can process. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrency"
    )]
    #[builder(default)]
    pub max_concurrency: Option<f64>,
    /// The memory size of your serverless endpoint. Valid values are in 1 GB increments: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "memorySizeInMb"
    )]
    #[builder(default)]
    pub memory_size_in_mb: Option<f64>,
    /// The amount of provisioned concurrency to allocate for the serverless endpoint. Should be less than or equal to max_concurrency. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "provisionedConcurrency"
    )]
    #[builder(default)]
    pub provisioned_concurrency: Option<f64>,
}

/// THIS IS A BETA FIELD. It will be honored
/// unless the Management Policies feature flag is disabled.
/// InitProvider holds the same fields as ForProvider, with the exception
/// of Identifier and other resource reference fields. The fields that are
/// in InitProvider are merged into ForProvider when the resource is created.
/// The same fields are also added to the terraform ignore_changes hook, to
/// avoid updating them after creation. This is useful for fields that are
/// required on creation, but we do not desire to update them after creation,
/// for example because of an external controller is managing them, like an
/// autoscaler.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProvider {
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "asyncInferenceConfig"
    )]
    #[builder(default)]
    pub async_inference_config: Option<EndpointConfigurationInitProviderAsyncInferenceConfig>,
    /// Specifies the parameters to capture input/output of SageMaker models endpoints. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "dataCaptureConfig"
    )]
    #[builder(default)]
    pub data_capture_config: Option<EndpointConfigurationInitProviderDataCaptureConfig>,
    /// Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArn")]
    #[builder(default)]
    pub kms_key_arn: Option<String>,
    /// Reference to a Key in kms to populate kmsKeyArn.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "kmsKeyArnRef"
    )]
    #[builder(default)]
    pub kms_key_arn_ref: Option<EndpointConfigurationInitProviderKmsKeyArnRef>,
    /// Selector for a Key in kms to populate kmsKeyArn.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "kmsKeyArnSelector"
    )]
    #[builder(default)]
    pub kms_key_arn_selector: Option<EndpointConfigurationInitProviderKmsKeyArnSelector>,
    /// An list of ProductionVariant objects, one for each model that you want to host at this endpoint. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "productionVariants"
    )]
    #[builder(default)]
    pub production_variants: Option<Vec<EndpointConfigurationInitProviderProductionVariants>>,
    /// Array of ProductionVariant objects. There is one for each model that you want to host at this endpoint in shadow mode with production traffic replicated from the model specified on ProductionVariants. If you use this field, you can only specify one variant for ProductionVariants and one variant for ShadowProductionVariants. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "shadowProductionVariants"
    )]
    #[builder(default)]
    pub shadow_production_variants:
        Option<Vec<EndpointConfigurationInitProviderShadowProductionVariants>>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub tags: Option<HashMap<String, String>>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderAsyncInferenceConfig {
    /// Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "clientConfig"
    )]
    #[builder(default)]
    pub client_config: Option<EndpointConfigurationInitProviderAsyncInferenceConfigClientConfig>,
    /// Specifies the configuration for asynchronous inference invocation outputs.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "outputConfig"
    )]
    #[builder(default)]
    pub output_config: Option<EndpointConfigurationInitProviderAsyncInferenceConfigOutputConfig>,
}

/// Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderAsyncInferenceConfigClientConfig {
    /// The maximum number of concurrent requests sent by the SageMaker client to the model container. If no value is provided, Amazon SageMaker will choose an optimal value for you.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrentInvocationsPerInstance"
    )]
    #[builder(default)]
    pub max_concurrent_invocations_per_instance: Option<f64>,
}

/// Specifies the configuration for asynchronous inference invocation outputs.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderAsyncInferenceConfigOutputConfig {
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt the asynchronous inference output in Amazon S3.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
    /// Specifies the configuration for notifications of inference results for asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "notificationConfig"
    )]
    #[builder(default)]
    pub notification_config:
        Option<EndpointConfigurationInitProviderAsyncInferenceConfigOutputConfigNotificationConfig>,
    /// The Amazon S3 location to upload failure inference responses to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "s3FailurePath"
    )]
    #[builder(default)]
    pub s3_failure_path: Option<String>,
    /// The Amazon S3 location to upload inference responses to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "s3OutputPath"
    )]
    #[builder(default)]
    pub s3_output_path: Option<String>,
}

/// Specifies the configuration for notifications of inference results for asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderAsyncInferenceConfigOutputConfigNotificationConfig {
    /// Amazon SNS topic to post a notification to when inference fails. If no topic is provided, no notification is sent on failure.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "errorTopic"
    )]
    #[builder(default)]
    pub error_topic: Option<String>,
    /// The Amazon SNS topics where you want the inference response to be included. Valid values are SUCCESS_NOTIFICATION_TOPIC and ERROR_NOTIFICATION_TOPIC.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "includeInferenceResponseIn"
    )]
    #[builder(default)]
    pub include_inference_response_in: Option<Vec<String>>,
    /// Amazon SNS topic to post a notification to when inference completes successfully. If no topic is provided, no notification is sent on success.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "successTopic"
    )]
    #[builder(default)]
    pub success_topic: Option<String>,
}

/// Specifies the parameters to capture input/output of SageMaker models endpoints. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderDataCaptureConfig {
    /// The content type headers to capture. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureContentTypeHeader"
    )]
    #[builder(default)]
    pub capture_content_type_header:
        Option<EndpointConfigurationInitProviderDataCaptureConfigCaptureContentTypeHeader>,
    /// Specifies what data to capture. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureOptions"
    )]
    #[builder(default)]
    pub capture_options:
        Option<Vec<EndpointConfigurationInitProviderDataCaptureConfigCaptureOptions>>,
    /// The URL for S3 location where the captured data is stored.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// Flag to enable data capture. Defaults to false.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableCapture"
    )]
    #[builder(default)]
    pub enable_capture: Option<bool>,
    /// Portion of data to capture. Should be between 0 and 100.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialSamplingPercentage"
    )]
    #[builder(default)]
    pub initial_sampling_percentage: Option<f64>,
    /// Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt the captured data on Amazon S3.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// The content type headers to capture. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderDataCaptureConfigCaptureContentTypeHeader {
    /// The CSV content type headers to capture.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "csvContentTypes"
    )]
    #[builder(default)]
    pub csv_content_types: Option<Vec<String>>,
    /// The JSON content type headers to capture.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "jsonContentTypes"
    )]
    #[builder(default)]
    pub json_content_types: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderDataCaptureConfigCaptureOptions {
    /// Specifies the data to be captured. Should be one of Input, Output or InputAndOutput.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureMode"
    )]
    #[builder(default)]
    pub capture_mode: Option<String>,
}

/// Reference to a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderKmsKeyArnRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationInitProviderKmsKeyArnRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderKmsKeyArnRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<EndpointConfigurationInitProviderKmsKeyArnRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<EndpointConfigurationInitProviderKmsKeyArnRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderKmsKeyArnRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderKmsKeyArnRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Key in kms to populate kmsKeyArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderKmsKeyArnSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchControllerRef"
    )]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchLabels"
    )]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationInitProviderKmsKeyArnSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderKmsKeyArnSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<EndpointConfigurationInitProviderKmsKeyArnSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<EndpointConfigurationInitProviderKmsKeyArnSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderKmsKeyArnSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderKmsKeyArnSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariants {
    /// The size of the Elastic Inference (EI) instance to use for the production variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "acceleratorType"
    )]
    #[builder(default)]
    pub accelerator_type: Option<String>,
    /// The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see How Your Container Should Respond to Health Check (Ping) Requests. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "containerStartupHealthCheckTimeoutInSeconds"
    )]
    #[builder(default)]
    pub container_startup_health_check_timeout_in_seconds: Option<f64>,
    /// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "coreDumpConfig"
    )]
    #[builder(default)]
    pub core_dump_config: Option<EndpointConfigurationInitProviderProductionVariantsCoreDumpConfig>,
    /// You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableSsmAccess"
    )]
    #[builder(default)]
    pub enable_ssm_access: Option<bool>,
    /// Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "inferenceAmiVersion"
    )]
    #[builder(default)]
    pub inference_ami_version: Option<String>,
    /// Initial number of instances used for auto-scaling.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialInstanceCount"
    )]
    #[builder(default)]
    pub initial_instance_count: Option<f64>,
    /// Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialVariantWeight"
    )]
    #[builder(default)]
    pub initial_variant_weight: Option<f64>,
    /// The type of instance to start.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "instanceType"
    )]
    #[builder(default)]
    pub instance_type: Option<String>,
    /// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managedInstanceScaling"
    )]
    #[builder(default)]
    pub managed_instance_scaling:
        Option<EndpointConfigurationInitProviderProductionVariantsManagedInstanceScaling>,
    /// The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelDataDownloadTimeoutInSeconds"
    )]
    #[builder(default)]
    pub model_data_download_timeout_in_seconds: Option<f64>,
    /// The name of the model to use.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelName")]
    #[builder(default)]
    pub model_name: Option<String>,
    /// Reference to a Model in sagemaker to populate modelName.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelNameRef"
    )]
    #[builder(default)]
    pub model_name_ref: Option<EndpointConfigurationInitProviderProductionVariantsModelNameRef>,
    /// Selector for a Model in sagemaker to populate modelName.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelNameSelector"
    )]
    #[builder(default)]
    pub model_name_selector:
        Option<EndpointConfigurationInitProviderProductionVariantsModelNameSelector>,
    /// Sets how the endpoint routes incoming traffic. See routing_config below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingConfig"
    )]
    #[builder(default)]
    pub routing_config:
        Option<Vec<EndpointConfigurationInitProviderProductionVariantsRoutingConfig>>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "serverlessConfig"
    )]
    #[builder(default)]
    pub serverless_config:
        Option<EndpointConfigurationInitProviderProductionVariantsServerlessConfig>,
    /// The name of the variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "variantName"
    )]
    #[builder(default)]
    pub variant_name: Option<String>,
    /// The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between 1 and 512.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "volumeSizeInGb"
    )]
    #[builder(default)]
    pub volume_size_in_gb: Option<f64>,
}

/// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsCoreDumpConfig {
    /// The Amazon S3 bucket to send the core dump to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that SageMaker uses to encrypt the core dump data at rest using Amazon S3 server-side encryption.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsManagedInstanceScaling {
    /// The maximum number of instances that the endpoint can provision when it scales up to accommodate an increase in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxInstanceCount"
    )]
    #[builder(default)]
    pub max_instance_count: Option<f64>,
    /// The minimum number of instances that the endpoint must retain when it scales down to accommodate a decrease in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "minInstanceCount"
    )]
    #[builder(default)]
    pub min_instance_count: Option<f64>,
    /// Indicates whether managed instance scaling is enabled. Valid values are ENABLED and DISABLED.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<String>,
}

/// Reference to a Model in sagemaker to populate modelName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsModelNameRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationInitProviderProductionVariantsModelNameRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsModelNameRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution:
        Option<EndpointConfigurationInitProviderProductionVariantsModelNameRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve:
        Option<EndpointConfigurationInitProviderProductionVariantsModelNameRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderProductionVariantsModelNameRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderProductionVariantsModelNameRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Model in sagemaker to populate modelName.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsModelNameSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchControllerRef"
    )]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "matchLabels"
    )]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationInitProviderProductionVariantsModelNameSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsModelNameSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<
        EndpointConfigurationInitProviderProductionVariantsModelNameSelectorPolicyResolution,
    >,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve:
        Option<EndpointConfigurationInitProviderProductionVariantsModelNameSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderProductionVariantsModelNameSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationInitProviderProductionVariantsModelNameSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsRoutingConfig {
    /// Sets how the endpoint routes incoming traffic. Valid values are LEAST_OUTSTANDING_REQUESTS and RANDOM. LEAST_OUTSTANDING_REQUESTS routes requests to the specific instances that have more capacity to process them. RANDOM routes each request to a randomly chosen instance.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingStrategy"
    )]
    #[builder(default)]
    pub routing_strategy: Option<String>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderProductionVariantsServerlessConfig {
    /// The maximum number of concurrent invocations your serverless endpoint can process. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrency"
    )]
    #[builder(default)]
    pub max_concurrency: Option<f64>,
    /// The memory size of your serverless endpoint. Valid values are in 1 GB increments: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "memorySizeInMb"
    )]
    #[builder(default)]
    pub memory_size_in_mb: Option<f64>,
    /// The amount of provisioned concurrency to allocate for the serverless endpoint. Should be less than or equal to max_concurrency. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "provisionedConcurrency"
    )]
    #[builder(default)]
    pub provisioned_concurrency: Option<f64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderShadowProductionVariants {
    /// The size of the Elastic Inference (EI) instance to use for the production variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "acceleratorType"
    )]
    #[builder(default)]
    pub accelerator_type: Option<String>,
    /// The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see How Your Container Should Respond to Health Check (Ping) Requests. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "containerStartupHealthCheckTimeoutInSeconds"
    )]
    #[builder(default)]
    pub container_startup_health_check_timeout_in_seconds: Option<f64>,
    /// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "coreDumpConfig"
    )]
    #[builder(default)]
    pub core_dump_config:
        Option<EndpointConfigurationInitProviderShadowProductionVariantsCoreDumpConfig>,
    /// You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableSsmAccess"
    )]
    #[builder(default)]
    pub enable_ssm_access: Option<bool>,
    /// Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "inferenceAmiVersion"
    )]
    #[builder(default)]
    pub inference_ami_version: Option<String>,
    /// Initial number of instances used for auto-scaling.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialInstanceCount"
    )]
    #[builder(default)]
    pub initial_instance_count: Option<f64>,
    /// Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialVariantWeight"
    )]
    #[builder(default)]
    pub initial_variant_weight: Option<f64>,
    /// The type of instance to start.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "instanceType"
    )]
    #[builder(default)]
    pub instance_type: Option<String>,
    /// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managedInstanceScaling"
    )]
    #[builder(default)]
    pub managed_instance_scaling:
        Option<EndpointConfigurationInitProviderShadowProductionVariantsManagedInstanceScaling>,
    /// The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelDataDownloadTimeoutInSeconds"
    )]
    #[builder(default)]
    pub model_data_download_timeout_in_seconds: Option<f64>,
    /// The name of the model to use.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelName")]
    #[builder(default)]
    pub model_name: Option<String>,
    /// Sets how the endpoint routes incoming traffic. See routing_config below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingConfig"
    )]
    #[builder(default)]
    pub routing_config:
        Option<Vec<EndpointConfigurationInitProviderShadowProductionVariantsRoutingConfig>>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "serverlessConfig"
    )]
    #[builder(default)]
    pub serverless_config:
        Option<EndpointConfigurationInitProviderShadowProductionVariantsServerlessConfig>,
    /// The name of the variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "variantName"
    )]
    #[builder(default)]
    pub variant_name: Option<String>,
    /// The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between 1 and 512.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "volumeSizeInGb"
    )]
    #[builder(default)]
    pub volume_size_in_gb: Option<f64>,
}

/// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderShadowProductionVariantsCoreDumpConfig {
    /// The Amazon S3 bucket to send the core dump to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that SageMaker uses to encrypt the core dump data at rest using Amazon S3 server-side encryption.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderShadowProductionVariantsManagedInstanceScaling {
    /// The maximum number of instances that the endpoint can provision when it scales up to accommodate an increase in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxInstanceCount"
    )]
    #[builder(default)]
    pub max_instance_count: Option<f64>,
    /// The minimum number of instances that the endpoint must retain when it scales down to accommodate a decrease in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "minInstanceCount"
    )]
    #[builder(default)]
    pub min_instance_count: Option<f64>,
    /// Indicates whether managed instance scaling is enabled. Valid values are ENABLED and DISABLED.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderShadowProductionVariantsRoutingConfig {
    /// Sets how the endpoint routes incoming traffic. Valid values are LEAST_OUTSTANDING_REQUESTS and RANDOM. LEAST_OUTSTANDING_REQUESTS routes requests to the specific instances that have more capacity to process them. RANDOM routes each request to a randomly chosen instance.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingStrategy"
    )]
    #[builder(default)]
    pub routing_strategy: Option<String>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationInitProviderShadowProductionVariantsServerlessConfig {
    /// The maximum number of concurrent invocations your serverless endpoint can process. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrency"
    )]
    #[builder(default)]
    pub max_concurrency: Option<f64>,
    /// The memory size of your serverless endpoint. Valid values are in 1 GB increments: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "memorySizeInMb"
    )]
    #[builder(default)]
    pub memory_size_in_mb: Option<f64>,
    /// The amount of provisioned concurrency to allocate for the serverless endpoint. Should be less than or equal to max_concurrency. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "provisionedConcurrency"
    )]
    #[builder(default)]
    pub provisioned_concurrency: Option<f64>,
}

/// ProviderConfigReference specifies how the provider that will be used to
/// create, observe, update, and delete this managed resource should be
/// configured.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationProviderConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationProviderConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationProviderConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<EndpointConfigurationProviderConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<EndpointConfigurationProviderConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationProviderConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationProviderConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// PublishConnectionDetailsTo specifies the connection secret config which
/// contains a name, metadata and a reference to secret store config to
/// which any connection details for this managed resource should be written.
/// Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationPublishConnectionDetailsTo {
    /// SecretStoreConfigRef specifies which secret store config should be used
    /// for this ConnectionSecret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configRef")]
    #[builder(default)]
    pub config_ref: Option<EndpointConfigurationPublishConnectionDetailsToConfigRef>,
    /// Metadata is the metadata for connection secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub metadata: Option<EndpointConfigurationPublishConnectionDetailsToMetadata>,
    /// Name is the name of the connection secret.
    pub name: String,
}

/// SecretStoreConfigRef specifies which secret store config should be used
/// for this ConnectionSecret.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationPublishConnectionDetailsToConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<EndpointConfigurationPublishConnectionDetailsToConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationPublishConnectionDetailsToConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution:
        Option<EndpointConfigurationPublishConnectionDetailsToConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<EndpointConfigurationPublishConnectionDetailsToConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationPublishConnectionDetailsToConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum EndpointConfigurationPublishConnectionDetailsToConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Metadata is the metadata for connection secret.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationPublishConnectionDetailsToMetadata {
    /// Annotations are the annotations to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.annotations".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub annotations: Option<HashMap<String, String>>,
    /// Labels are the labels/tags to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.labels".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub labels: Option<HashMap<String, String>>,
    /// Type is the SecretType for the connection secret.
    /// - Only valid for Kubernetes Secret Stores.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    #[builder(default)]
    pub r#type: Option<String>,
}

/// WriteConnectionSecretToReference specifies the namespace and name of a
/// Secret to which any connection details for this managed resource should
/// be written. Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
/// This field is planned to be replaced in a future release in favor of
/// PublishConnectionDetailsTo. Currently, both could be set independently
/// and connection details would be published to both without affecting
/// each other.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationWriteConnectionSecretToRef {
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// EndpointConfigurationStatus defines the observed state of EndpointConfiguration.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatus {
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "atProvider"
    )]
    #[builder(default)]
    pub at_provider: Option<EndpointConfigurationStatusAtProvider>,
    /// Conditions of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub conditions: Option<Vec<Condition>>,
    /// ObservedGeneration is the latest metadata.generation
    /// which resulted in either a ready state, or stalled due to error
    /// it can not recover from without human intervention.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "observedGeneration"
    )]
    #[builder(default)]
    pub observed_generation: Option<i64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProvider {
    /// The Amazon Resource Name (ARN) assigned by AWS to this endpoint configuration.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub arn: Option<String>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "asyncInferenceConfig"
    )]
    #[builder(default)]
    pub async_inference_config: Option<EndpointConfigurationStatusAtProviderAsyncInferenceConfig>,
    /// Specifies the parameters to capture input/output of SageMaker models endpoints. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "dataCaptureConfig"
    )]
    #[builder(default)]
    pub data_capture_config: Option<EndpointConfigurationStatusAtProviderDataCaptureConfig>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub id: Option<String>,
    /// Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance that hosts the endpoint.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyArn")]
    #[builder(default)]
    pub kms_key_arn: Option<String>,
    /// An list of ProductionVariant objects, one for each model that you want to host at this endpoint. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "productionVariants"
    )]
    #[builder(default)]
    pub production_variants: Option<Vec<EndpointConfigurationStatusAtProviderProductionVariants>>,
    /// Array of ProductionVariant objects. There is one for each model that you want to host at this endpoint in shadow mode with production traffic replicated from the model specified on ProductionVariants. If you use this field, you can only specify one variant for ProductionVariants and one variant for ShadowProductionVariants. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "shadowProductionVariants"
    )]
    #[builder(default)]
    pub shadow_production_variants:
        Option<Vec<EndpointConfigurationStatusAtProviderShadowProductionVariants>>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub tags: Option<HashMap<String, String>>,
    /// A map of tags assigned to the resource, including those inherited from the provider default_tags configuration block.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tagsAll")]
    #[builder(default)]
    pub tags_all: Option<HashMap<String, String>>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderAsyncInferenceConfig {
    /// Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "clientConfig"
    )]
    #[builder(default)]
    pub client_config:
        Option<EndpointConfigurationStatusAtProviderAsyncInferenceConfigClientConfig>,
    /// Specifies the configuration for asynchronous inference invocation outputs.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "outputConfig"
    )]
    #[builder(default)]
    pub output_config:
        Option<EndpointConfigurationStatusAtProviderAsyncInferenceConfigOutputConfig>,
}

/// Configures the behavior of the client used by Amazon SageMaker to interact with the model container during asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderAsyncInferenceConfigClientConfig {
    /// The maximum number of concurrent requests sent by the SageMaker client to the model container. If no value is provided, Amazon SageMaker will choose an optimal value for you.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrentInvocationsPerInstance"
    )]
    #[builder(default)]
    pub max_concurrent_invocations_per_instance: Option<f64>,
}

/// Specifies the configuration for asynchronous inference invocation outputs.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderAsyncInferenceConfigOutputConfig {
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that Amazon SageMaker uses to encrypt the asynchronous inference output in Amazon S3.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
    /// Specifies the configuration for notifications of inference results for asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "notificationConfig"
    )]
    #[builder(default)]
    pub notification_config: Option<
        EndpointConfigurationStatusAtProviderAsyncInferenceConfigOutputConfigNotificationConfig,
    >,
    /// The Amazon S3 location to upload failure inference responses to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "s3FailurePath"
    )]
    #[builder(default)]
    pub s3_failure_path: Option<String>,
    /// The Amazon S3 location to upload inference responses to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "s3OutputPath"
    )]
    #[builder(default)]
    pub s3_output_path: Option<String>,
}

/// Specifies the configuration for notifications of inference results for asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderAsyncInferenceConfigOutputConfigNotificationConfig {
    /// Amazon SNS topic to post a notification to when inference fails. If no topic is provided, no notification is sent on failure.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "errorTopic"
    )]
    #[builder(default)]
    pub error_topic: Option<String>,
    /// The Amazon SNS topics where you want the inference response to be included. Valid values are SUCCESS_NOTIFICATION_TOPIC and ERROR_NOTIFICATION_TOPIC.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "includeInferenceResponseIn"
    )]
    #[builder(default)]
    pub include_inference_response_in: Option<Vec<String>>,
    /// Amazon SNS topic to post a notification to when inference completes successfully. If no topic is provided, no notification is sent on success.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "successTopic"
    )]
    #[builder(default)]
    pub success_topic: Option<String>,
}

/// Specifies the parameters to capture input/output of SageMaker models endpoints. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderDataCaptureConfig {
    /// The content type headers to capture. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureContentTypeHeader"
    )]
    #[builder(default)]
    pub capture_content_type_header:
        Option<EndpointConfigurationStatusAtProviderDataCaptureConfigCaptureContentTypeHeader>,
    /// Specifies what data to capture. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureOptions"
    )]
    #[builder(default)]
    pub capture_options:
        Option<Vec<EndpointConfigurationStatusAtProviderDataCaptureConfigCaptureOptions>>,
    /// The URL for S3 location where the captured data is stored.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// Flag to enable data capture. Defaults to false.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableCapture"
    )]
    #[builder(default)]
    pub enable_capture: Option<bool>,
    /// Portion of data to capture. Should be between 0 and 100.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialSamplingPercentage"
    )]
    #[builder(default)]
    pub initial_sampling_percentage: Option<f64>,
    /// Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker uses to encrypt the captured data on Amazon S3.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// The content type headers to capture. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderDataCaptureConfigCaptureContentTypeHeader {
    /// The CSV content type headers to capture.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "csvContentTypes"
    )]
    #[builder(default)]
    pub csv_content_types: Option<Vec<String>>,
    /// The JSON content type headers to capture.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "jsonContentTypes"
    )]
    #[builder(default)]
    pub json_content_types: Option<Vec<String>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderDataCaptureConfigCaptureOptions {
    /// Specifies the data to be captured. Should be one of Input, Output or InputAndOutput.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "captureMode"
    )]
    #[builder(default)]
    pub capture_mode: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderProductionVariants {
    /// The size of the Elastic Inference (EI) instance to use for the production variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "acceleratorType"
    )]
    #[builder(default)]
    pub accelerator_type: Option<String>,
    /// The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see How Your Container Should Respond to Health Check (Ping) Requests. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "containerStartupHealthCheckTimeoutInSeconds"
    )]
    #[builder(default)]
    pub container_startup_health_check_timeout_in_seconds: Option<f64>,
    /// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "coreDumpConfig"
    )]
    #[builder(default)]
    pub core_dump_config:
        Option<EndpointConfigurationStatusAtProviderProductionVariantsCoreDumpConfig>,
    /// You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableSsmAccess"
    )]
    #[builder(default)]
    pub enable_ssm_access: Option<bool>,
    /// Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "inferenceAmiVersion"
    )]
    #[builder(default)]
    pub inference_ami_version: Option<String>,
    /// Initial number of instances used for auto-scaling.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialInstanceCount"
    )]
    #[builder(default)]
    pub initial_instance_count: Option<f64>,
    /// Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialVariantWeight"
    )]
    #[builder(default)]
    pub initial_variant_weight: Option<f64>,
    /// The type of instance to start.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "instanceType"
    )]
    #[builder(default)]
    pub instance_type: Option<String>,
    /// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managedInstanceScaling"
    )]
    #[builder(default)]
    pub managed_instance_scaling:
        Option<EndpointConfigurationStatusAtProviderProductionVariantsManagedInstanceScaling>,
    /// The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelDataDownloadTimeoutInSeconds"
    )]
    #[builder(default)]
    pub model_data_download_timeout_in_seconds: Option<f64>,
    /// The name of the model to use.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelName")]
    #[builder(default)]
    pub model_name: Option<String>,
    /// Sets how the endpoint routes incoming traffic. See routing_config below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingConfig"
    )]
    #[builder(default)]
    pub routing_config:
        Option<Vec<EndpointConfigurationStatusAtProviderProductionVariantsRoutingConfig>>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "serverlessConfig"
    )]
    #[builder(default)]
    pub serverless_config:
        Option<EndpointConfigurationStatusAtProviderProductionVariantsServerlessConfig>,
    /// The name of the variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "variantName"
    )]
    #[builder(default)]
    pub variant_name: Option<String>,
    /// The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between 1 and 512.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "volumeSizeInGb"
    )]
    #[builder(default)]
    pub volume_size_in_gb: Option<f64>,
}

/// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderProductionVariantsCoreDumpConfig {
    /// The Amazon S3 bucket to send the core dump to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that SageMaker uses to encrypt the core dump data at rest using Amazon S3 server-side encryption.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderProductionVariantsManagedInstanceScaling {
    /// The maximum number of instances that the endpoint can provision when it scales up to accommodate an increase in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxInstanceCount"
    )]
    #[builder(default)]
    pub max_instance_count: Option<f64>,
    /// The minimum number of instances that the endpoint must retain when it scales down to accommodate a decrease in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "minInstanceCount"
    )]
    #[builder(default)]
    pub min_instance_count: Option<f64>,
    /// Indicates whether managed instance scaling is enabled. Valid values are ENABLED and DISABLED.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderProductionVariantsRoutingConfig {
    /// Sets how the endpoint routes incoming traffic. Valid values are LEAST_OUTSTANDING_REQUESTS and RANDOM. LEAST_OUTSTANDING_REQUESTS routes requests to the specific instances that have more capacity to process them. RANDOM routes each request to a randomly chosen instance.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingStrategy"
    )]
    #[builder(default)]
    pub routing_strategy: Option<String>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderProductionVariantsServerlessConfig {
    /// The maximum number of concurrent invocations your serverless endpoint can process. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrency"
    )]
    #[builder(default)]
    pub max_concurrency: Option<f64>,
    /// The memory size of your serverless endpoint. Valid values are in 1 GB increments: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "memorySizeInMb"
    )]
    #[builder(default)]
    pub memory_size_in_mb: Option<f64>,
    /// The amount of provisioned concurrency to allocate for the serverless endpoint. Should be less than or equal to max_concurrency. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "provisionedConcurrency"
    )]
    #[builder(default)]
    pub provisioned_concurrency: Option<f64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderShadowProductionVariants {
    /// The size of the Elastic Inference (EI) instance to use for the production variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "acceleratorType"
    )]
    #[builder(default)]
    pub accelerator_type: Option<String>,
    /// The timeout value, in seconds, for your inference container to pass health check by SageMaker Hosting. For more information about health check, see How Your Container Should Respond to Health Check (Ping) Requests. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "containerStartupHealthCheckTimeoutInSeconds"
    )]
    #[builder(default)]
    pub container_startup_health_check_timeout_in_seconds: Option<f64>,
    /// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "coreDumpConfig"
    )]
    #[builder(default)]
    pub core_dump_config:
        Option<EndpointConfigurationStatusAtProviderShadowProductionVariantsCoreDumpConfig>,
    /// You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "enableSsmAccess"
    )]
    #[builder(default)]
    pub enable_ssm_access: Option<bool>,
    /// Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "inferenceAmiVersion"
    )]
    #[builder(default)]
    pub inference_ami_version: Option<String>,
    /// Initial number of instances used for auto-scaling.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialInstanceCount"
    )]
    #[builder(default)]
    pub initial_instance_count: Option<f64>,
    /// Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to 1.0.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "initialVariantWeight"
    )]
    #[builder(default)]
    pub initial_variant_weight: Option<f64>,
    /// The type of instance to start.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "instanceType"
    )]
    #[builder(default)]
    pub instance_type: Option<String>,
    /// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "managedInstanceScaling"
    )]
    #[builder(default)]
    pub managed_instance_scaling:
        Option<EndpointConfigurationStatusAtProviderShadowProductionVariantsManagedInstanceScaling>,
    /// The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between 60 and 3600.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "modelDataDownloadTimeoutInSeconds"
    )]
    #[builder(default)]
    pub model_data_download_timeout_in_seconds: Option<f64>,
    /// The name of the model to use.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelName")]
    #[builder(default)]
    pub model_name: Option<String>,
    /// Sets how the endpoint routes incoming traffic. See routing_config below.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingConfig"
    )]
    #[builder(default)]
    pub routing_config:
        Option<Vec<EndpointConfigurationStatusAtProviderShadowProductionVariantsRoutingConfig>>,
    /// Specifies configuration for how an endpoint performs asynchronous inference.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "serverlessConfig"
    )]
    #[builder(default)]
    pub serverless_config:
        Option<EndpointConfigurationStatusAtProviderShadowProductionVariantsServerlessConfig>,
    /// The name of the variant.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "variantName"
    )]
    #[builder(default)]
    pub variant_name: Option<String>,
    /// The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between 1 and 512.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "volumeSizeInGb"
    )]
    #[builder(default)]
    pub volume_size_in_gb: Option<f64>,
}

/// Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderShadowProductionVariantsCoreDumpConfig {
    /// The Amazon S3 bucket to send the core dump to.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "destinationS3Uri"
    )]
    #[builder(default)]
    pub destination_s3_uri: Option<String>,
    /// The Amazon Web Services Key Management Service (Amazon Web Services KMS) key that SageMaker uses to encrypt the core dump data at rest using Amazon S3 server-side encryption.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "kmsKeyId")]
    #[builder(default)]
    pub kms_key_id: Option<String>,
}

/// Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderShadowProductionVariantsManagedInstanceScaling {
    /// The maximum number of instances that the endpoint can provision when it scales up to accommodate an increase in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxInstanceCount"
    )]
    #[builder(default)]
    pub max_instance_count: Option<f64>,
    /// The minimum number of instances that the endpoint must retain when it scales down to accommodate a decrease in traffic.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "minInstanceCount"
    )]
    #[builder(default)]
    pub min_instance_count: Option<f64>,
    /// Indicates whether managed instance scaling is enabled. Valid values are ENABLED and DISABLED.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub status: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderShadowProductionVariantsRoutingConfig {
    /// Sets how the endpoint routes incoming traffic. Valid values are LEAST_OUTSTANDING_REQUESTS and RANDOM. LEAST_OUTSTANDING_REQUESTS routes requests to the specific instances that have more capacity to process them. RANDOM routes each request to a randomly chosen instance.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "routingStrategy"
    )]
    #[builder(default)]
    pub routing_strategy: Option<String>,
}

/// Specifies configuration for how an endpoint performs asynchronous inference.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct EndpointConfigurationStatusAtProviderShadowProductionVariantsServerlessConfig {
    /// The maximum number of concurrent invocations your serverless endpoint can process. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "maxConcurrency"
    )]
    #[builder(default)]
    pub max_concurrency: Option<f64>,
    /// The memory size of your serverless endpoint. Valid values are in 1 GB increments: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB, or 6144 MB.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "memorySizeInMb"
    )]
    #[builder(default)]
    pub memory_size_in_mb: Option<f64>,
    /// The amount of provisioned concurrency to allocate for the serverless endpoint. Should be less than or equal to max_concurrency. Valid values are between 1 and 200.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        rename = "provisionedConcurrency"
    )]
    #[builder(default)]
    pub provisioned_concurrency: Option<f64>,
}
