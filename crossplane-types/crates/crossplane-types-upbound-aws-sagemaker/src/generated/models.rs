// WARNING: generated by kopium - manual changes will be overwritten
// kopium version: 0.21.2

#[allow(unused_imports)]
mod prelude {
    pub use kube::CustomResource;
    pub use typed_builder::TypedBuilder;
    pub use schemars::JsonSchema;
    pub use serde::{Serialize, Deserialize};
    pub use std::collections::HashMap;
    pub use k8s_openapi::apimachinery::pkg::apis::meta::v1::Condition;
}
use self::prelude::*;

/// ModelSpec defines the desired state of Model
#[derive(CustomResource, Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
#[kube(group = "sagemaker.aws.upbound.io", version = "v1beta2", kind = "Model", plural = "models")]
#[kube(status = "ModelStatus")]
pub struct ModelSpec {
    /// DeletionPolicy specifies what will happen to the underlying external
    /// when this managed resource is deleted - either "Delete" or "Orphan" the
    /// external resource.
    /// This field is planned to be deprecated in favor of the ManagementPolicies
    /// field in a future release. Currently, both could be set independently and
    /// non-default values would be honored if the feature flag is enabled.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "deletionPolicy")]
    #[builder(default)]
    pub deletion_policy: Option<ModelDeletionPolicy>,
    #[serde(rename = "forProvider")]
    pub for_provider: ModelForProvider,
    /// THIS IS A BETA FIELD. It will be honored
    /// unless the Management Policies feature flag is disabled.
    /// InitProvider holds the same fields as ForProvider, with the exception
    /// of Identifier and other resource reference fields. The fields that are
    /// in InitProvider are merged into ForProvider when the resource is created.
    /// The same fields are also added to the terraform ignore_changes hook, to
    /// avoid updating them after creation. This is useful for fields that are
    /// required on creation, but we do not desire to update them after creation,
    /// for example because of an external controller is managing them, like an
    /// autoscaler.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "initProvider")]
    #[builder(default)]
    pub init_provider: Option<ModelInitProvider>,
    /// THIS IS A BETA FIELD. It is on by default but can be opted out
    /// through a Crossplane feature flag.
    /// ManagementPolicies specify the array of actions Crossplane is allowed to
    /// take on the managed and external resources.
    /// This field is planned to replace the DeletionPolicy field in a future
    /// release. Currently, both could be set independently and non-default
    /// values would be honored if the feature flag is enabled. If both are
    /// custom, the DeletionPolicy field will be ignored.
    /// See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    /// and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "managementPolicies")]
    #[builder(default)]
    pub management_policies: Option<Vec<String>>,
    /// ProviderConfigReference specifies how the provider that will be used to
    /// create, observe, update, and delete this managed resource should be
    /// configured.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "providerConfigRef")]
    #[builder(default)]
    pub provider_config_ref: Option<ModelProviderConfigRef>,
    /// PublishConnectionDetailsTo specifies the connection secret config which
    /// contains a name, metadata and a reference to secret store config to
    /// which any connection details for this managed resource should be written.
    /// Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "publishConnectionDetailsTo")]
    #[builder(default)]
    pub publish_connection_details_to: Option<ModelPublishConnectionDetailsTo>,
    /// WriteConnectionSecretToReference specifies the namespace and name of a
    /// Secret to which any connection details for this managed resource should
    /// be written. Connection details frequently include the endpoint, username,
    /// and password required to connect to the managed resource.
    /// This field is planned to be replaced in a future release in favor of
    /// PublishConnectionDetailsTo. Currently, both could be set independently
    /// and connection details would be published to both without affecting
    /// each other.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "writeConnectionSecretToRef")]
    #[builder(default)]
    pub write_connection_secret_to_ref: Option<ModelWriteConnectionSecretToRef>,
}

/// ModelSpec defines the desired state of Model
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelDeletionPolicy {
    Orphan,
    Delete,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProvider {
    /// Specifies containers in the inference pipeline. If not specified, the primary_container argument is required. Fields are documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub container: Option<Vec<ModelForProviderContainer>>,
    /// Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableNetworkIsolation")]
    #[builder(default)]
    pub enable_network_isolation: Option<bool>,
    /// A role that SageMaker can assume to access model artifacts and docker images for deployment.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArn")]
    #[builder(default)]
    pub execution_role_arn: Option<String>,
    /// Reference to a Role in iam to populate executionRoleArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArnRef")]
    #[builder(default)]
    pub execution_role_arn_ref: Option<ModelForProviderExecutionRoleArnRef>,
    /// Selector for a Role in iam to populate executionRoleArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArnSelector")]
    #[builder(default)]
    pub execution_role_arn_selector: Option<ModelForProviderExecutionRoleArnSelector>,
    /// Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceExecutionConfig")]
    #[builder(default)]
    pub inference_execution_config: Option<ModelForProviderInferenceExecutionConfig>,
    /// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryContainer")]
    #[builder(default)]
    pub primary_container: Option<ModelForProviderPrimaryContainer>,
    /// Region is the region you'd like your resource to be created in.
    pub region: String,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub tags: Option<HashMap<String, String>>,
    /// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "vpcConfig")]
    #[builder(default)]
    pub vpc_config: Option<ModelForProviderVpcConfig>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainer {
    /// The DNS host name for the container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerHostname")]
    #[builder(default)]
    pub container_hostname: Option<String>,
    /// Environment variables for the Docker container.
    /// A list of key value pairs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub environment: Option<HashMap<String, String>>,
    /// The registry path where the inference code image is stored in Amazon ECR.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub image: Option<String>,
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageConfig")]
    #[builder(default)]
    pub image_config: Option<ModelForProviderContainerImageConfig>,
    /// The inference specification name in the model package version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceSpecificationName")]
    #[builder(default)]
    pub inference_specification_name: Option<String>,
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
    /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataSource")]
    #[builder(default)]
    pub model_data_source: Option<ModelForProviderContainerModelDataSource>,
    /// The URL for the S3 location where model artifacts are stored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataUrl")]
    #[builder(default)]
    pub model_data_url: Option<String>,
    /// The Amazon Resource Name (ARN) of the model package to use to create the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelPackageName")]
    #[builder(default)]
    pub model_package_name: Option<String>,
    /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiModelConfig")]
    #[builder(default)]
    pub multi_model_config: Option<ModelForProviderContainerMultiModelConfig>,
}

/// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainerImageConfig {
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAccessMode")]
    #[builder(default)]
    pub repository_access_mode: Option<String>,
    /// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAuthConfig")]
    #[builder(default)]
    pub repository_auth_config: Option<ModelForProviderContainerImageConfigRepositoryAuthConfig>,
}

/// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainerImageConfigRepositoryAuthConfig {
    /// The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryCredentialsProviderArn")]
    #[builder(default)]
    pub repository_credentials_provider_arn: Option<String>,
}

/// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainerModelDataSource {
    /// The S3 location of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    #[builder(default)]
    pub s3_data_source: Option<Vec<ModelForProviderContainerModelDataSourceS3DataSource>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainerModelDataSourceS3DataSource {
    /// How the model data is prepared. Allowed values are: None and Gzip.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    #[builder(default)]
    pub compression_type: Option<String>,
    /// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelAccessConfig")]
    #[builder(default)]
    pub model_access_config: Option<ModelForProviderContainerModelDataSourceS3DataSourceModelAccessConfig>,
    /// The type of model data to deploy. Allowed values are: S3Object and S3Prefix.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    #[builder(default)]
    pub s3_data_type: Option<String>,
    /// The S3 path of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Uri")]
    #[builder(default)]
    pub s3_uri: Option<String>,
}

/// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainerModelDataSourceS3DataSourceModelAccessConfig {
    /// Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "acceptEula")]
    #[builder(default)]
    pub accept_eula: Option<bool>,
}

/// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderContainerMultiModelConfig {
    /// Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelCacheSetting")]
    #[builder(default)]
    pub model_cache_setting: Option<String>,
}

/// Reference to a Role in iam to populate executionRoleArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderExecutionRoleArnRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<ModelForProviderExecutionRoleArnRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderExecutionRoleArnRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<ModelForProviderExecutionRoleArnRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<ModelForProviderExecutionRoleArnRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelForProviderExecutionRoleArnRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelForProviderExecutionRoleArnRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Role in iam to populate executionRoleArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderExecutionRoleArnSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<ModelForProviderExecutionRoleArnSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderExecutionRoleArnSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<ModelForProviderExecutionRoleArnSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<ModelForProviderExecutionRoleArnSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelForProviderExecutionRoleArnSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelForProviderExecutionRoleArnSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderInferenceExecutionConfig {
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
}

/// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainer {
    /// The DNS host name for the container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerHostname")]
    #[builder(default)]
    pub container_hostname: Option<String>,
    /// Environment variables for the Docker container.
    /// A list of key value pairs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub environment: Option<HashMap<String, String>>,
    /// The registry path where the inference code image is stored in Amazon ECR.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub image: Option<String>,
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageConfig")]
    #[builder(default)]
    pub image_config: Option<ModelForProviderPrimaryContainerImageConfig>,
    /// The inference specification name in the model package version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceSpecificationName")]
    #[builder(default)]
    pub inference_specification_name: Option<String>,
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
    /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataSource")]
    #[builder(default)]
    pub model_data_source: Option<ModelForProviderPrimaryContainerModelDataSource>,
    /// The URL for the S3 location where model artifacts are stored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataUrl")]
    #[builder(default)]
    pub model_data_url: Option<String>,
    /// The Amazon Resource Name (ARN) of the model package to use to create the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelPackageName")]
    #[builder(default)]
    pub model_package_name: Option<String>,
    /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiModelConfig")]
    #[builder(default)]
    pub multi_model_config: Option<ModelForProviderPrimaryContainerMultiModelConfig>,
}

/// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainerImageConfig {
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAccessMode")]
    #[builder(default)]
    pub repository_access_mode: Option<String>,
    /// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAuthConfig")]
    #[builder(default)]
    pub repository_auth_config: Option<ModelForProviderPrimaryContainerImageConfigRepositoryAuthConfig>,
}

/// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainerImageConfigRepositoryAuthConfig {
    /// The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryCredentialsProviderArn")]
    #[builder(default)]
    pub repository_credentials_provider_arn: Option<String>,
}

/// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainerModelDataSource {
    /// The S3 location of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    #[builder(default)]
    pub s3_data_source: Option<Vec<ModelForProviderPrimaryContainerModelDataSourceS3DataSource>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainerModelDataSourceS3DataSource {
    /// How the model data is prepared. Allowed values are: None and Gzip.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    #[builder(default)]
    pub compression_type: Option<String>,
    /// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelAccessConfig")]
    #[builder(default)]
    pub model_access_config: Option<ModelForProviderPrimaryContainerModelDataSourceS3DataSourceModelAccessConfig>,
    /// The type of model data to deploy. Allowed values are: S3Object and S3Prefix.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    #[builder(default)]
    pub s3_data_type: Option<String>,
    /// The S3 path of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Uri")]
    #[builder(default)]
    pub s3_uri: Option<String>,
}

/// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainerModelDataSourceS3DataSourceModelAccessConfig {
    /// Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "acceptEula")]
    #[builder(default)]
    pub accept_eula: Option<bool>,
}

/// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderPrimaryContainerMultiModelConfig {
    /// Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelCacheSetting")]
    #[builder(default)]
    pub model_cache_setting: Option<String>,
}

/// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelForProviderVpcConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "securityGroupIds")]
    #[builder(default)]
    pub security_group_ids: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub subnets: Option<Vec<String>>,
}

/// THIS IS A BETA FIELD. It will be honored
/// unless the Management Policies feature flag is disabled.
/// InitProvider holds the same fields as ForProvider, with the exception
/// of Identifier and other resource reference fields. The fields that are
/// in InitProvider are merged into ForProvider when the resource is created.
/// The same fields are also added to the terraform ignore_changes hook, to
/// avoid updating them after creation. This is useful for fields that are
/// required on creation, but we do not desire to update them after creation,
/// for example because of an external controller is managing them, like an
/// autoscaler.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProvider {
    /// Specifies containers in the inference pipeline. If not specified, the primary_container argument is required. Fields are documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub container: Option<Vec<ModelInitProviderContainer>>,
    /// Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableNetworkIsolation")]
    #[builder(default)]
    pub enable_network_isolation: Option<bool>,
    /// A role that SageMaker can assume to access model artifacts and docker images for deployment.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArn")]
    #[builder(default)]
    pub execution_role_arn: Option<String>,
    /// Reference to a Role in iam to populate executionRoleArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArnRef")]
    #[builder(default)]
    pub execution_role_arn_ref: Option<ModelInitProviderExecutionRoleArnRef>,
    /// Selector for a Role in iam to populate executionRoleArn.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArnSelector")]
    #[builder(default)]
    pub execution_role_arn_selector: Option<ModelInitProviderExecutionRoleArnSelector>,
    /// Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceExecutionConfig")]
    #[builder(default)]
    pub inference_execution_config: Option<ModelInitProviderInferenceExecutionConfig>,
    /// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryContainer")]
    #[builder(default)]
    pub primary_container: Option<ModelInitProviderPrimaryContainer>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub tags: Option<HashMap<String, String>>,
    /// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "vpcConfig")]
    #[builder(default)]
    pub vpc_config: Option<ModelInitProviderVpcConfig>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainer {
    /// The DNS host name for the container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerHostname")]
    #[builder(default)]
    pub container_hostname: Option<String>,
    /// Environment variables for the Docker container.
    /// A list of key value pairs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub environment: Option<HashMap<String, String>>,
    /// The registry path where the inference code image is stored in Amazon ECR.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub image: Option<String>,
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageConfig")]
    #[builder(default)]
    pub image_config: Option<ModelInitProviderContainerImageConfig>,
    /// The inference specification name in the model package version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceSpecificationName")]
    #[builder(default)]
    pub inference_specification_name: Option<String>,
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
    /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataSource")]
    #[builder(default)]
    pub model_data_source: Option<ModelInitProviderContainerModelDataSource>,
    /// The URL for the S3 location where model artifacts are stored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataUrl")]
    #[builder(default)]
    pub model_data_url: Option<String>,
    /// The Amazon Resource Name (ARN) of the model package to use to create the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelPackageName")]
    #[builder(default)]
    pub model_package_name: Option<String>,
    /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiModelConfig")]
    #[builder(default)]
    pub multi_model_config: Option<ModelInitProviderContainerMultiModelConfig>,
}

/// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainerImageConfig {
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAccessMode")]
    #[builder(default)]
    pub repository_access_mode: Option<String>,
    /// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAuthConfig")]
    #[builder(default)]
    pub repository_auth_config: Option<ModelInitProviderContainerImageConfigRepositoryAuthConfig>,
}

/// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainerImageConfigRepositoryAuthConfig {
    /// The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryCredentialsProviderArn")]
    #[builder(default)]
    pub repository_credentials_provider_arn: Option<String>,
}

/// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainerModelDataSource {
    /// The S3 location of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    #[builder(default)]
    pub s3_data_source: Option<Vec<ModelInitProviderContainerModelDataSourceS3DataSource>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainerModelDataSourceS3DataSource {
    /// How the model data is prepared. Allowed values are: None and Gzip.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    #[builder(default)]
    pub compression_type: Option<String>,
    /// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelAccessConfig")]
    #[builder(default)]
    pub model_access_config: Option<ModelInitProviderContainerModelDataSourceS3DataSourceModelAccessConfig>,
    /// The type of model data to deploy. Allowed values are: S3Object and S3Prefix.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    #[builder(default)]
    pub s3_data_type: Option<String>,
    /// The S3 path of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Uri")]
    #[builder(default)]
    pub s3_uri: Option<String>,
}

/// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainerModelDataSourceS3DataSourceModelAccessConfig {
    /// Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "acceptEula")]
    #[builder(default)]
    pub accept_eula: Option<bool>,
}

/// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderContainerMultiModelConfig {
    /// Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelCacheSetting")]
    #[builder(default)]
    pub model_cache_setting: Option<String>,
}

/// Reference to a Role in iam to populate executionRoleArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderExecutionRoleArnRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<ModelInitProviderExecutionRoleArnRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderExecutionRoleArnRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<ModelInitProviderExecutionRoleArnRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<ModelInitProviderExecutionRoleArnRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelInitProviderExecutionRoleArnRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelInitProviderExecutionRoleArnRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Selector for a Role in iam to populate executionRoleArn.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderExecutionRoleArnSelector {
    /// MatchControllerRef ensures an object with the same controller reference
    /// as the selecting object is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchControllerRef")]
    #[builder(default)]
    pub match_controller_ref: Option<bool>,
    /// MatchLabels ensures an object with matching labels is selected.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "matchLabels")]
    #[builder(default)]
    pub match_labels: Option<HashMap<String, String>>,
    /// Policies for selection.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<ModelInitProviderExecutionRoleArnSelectorPolicy>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderExecutionRoleArnSelectorPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<ModelInitProviderExecutionRoleArnSelectorPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<ModelInitProviderExecutionRoleArnSelectorPolicyResolve>,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelInitProviderExecutionRoleArnSelectorPolicyResolution {
    Required,
    Optional,
}

/// Policies for selection.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelInitProviderExecutionRoleArnSelectorPolicyResolve {
    Always,
    IfNotPresent,
}

/// Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderInferenceExecutionConfig {
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
}

/// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainer {
    /// The DNS host name for the container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerHostname")]
    #[builder(default)]
    pub container_hostname: Option<String>,
    /// Environment variables for the Docker container.
    /// A list of key value pairs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub environment: Option<HashMap<String, String>>,
    /// The registry path where the inference code image is stored in Amazon ECR.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub image: Option<String>,
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageConfig")]
    #[builder(default)]
    pub image_config: Option<ModelInitProviderPrimaryContainerImageConfig>,
    /// The inference specification name in the model package version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceSpecificationName")]
    #[builder(default)]
    pub inference_specification_name: Option<String>,
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
    /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataSource")]
    #[builder(default)]
    pub model_data_source: Option<ModelInitProviderPrimaryContainerModelDataSource>,
    /// The URL for the S3 location where model artifacts are stored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataUrl")]
    #[builder(default)]
    pub model_data_url: Option<String>,
    /// The Amazon Resource Name (ARN) of the model package to use to create the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelPackageName")]
    #[builder(default)]
    pub model_package_name: Option<String>,
    /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiModelConfig")]
    #[builder(default)]
    pub multi_model_config: Option<ModelInitProviderPrimaryContainerMultiModelConfig>,
}

/// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainerImageConfig {
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAccessMode")]
    #[builder(default)]
    pub repository_access_mode: Option<String>,
    /// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAuthConfig")]
    #[builder(default)]
    pub repository_auth_config: Option<ModelInitProviderPrimaryContainerImageConfigRepositoryAuthConfig>,
}

/// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainerImageConfigRepositoryAuthConfig {
    /// The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryCredentialsProviderArn")]
    #[builder(default)]
    pub repository_credentials_provider_arn: Option<String>,
}

/// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainerModelDataSource {
    /// The S3 location of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    #[builder(default)]
    pub s3_data_source: Option<Vec<ModelInitProviderPrimaryContainerModelDataSourceS3DataSource>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainerModelDataSourceS3DataSource {
    /// How the model data is prepared. Allowed values are: None and Gzip.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    #[builder(default)]
    pub compression_type: Option<String>,
    /// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelAccessConfig")]
    #[builder(default)]
    pub model_access_config: Option<ModelInitProviderPrimaryContainerModelDataSourceS3DataSourceModelAccessConfig>,
    /// The type of model data to deploy. Allowed values are: S3Object and S3Prefix.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    #[builder(default)]
    pub s3_data_type: Option<String>,
    /// The S3 path of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Uri")]
    #[builder(default)]
    pub s3_uri: Option<String>,
}

/// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainerModelDataSourceS3DataSourceModelAccessConfig {
    /// Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "acceptEula")]
    #[builder(default)]
    pub accept_eula: Option<bool>,
}

/// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderPrimaryContainerMultiModelConfig {
    /// Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelCacheSetting")]
    #[builder(default)]
    pub model_cache_setting: Option<String>,
}

/// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelInitProviderVpcConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "securityGroupIds")]
    #[builder(default)]
    pub security_group_ids: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub subnets: Option<Vec<String>>,
}

/// ProviderConfigReference specifies how the provider that will be used to
/// create, observe, update, and delete this managed resource should be
/// configured.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelProviderConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<ModelProviderConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelProviderConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<ModelProviderConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<ModelProviderConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelProviderConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelProviderConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// PublishConnectionDetailsTo specifies the connection secret config which
/// contains a name, metadata and a reference to secret store config to
/// which any connection details for this managed resource should be written.
/// Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelPublishConnectionDetailsTo {
    /// SecretStoreConfigRef specifies which secret store config should be used
    /// for this ConnectionSecret.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "configRef")]
    #[builder(default)]
    pub config_ref: Option<ModelPublishConnectionDetailsToConfigRef>,
    /// Metadata is the metadata for connection secret.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub metadata: Option<ModelPublishConnectionDetailsToMetadata>,
    /// Name is the name of the connection secret.
    pub name: String,
}

/// SecretStoreConfigRef specifies which secret store config should be used
/// for this ConnectionSecret.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelPublishConnectionDetailsToConfigRef {
    /// Name of the referenced object.
    pub name: String,
    /// Policies for referencing.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub policy: Option<ModelPublishConnectionDetailsToConfigRefPolicy>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelPublishConnectionDetailsToConfigRefPolicy {
    /// Resolution specifies whether resolution of this reference is required.
    /// The default is 'Required', which means the reconcile will fail if the
    /// reference cannot be resolved. 'Optional' means this reference will be
    /// a no-op if it cannot be resolved.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolution: Option<ModelPublishConnectionDetailsToConfigRefPolicyResolution>,
    /// Resolve specifies when this reference should be resolved. The default
    /// is 'IfNotPresent', which will attempt to resolve the reference only when
    /// the corresponding field is not present. Use 'Always' to resolve the
    /// reference on every reconcile.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub resolve: Option<ModelPublishConnectionDetailsToConfigRefPolicyResolve>,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelPublishConnectionDetailsToConfigRefPolicyResolution {
    Required,
    Optional,
}

/// Policies for referencing.
#[derive(Serialize, Deserialize, Clone, Debug, JsonSchema)]
pub enum ModelPublishConnectionDetailsToConfigRefPolicyResolve {
    Always,
    IfNotPresent,
}

/// Metadata is the metadata for connection secret.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelPublishConnectionDetailsToMetadata {
    /// Annotations are the annotations to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.annotations".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub annotations: Option<HashMap<String, String>>,
    /// Labels are the labels/tags to be added to connection secret.
    /// - For Kubernetes secrets, this will be used as "metadata.labels".
    /// - It is up to Secret Store implementation for others store types.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub labels: Option<HashMap<String, String>>,
    /// Type is the SecretType for the connection secret.
    /// - Only valid for Kubernetes Secret Stores.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "type")]
    #[builder(default)]
    pub r#type: Option<String>,
}

/// WriteConnectionSecretToReference specifies the namespace and name of a
/// Secret to which any connection details for this managed resource should
/// be written. Connection details frequently include the endpoint, username,
/// and password required to connect to the managed resource.
/// This field is planned to be replaced in a future release in favor of
/// PublishConnectionDetailsTo. Currently, both could be set independently
/// and connection details would be published to both without affecting
/// each other.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelWriteConnectionSecretToRef {
    /// Name of the secret.
    pub name: String,
    /// Namespace of the secret.
    pub namespace: String,
}

/// ModelStatus defines the observed state of Model.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatus {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "atProvider")]
    #[builder(default)]
    pub at_provider: Option<ModelStatusAtProvider>,
    /// Conditions of the resource.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub conditions: Option<Vec<Condition>>,
    /// ObservedGeneration is the latest metadata.generation
    /// which resulted in either a ready state, or stalled due to error
    /// it can not recover from without human intervention.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "observedGeneration")]
    #[builder(default)]
    pub observed_generation: Option<i64>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProvider {
    /// The Amazon Resource Name (ARN) assigned by AWS to this model.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub arn: Option<String>,
    /// Specifies containers in the inference pipeline. If not specified, the primary_container argument is required. Fields are documented below.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub container: Option<Vec<ModelStatusAtProviderContainer>>,
    /// Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "enableNetworkIsolation")]
    #[builder(default)]
    pub enable_network_isolation: Option<bool>,
    /// A role that SageMaker can assume to access model artifacts and docker images for deployment.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "executionRoleArn")]
    #[builder(default)]
    pub execution_role_arn: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub id: Option<String>,
    /// Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceExecutionConfig")]
    #[builder(default)]
    pub inference_execution_config: Option<ModelStatusAtProviderInferenceExecutionConfig>,
    /// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "primaryContainer")]
    #[builder(default)]
    pub primary_container: Option<ModelStatusAtProviderPrimaryContainer>,
    /// Key-value map of resource tags.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub tags: Option<HashMap<String, String>>,
    /// A map of tags assigned to the resource, including those inherited from the provider default_tags configuration block.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "tagsAll")]
    #[builder(default)]
    pub tags_all: Option<HashMap<String, String>>,
    /// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "vpcConfig")]
    #[builder(default)]
    pub vpc_config: Option<ModelStatusAtProviderVpcConfig>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainer {
    /// The DNS host name for the container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerHostname")]
    #[builder(default)]
    pub container_hostname: Option<String>,
    /// Environment variables for the Docker container.
    /// A list of key value pairs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub environment: Option<HashMap<String, String>>,
    /// The registry path where the inference code image is stored in Amazon ECR.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub image: Option<String>,
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageConfig")]
    #[builder(default)]
    pub image_config: Option<ModelStatusAtProviderContainerImageConfig>,
    /// The inference specification name in the model package version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceSpecificationName")]
    #[builder(default)]
    pub inference_specification_name: Option<String>,
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
    /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataSource")]
    #[builder(default)]
    pub model_data_source: Option<ModelStatusAtProviderContainerModelDataSource>,
    /// The URL for the S3 location where model artifacts are stored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataUrl")]
    #[builder(default)]
    pub model_data_url: Option<String>,
    /// The Amazon Resource Name (ARN) of the model package to use to create the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelPackageName")]
    #[builder(default)]
    pub model_package_name: Option<String>,
    /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiModelConfig")]
    #[builder(default)]
    pub multi_model_config: Option<ModelStatusAtProviderContainerMultiModelConfig>,
}

/// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainerImageConfig {
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAccessMode")]
    #[builder(default)]
    pub repository_access_mode: Option<String>,
    /// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAuthConfig")]
    #[builder(default)]
    pub repository_auth_config: Option<ModelStatusAtProviderContainerImageConfigRepositoryAuthConfig>,
}

/// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainerImageConfigRepositoryAuthConfig {
    /// The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryCredentialsProviderArn")]
    #[builder(default)]
    pub repository_credentials_provider_arn: Option<String>,
}

/// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainerModelDataSource {
    /// The S3 location of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    #[builder(default)]
    pub s3_data_source: Option<Vec<ModelStatusAtProviderContainerModelDataSourceS3DataSource>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainerModelDataSourceS3DataSource {
    /// How the model data is prepared. Allowed values are: None and Gzip.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    #[builder(default)]
    pub compression_type: Option<String>,
    /// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelAccessConfig")]
    #[builder(default)]
    pub model_access_config: Option<ModelStatusAtProviderContainerModelDataSourceS3DataSourceModelAccessConfig>,
    /// The type of model data to deploy. Allowed values are: S3Object and S3Prefix.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    #[builder(default)]
    pub s3_data_type: Option<String>,
    /// The S3 path of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Uri")]
    #[builder(default)]
    pub s3_uri: Option<String>,
}

/// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainerModelDataSourceS3DataSourceModelAccessConfig {
    /// Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "acceptEula")]
    #[builder(default)]
    pub accept_eula: Option<bool>,
}

/// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderContainerMultiModelConfig {
    /// Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelCacheSetting")]
    #[builder(default)]
    pub model_cache_setting: Option<String>,
}

/// Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderInferenceExecutionConfig {
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
}

/// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the container argument is required. Fields are documented below.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainer {
    /// The DNS host name for the container.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "containerHostname")]
    #[builder(default)]
    pub container_hostname: Option<String>,
    /// Environment variables for the Docker container.
    /// A list of key value pairs.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub environment: Option<HashMap<String, String>>,
    /// The registry path where the inference code image is stored in Amazon ECR.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub image: Option<String>,
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "imageConfig")]
    #[builder(default)]
    pub image_config: Option<ModelStatusAtProviderPrimaryContainerImageConfig>,
    /// The inference specification name in the model package version.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "inferenceSpecificationName")]
    #[builder(default)]
    pub inference_specification_name: Option<String>,
    /// The container hosts value SingleModel/MultiModel. The default value is SingleModel.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub mode: Option<String>,
    /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataSource")]
    #[builder(default)]
    pub model_data_source: Option<ModelStatusAtProviderPrimaryContainerModelDataSource>,
    /// The URL for the S3 location where model artifacts are stored.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelDataUrl")]
    #[builder(default)]
    pub model_data_url: Option<String>,
    /// The Amazon Resource Name (ARN) of the model package to use to create the model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelPackageName")]
    #[builder(default)]
    pub model_package_name: Option<String>,
    /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "multiModelConfig")]
    #[builder(default)]
    pub multi_model_config: Option<ModelStatusAtProviderPrimaryContainerMultiModelConfig>,
}

/// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see Using a Private Docker Registry for Real-Time Inference Containers. see Image Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainerImageConfig {
    /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). Allowed values are: Platform and Vpc.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAccessMode")]
    #[builder(default)]
    pub repository_access_mode: Option<String>,
    /// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryAuthConfig")]
    #[builder(default)]
    pub repository_auth_config: Option<ModelStatusAtProviderPrimaryContainerImageConfigRepositoryAuthConfig>,
}

/// Specifies an authentication configuration for the private docker registry where your model image is hosted. Specify a value for this property only if you specified Vpc as the value for the RepositoryAccessMode field, and the private Docker registry where the model image is hosted requires authentication. see Repository Auth Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainerImageConfigRepositoryAuthConfig {
    /// The Amazon Resource Name (ARN) of an AWS Lambda function that provides credentials to authenticate to the private Docker registry where your model image is hosted. For information about how to create an AWS Lambda function, see Create a Lambda function with the console in the AWS Lambda Developer Guide.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "repositoryCredentialsProviderArn")]
    #[builder(default)]
    pub repository_credentials_provider_arn: Option<String>,
}

/// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see Deploying uncompressed models in the AWS SageMaker Developer Guide.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainerModelDataSource {
    /// The S3 location of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataSource")]
    #[builder(default)]
    pub s3_data_source: Option<Vec<ModelStatusAtProviderPrimaryContainerModelDataSourceS3DataSource>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainerModelDataSourceS3DataSource {
    /// How the model data is prepared. Allowed values are: None and Gzip.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "compressionType")]
    #[builder(default)]
    pub compression_type: Option<String>,
    /// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelAccessConfig")]
    #[builder(default)]
    pub model_access_config: Option<ModelStatusAtProviderPrimaryContainerModelDataSourceS3DataSourceModelAccessConfig>,
    /// The type of model data to deploy. Allowed values are: S3Object and S3Prefix.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3DataType")]
    #[builder(default)]
    pub s3_data_type: Option<String>,
    /// The S3 path of model data to deploy.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "s3Uri")]
    #[builder(default)]
    pub s3_uri: Option<String>,
}

/// Specifies the access configuration file for the ML model. You can explicitly accept the model end-user license agreement (EULA) within the [model_access_config configuration block]. see Model Access Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainerModelDataSourceS3DataSourceModelAccessConfig {
    /// Specifies agreement to the model end-user license agreement (EULA). The AcceptEula value must be explicitly defined as true in order to accept the EULA that this model requires. You are responsible for reviewing and complying with any applicable license terms and making sure they are acceptable for your use case before downloading or using a model.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "acceptEula")]
    #[builder(default)]
    pub accept_eula: Option<bool>,
}

/// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderPrimaryContainerMultiModelConfig {
    /// Whether to cache models for a multi-model endpoint. By default, multi-model endpoints cache models so that a model does not have to be loaded into memory each time it is invoked. Some use cases do not benefit from model caching. For example, if an endpoint hosts a large number of models that are each invoked infrequently, the endpoint might perform better if you disable model caching. To disable model caching, set the value of this parameter to Disabled. Allowed values are: Enabled and Disabled.
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "modelCacheSetting")]
    #[builder(default)]
    pub model_cache_setting: Option<String>,
}

/// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
#[derive(Serialize, Deserialize, Clone, Debug, TypedBuilder, JsonSchema)]
#[builder(field_defaults(setter(strip_option(ignore_invalid))))]
pub struct ModelStatusAtProviderVpcConfig {
    #[serde(default, skip_serializing_if = "Option::is_none", rename = "securityGroupIds")]
    #[builder(default)]
    pub security_group_ids: Option<Vec<String>>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    #[builder(default)]
    pub subnets: Option<Vec<String>>,
}

